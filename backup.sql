-- MySQL dump 10.16  Distrib 10.1.16-MariaDB, for Win64 (AMD64)
--
-- Host: 123.206.21.165    Database: blog
-- ------------------------------------------------------
-- Server version	10.1.16-MariaDB

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `category`
--

DROP TABLE IF EXISTS `category`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `category` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `category`
--

LOCK TABLES `category` WRITE;
/*!40000 ALTER TABLE `category` DISABLE KEYS */;
INSERT INTO `category` VALUES (1,'编程'),(2,'读书'),(3,'生活');
/*!40000 ALTER TABLE `category` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `comments`
--

DROP TABLE IF EXISTS `comments`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `comments` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `post_id` int(11) NOT NULL,
  `parent_id` int(11) DEFAULT '0' COMMENT '评论父id，如果是根评论，那么值为0',
  `ip` varchar(255) DEFAULT NULL COMMENT '评论者的ip',
  `name` varchar(255) DEFAULT NULL COMMENT '评论者的昵称',
  `ua` varchar(255) DEFAULT NULL COMMENT '评论者的浏览器类型',
  `content` longtext COMMENT '评论内容',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `comments`
--

LOCK TABLES `comments` WRITE;
/*!40000 ALTER TABLE `comments` DISABLE KEYS */;
/*!40000 ALTER TABLE `comments` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `post_tag`
--

DROP TABLE IF EXISTS `post_tag`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `post_tag` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `post_id` int(11) NOT NULL,
  `tag_id` int(11) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=143 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `post_tag`
--

LOCK TABLES `post_tag` WRITE;
/*!40000 ALTER TABLE `post_tag` DISABLE KEYS */;
INSERT INTO `post_tag` VALUES (21,39,29),(22,40,30),(23,41,29),(24,42,31),(25,43,32),(26,44,33),(27,45,34),(28,46,32),(29,46,35),(30,47,36),(31,48,36),(32,49,36),(33,50,37),(34,50,38),(35,51,39),(36,52,40),(37,53,41),(38,54,36),(39,54,42),(40,55,43),(41,56,44),(42,57,36),(43,57,45),(46,65,47),(47,65,48),(48,64,52),(49,69,36),(50,69,34),(51,70,38),(52,71,32),(53,72,39),(54,72,36),(55,73,53),(56,73,54),(57,74,34),(58,75,34),(59,76,36),(60,76,55),(61,77,56),(62,78,57),(63,79,58),(64,80,58),(65,80,59),(66,81,34),(67,82,34),(68,82,36),(69,83,45),(70,83,36),(71,84,36),(72,84,45),(73,85,30),(74,86,36),(75,90,36),(76,91,54),(77,91,37),(78,92,45),(79,93,59),(80,94,36),(81,95,36),(82,97,36),(83,97,60),(84,98,36),(85,98,60),(86,99,36),(87,100,36),(88,101,36),(89,101,34),(90,102,36),(91,103,36),(92,104,36),(93,105,36),(94,105,61),(95,106,36),(96,107,36),(97,108,62),(98,109,36),(99,110,36),(100,110,61),(101,111,36),(102,111,61),(103,112,36),(104,112,61),(105,113,36),(106,114,36),(107,115,36),(108,115,61),(109,116,36),(110,116,63),(111,117,36),(112,117,61),(113,118,36),(114,118,61),(115,119,36),(116,119,61),(117,120,36),(118,120,61),(119,121,36),(120,121,61),(121,122,36),(122,122,61),(123,123,36),(124,123,61),(125,124,64),(126,125,36),(127,125,61),(128,126,54),(129,127,36),(130,127,54),(131,128,30),(132,129,65),(133,130,36),(134,130,66),(135,131,36),(136,131,66),(137,132,36),(138,132,66),(139,133,45),(140,134,36),(141,135,36),(142,136,36);
/*!40000 ALTER TABLE `post_tag` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `posts`
--

DROP TABLE IF EXISTS `posts`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `posts` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `title` text NOT NULL,
  `content` longtext NOT NULL COMMENT '经过转换的博客内容',
  `markdown_source` longtext COMMENT 'markdown源文件，因为可能进行二次编辑',
  `category_id` int(11) NOT NULL COMMENT '归类id',
  `tags` varchar(1000) DEFAULT NULL COMMENT '标签集',
  `post_time` int(11) NOT NULL COMMENT '博客发布的时间戳',
  `comment_counts` int(11) NOT NULL DEFAULT '0',
  `view_counts` int(11) NOT NULL DEFAULT '0',
  `like_counts` int(11) NOT NULL DEFAULT '0',
  `status` smallint(6) NOT NULL DEFAULT '1' COMMENT '0表示异常，1表示正常',
  `stype` smallint(6) NOT NULL DEFAULT '1' COMMENT '1为已发布的博客，2为草稿',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=137 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `posts`
--

LOCK TABLES `posts` WRITE;
/*!40000 ALTER TABLE `posts` DISABLE KEYS */;
INSERT INTO `posts` VALUES (38,'关于','&lt;h2&gt;关于作者&lt;/h2&gt;\n&lt;hr/&gt;\n<ul>\n<li><em>Pythoner</em>+<em>Javascript Lover</em>+<em>LOLer</em>, 爱读书，爱编程，爱读书，爱开源，爱看《火影》(所以博客icon就是木叶的标志)。喜欢做Web开发相关工作(但是实验室不做这个，尴尬...)，欲从事互联网方面工作</li>\n<li>现在是研究僧一枚，从事舆情监控相关工作，主要使用的是<em>Python</em>+<em>Java</em>，目前在做研究新浪微博数据采集工作，重点是研究它的反爬虫机制</li>\n<li>虽然不知道博客会有多少读者会看，但是我还是想用这种方式记录经验教训，如果能帮到其它人那就更好了</li>\n</ul>\n&lt;h2&gt;关于该博客系统&lt;/h2&gt;\n&lt;hr/&gt;\n<ul>\n<li>本博客系统目前托管在github上，采用的是Flask+Bootstrap开发，数据库用的是Mysql,Flask和Bootstrap都是我现学现用的，所以还需要进一步完善。Flask/Python或者Web开发新手可以看看，了解一下Web开发的整个流程</li>\n<li>如果你也喜欢博客的风格，欢迎到github上fork它。<a href=\"https://github.com/ResolveWang/myblog\" rel=\"nofollow\">Fork it on github</a></li>\n</ul>\n&lt;h2&gt;联系方式&lt;/h2&gt;\n&lt;hr/&gt;\n<ul>\n<li>github:<a href=\"https://github.com/ResolveWang\" rel=\"nofollow\">ResolveWang</a></li>\n<li>weibo:<a href=\"http://weibo.com/u/3948359446/home\" rel=\"nofollow\">resolvewang</a></li>\n</ul>','## 关于作者 ##\n---\n- *Pythoner*+*Javascript Lover*+*LOLer*, 爱读书，爱编程，爱读书，爱开源，爱看《火影》(所以博客icon就是木叶的标志)。喜欢做Web开发相关工作(但是实验室不做这个，尴尬...)，欲从事互联网方面工作\n- 现在是研究僧一枚，从事舆情监控相关工作，主要使用的是*Python*+*Java*，目前在做研究新浪微博数据采集工作，重点是研究它的反爬虫机制\n- 虽然不知道博客会有多少读者会看，但是我还是想用这种方式记录经验教训，如果能帮到其它人那就更好了\n\n## 关于该博客系统 ##\n---\n- 本博客系统目前托管在github上，采用的是Flask+Bootstrap开发，数据库用的是Mysql,Flask和Bootstrap都是我现学现用的，所以还需要进一步完善。Flask/Python或者Web开发新手可以看看，了解一下Web开发的整个流程\n- 如果你也喜欢博客的风格，欢迎到github上fork它。[Fork it on github](https://github.com/ResolveWang/myblog)\n\n## 联系方式  ##\n---\n- github:[ResolveWang](https://github.com/ResolveWang)\n- weibo:[resolvewang](http://weibo.com/u/3948359446/home)',0,'',1466484012,0,0,0,1,1),(39,'记一次win server 2012上oracle12c的安装过程','<p>由于以前的服务器老出问题，所以重装了win server12 r2。项目组用的是oracle数据库，它的安装和配置比普通数据库麻烦一些，这里我把它记录下来，以后方便查看。</p>\n<h4>下载及解压oracle12c</h4>\n<p>我是在oracle官网上下载的，下载地址为http://<a href=\"http://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html\" rel=\"nofollow\">www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html</a> 。注意点击接受协议，然后点击“File1”和“File2”下载win64的两个压缩文件,但是下载oracle需要你先登录，所以必须先注册一个oracle的账号。这一步应该比较简单，所以就不截图和演示了。\n两个压缩文件大概有2.5G，下载下来过后分别解压。两个压缩文件解压之后都是database文件夹，把第二个的components文件夹中的所有文件都拷贝到第一个database文件夹下的componets目录下。</p>\n<h4>安装过程</h4>\n<p>1.单击“setup.exe”执行安装.在出现“配置安全更新”窗口中，取消勾选“我希望通过My Oracle Support接受安全更新”，单击下一步。这时候可能会弹出警告说“未提供电子邮件地址...”,忽略就行了(即点击“是”)\n2.如果下一步是软件更新的话，选择跳过软件更新(我安装的时候没出现这一步)，单击下一步\n3.在“安装选项”窗口中，选择“创建和配置数据库”，单击下一步\n4.在“系统类”窗口中，选择“桌面类”，单击下一步\n5.在“oracle主目录用户选择”中选择“使用windows内置账户”，单击下一步，这个时候会出现一个警告，忽略就行了(即点击“是”)\n6.在“典型安装”窗口中，选择“oracle的基目录”，“软件位置”和“数据库文件位置”。这里特别注意最好把三者放到比较大的磁盘中去，不然到后面数据增长或许会把磁盘撑爆，这是我的前车之鉴...选择数据库的版本为“企业版”，编码方式我选的是“UTF-8”，而不是默认的“GBK”，全局数据库名就是你需要用到的数据库，这个自己取名就行了。然后设置口令。最后‘“创建为容器数据库”为默认勾选，我没有管，点击下一步。\n7.“检查选角条件”，点击下一步\n8.在“概要”窗口中，确认你的安装配置（最好截一张图把这些配置信息保存到本地，方便以后查看），检查没问题过后，单击“安装”。单击之前最好把杀软、安全卫士等关闭，因为安装过程很慢很慢...\n9.“安装”。这是一个漫长的过程，等待就好，特别是“Database Configuration Assistant”的安装过程\n10.安装完成会要求你修改“sys”(超级管理员)和“system”(普通管理员)的密码。我想说的是一定要记住你的这两个密码，很重要...</p>\n<h4>服务设置</h4>\n<p>我在安装完成的时候关于oracle的服务都开启了。这里我还是说一下：\n- OracleOraDB12Home1TNSListener: 表示监听服务，如果客户端想连接数据库，必须打开它，包括程序想连接它也一样\n- OracleServiceORCL: 表示主服务。这个不开，oracle没法用。</p><strong>命名规则是：OracleService+数据库名称</strong>，这里的数据库名称是安装过程6中的<strong>全局数据库名称</strong>。&lt;/p&gt;\n&lt;p&gt;这个过程我是按网上已有的经验来安装的，点击<a href=\"http://jingyan.baidu.com/article/fea4511a78fc22f7ba912576.html?qq-pf-to=pcqq.c2c\" rel=\"nofollow\">原文</a>进行阅读。这样安装之后本地是能用了，但是还存在两个问题，这里说一下。&lt;/p&gt;\n&lt;h5&gt;ORA-12541：TNS:无监听程序&lt;/h5&gt;\n&lt;p&gt;安装后我用PLSQL远程连接Oracle出现了“ ORA-12541:TNS:无监听程序”这个错误。我又检查了一下“OracleOraDB12Home1TNSListener”这个服务是开启的，重新开启并没有效果。后来找到一篇文章得到了启发。解决方法如下：\n1.打开服务器上的“Net Configuration Assistant”\n2.选择监听程序配置，单击下一步\n3.选择重新配置，单击下一步\n4.选择监听程序，默认，下一步；如果你的监听已经启动，则会出现提示框，让你停止并修改监听程序，选择“是”，单击下一步\n5.使用默认的TCP协议，单击下一步\n6.选择端口号，使用默认的1521，单击下一步\n7.不配置另一个监听程序。选择“否”，单击下一步\n8.监听程序配置完成，单击下一步&lt;/p&gt;\n&lt;p&gt;重配服务名，测试连接\n1.打开服务器上的“Net Configuration Assistant”\n2.选择net服务器配置，单击下一步\n3.选择重新配置，单击下一步\n4.选择数据库名，单击下一步\n5.选择服务名，也就是创建数据库时使用的全局数据库名，单击下一步（如果记不住全局数据库名，可以打开windows服务，上文中已经讲了主服务的命名规则，其中就有全局数据库名）\n6.选择TCP协议，单击下一步\n7.填写主机名(最好使用公网或者内网IP)，端口使用自己设置的，一般是默认的1521，单击下一步\n8.选择进行测试，单击下一步\n9.选择更改登陆，点击下一步\n10 填写用户名和口令（system和sys已经在安装时候设置了），单击下一步\n11 测试连接成功(不出意外的话)。单击下一步\n12 网络服务名，默认（和之前的数据库名一样），单击下一步\n13 不配置另一个Net服务名，选择否，下一步\n14 Net服务名配置完成，单击下一步\n这时候应该可以使用PLSQL进行远程登录Oracle了&lt;/p&gt;\n&lt;p&gt;我是查看<a href=\"http://blog.csdn.net/wwbmyos/article/details/11475551/\" rel=\"nofollow\">这篇文章</a>找到上述解决方法的。&lt;/p&gt;\n&lt;h5&gt;创建用户的时候出错&lt;/h5&gt;\n&lt;p&gt;我使用sys账号用“create user username identified by password”创建用户的时候出错。查原因发现是<strong>oracle12c版本必须要求用户名以“c##”开头</strong>。一试，果然就成功了。然后要做的就是给用户赋权限了，因为网上很多这一类的例子，这里我就不细说了&lt;/p&gt;\n&lt;p&gt;ps:在安装和解决PLSQL连接问题的时候都参考了网上的方法，两篇文章原文都配有图，如果光看我的文章不清楚的，可以点击查看那两篇参考文章:<a href=\"http://jingyan.baidu.com/article/fea4511a78fc22f7ba912576.html?qq-pf-to=pcqq.c2c\" rel=\"nofollow\">安装过程</a>、<a href=\"http://blog.csdn.net/wwbmyos/article/details/11475551\" rel=\"nofollow\">解决监听出错问题</a>。我只是把知识做了一个归纳，并不是原创文章。考虑到以后可能还用得上这些知识，所以就简单总结了，以后就不用自己再花比较多的时间找了&lt;/p&gt;','由于以前的服务器老出问题，所以重装了win server12 r2。项目组用的是oracle数据库，它的安装和配置比普通数据库麻烦一些，这里我把它记录下来，以后方便查看。\n#### 下载及解压oracle12c\n我是在oracle官网上下载的，下载地址为http://www.oracle.com/technetwork/database/enterprise-edition/downloads/index.html 。注意点击接受协议，然后点击“File1”和“File2”下载win64的两个压缩文件,但是下载oracle需要你先登录，所以必须先注册一个oracle的账号。这一步应该比较简单，所以就不截图和演示了。\n两个压缩文件大概有2.5G，下载下来过后分别解压。两个压缩文件解压之后都是database文件夹，把第二个的components文件夹中的所有文件都拷贝到第一个database文件夹下的componets目录下。\n#### 安装过程\n1.单击“setup.exe”执行安装.在出现“配置安全更新”窗口中，取消勾选“我希望通过My Oracle Support接受安全更新”，单击下一步。这时候可能会弹出警告说“未提供电子邮件地址...”,忽略就行了(即点击“是”)\n2.如果下一步是软件更新的话，选择跳过软件更新(我安装的时候没出现这一步)，单击下一步\n3.在“安装选项”窗口中，选择“创建和配置数据库”，单击下一步\n4.在“系统类”窗口中，选择“桌面类”，单击下一步\n5.在“oracle主目录用户选择”中选择“使用windows内置账户”，单击下一步，这个时候会出现一个警告，忽略就行了(即点击“是”)\n6.在“典型安装”窗口中，选择“oracle的基目录”，“软件位置”和“数据库文件位置”。这里特别注意最好把三者放到比较大的磁盘中去，不然到后面数据增长或许会把磁盘撑爆，这是我的前车之鉴...选择数据库的版本为“企业版”，编码方式我选的是“UTF-8”，而不是默认的“GBK”，全局数据库名就是你需要用到的数据库，这个自己取名就行了。然后设置口令。最后‘“创建为容器数据库”为默认勾选，我没有管，点击下一步。\n7.“检查选角条件”，点击下一步\n8.在“概要”窗口中，确认你的安装配置（最好截一张图把这些配置信息保存到本地，方便以后查看），检查没问题过后，单击“安装”。单击之前最好把杀软、安全卫士等关闭，因为安装过程很慢很慢...\n9.“安装”。这是一个漫长的过程，等待就好，特别是“Database Configuration Assistant”的安装过程\n10.安装完成会要求你修改“sys”(超级管理员)和“system”(普通管理员)的密码。我想说的是一定要记住你的这两个密码，很重要...\n\n#### 服务设置\n我在安装完成的时候关于oracle的服务都开启了。这里我还是说一下：\n- OracleOraDB12Home1TNSListener: 表示监听服务，如果客户端想连接数据库，必须打开它，包括程序想连接它也一样\n- OracleServiceORCL: 表示主服务。这个不开，oracle没法用。**命名规则是：OracleService+数据库名称**，这里的数据库名称是安装过程6中的**全局数据库名称**。\n\n这个过程我是按网上已有的经验来安装的，点击[原文](http://jingyan.baidu.com/article/fea4511a78fc22f7ba912576.html?qq-pf-to=pcqq.c2c)进行阅读。这样安装之后本地是能用了，但是还存在两个问题，这里说一下。\n\n##### ORA-12541：TNS:无监听程序\n安装后我用PLSQL远程连接Oracle出现了“ ORA-12541:TNS:无监听程序”这个错误。我又检查了一下“OracleOraDB12Home1TNSListener”这个服务是开启的，重新开启并没有效果。后来找到一篇文章得到了启发。解决方法如下：\n1.打开服务器上的“Net Configuration Assistant”\n2.选择监听程序配置，单击下一步\n3.选择重新配置，单击下一步\n4.选择监听程序，默认，下一步；如果你的监听已经启动，则会出现提示框，让你停止并修改监听程序，选择“是”，单击下一步\n5.使用默认的TCP协议，单击下一步\n6.选择端口号，使用默认的1521，单击下一步\n7.不配置另一个监听程序。选择“否”，单击下一步\n8.监听程序配置完成，单击下一步\n\n重配服务名，测试连接\n1.打开服务器上的“Net Configuration Assistant”\n2.选择net服务器配置，单击下一步\n3.选择重新配置，单击下一步\n4.选择数据库名，单击下一步\n5.选择服务名，也就是创建数据库时使用的全局数据库名，单击下一步（如果记不住全局数据库名，可以打开windows服务，上文中已经讲了主服务的命名规则，其中就有全局数据库名）\n6.选择TCP协议，单击下一步\n7.填写主机名(最好使用公网或者内网IP)，端口使用自己设置的，一般是默认的1521，单击下一步\n8.选择进行测试，单击下一步\n9.选择更改登陆，点击下一步\n10 填写用户名和口令（system和sys已经在安装时候设置了），单击下一步\n11 测试连接成功(不出意外的话)。单击下一步\n12 网络服务名，默认（和之前的数据库名一样），单击下一步\n13 不配置另一个Net服务名，选择否，下一步\n14 Net服务名配置完成，单击下一步\n这时候应该可以使用PLSQL进行远程登录Oracle了\n\n我是查看[这篇文章](http://blog.csdn.net/wwbmyos/article/details/11475551/)找到上述解决方法的。\n\n##### 创建用户的时候出错\n我使用sys账号用“create user username identified by password”创建用户的时候出错。查原因发现是**oracle12c版本必须要求用户名以“c##”开头**。一试，果然就成功了。然后要做的就是给用户赋权限了，因为网上很多这一类的例子，这里我就不细说了\n\nps:在安装和解决PLSQL连接问题的时候都参考了网上的方法，两篇文章原文都配有图，如果光看我的文章不清楚的，可以点击查看那两篇参考文章:[安装过程](http://jingyan.baidu.com/article/fea4511a78fc22f7ba912576.html?qq-pf-to=pcqq.c2c)、[解决监听出错问题](http://blog.csdn.net/wwbmyos/article/details/11475551)。我只是把知识做了一个归纳，并不是原创文章。考虑到以后可能还用得上这些知识，所以就简单总结了，以后就不用自己再花比较多的时间找了',1,'数据库',1466484163,0,86,0,1,1),(40,'记一次ubuntu16.04 lantern安装过程(win用户也可以看看)','&lt;p&gt;lantern中文名为蓝灯，主要用于科学上网。最近百度因为魏则西事件又被舆论推向了风口浪尖，除了百度之外，还有很多很优秀的搜索引擎，比如必应和google。而google需要FQ才能上，而蓝灯就是实现这个功能的。而我最近升级了ubuntu16.04，因为无线网卡驱动不兼容和命令行终端bug，我选择了中国版的ukyliny16.04,说实话，我感觉无论从界面还有使用习惯上来说，都比ubuntu16.04更适合我。升级了系统我一般第一件事就是安装google浏览器和用于科学上网的工具。lantern速度很快，表现很出色，所以我一般都用的它，而不是每次都麻烦去找google的镜像IP和更换host文件，因为我觉得那样太麻烦了。\n下面具体说一下安装过程：由于GFW的原因，我们是不能直接访问lantern的官网的，但所幸的是lantern整个项目托管在github上并且是开源的，这里是它的项目主页：<a href=\"https://github.com/getlantern/lantern\" rel=\"nofollow\">lantern项目主页</a>,这是不需要FQ就能获取的。<strong>我也在win平台上使用它，win平台安装比较方便，直接下载安装包就可以安装了，安装包地址请看项目主页的README.md文件。</strong>win平台就不多说。我主要说说ubuntu下的安装。我们可以直接下载整个项目，解压后切换到lantern-devel-&gt;installer-resources-&gt;linux目录下，使用&lt;/p&gt;\n<blockquote>\n<p>./<a href=\"http://lantern.sh\" rel=\"nofollow\">lantern.sh</a></p>\n</blockquote>\n&lt;p&gt;即可运行lantern,然后就可以享受科学上网的乐趣了。但是我这次使用这种方式没成功。于是我就在它的README.md文件中找到了它的ubuntu的安装包。我的系统是64位，但我第一次使用的是32位的安装包，并没安装成功，于是我又卸载再安装的64位安装包。再说说详细安装方法吧，ubuntu16.04的软件中心应该是有bug，安装不了第三方.deb文件，我们只有使用dpkg -i 或者gdebi的方式安装，我使用的是后者，因为后者功能更加强大。要使用gdebi命令先要安装它：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;sudo apt install gdebi-core&lt;/p&gt;\n</blockquote>\n&lt;p&gt;然后就可以安装.deb文件了。安装过程如下：先切换到你下载的lantern的安装文件目录下，直接使用&lt;/p&gt;\n<blockquote>\n&lt;p&gt;sudo gdebi lantern-installer-beta-64-bit.deb &lt;/p&gt;\n</blockquote>\n&lt;p&gt;(这个是我的安装文件名)，这样就成功安装了。\n安装好了我并没找到它的启动图标（重启系统后可以搜索到它的启动图标），我们可以直接在终端输入&lt;/p&gt;\n<blockquote>\n&lt;p&gt;lantern&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这样就开启lantern了，然后就可以直接使用google搜索引擎了。但是从个人的使用经验来说，我需要说明一点：如果打开lantern后，立即访问被墙的网站，可能会访问不到，因为那个时候lantern还可能在寻找可用的ip。但是这个最长时间持续不到5分钟。之后就能很快的上google、facebook、youtube等网站了，速度和付费的vpn来比也丝毫不逊色。\nPS：相对于百度搜索和360搜索等搜索引擎，google搜索结果更精准，更没有将那些恶心的推广链接放在首位，我并不是谷歌吹，谁用谁知道，特别是对于开发者而言。而国内诸如百度等搜索引擎，个人感觉是没多少社会责任感和企业价值观的，还是少用为好&lt;/p&gt;','lantern中文名为蓝灯，主要用于科学上网。最近百度因为魏则西事件又被舆论推向了风口浪尖，除了百度之外，还有很多很优秀的搜索引擎，比如必应和google。而google需要FQ才能上，而蓝灯就是实现这个功能的。而我最近升级了ubuntu16.04，因为无线网卡驱动不兼容和命令行终端bug，我选择了中国版的ukyliny16.04,说实话，我感觉无论从界面还有使用习惯上来说，都比ubuntu16.04更适合我。升级了系统我一般第一件事就是安装google浏览器和用于科学上网的工具。lantern速度很快，表现很出色，所以我一般都用的它，而不是每次都麻烦去找google的镜像IP和更换host文件，因为我觉得那样太麻烦了。\n下面具体说一下安装过程：由于GFW的原因，我们是不能直接访问lantern的官网的，但所幸的是lantern整个项目托管在github上并且是开源的，这里是它的项目主页：[lantern项目主页](https://github.com/getlantern/lantern),这是不需要FQ就能获取的。**我也在win平台上使用它，win平台安装比较方便，直接下载安装包就可以安装了，安装包地址请看项目主页的README.md文件。**win平台就不多说。我主要说说ubuntu下的安装。我们可以直接下载整个项目，解压后切换到lantern-devel->installer-resources->linux目录下，使用\n>./lantern.sh\n\n即可运行lantern,然后就可以享受科学上网的乐趣了。但是我这次使用这种方式没成功。于是我就在它的README.md文件中找到了它的ubuntu的安装包。我的系统是64位，但我第一次使用的是32位的安装包，并没安装成功，于是我又卸载再安装的64位安装包。再说说详细安装方法吧，ubuntu16.04的软件中心应该是有bug，安装不了第三方.deb文件，我们只有使用dpkg -i 或者gdebi的方式安装，我使用的是后者，因为后者功能更加强大。要使用gdebi命令先要安装它：\n>sudo apt install gdebi-core\n\n然后就可以安装.deb文件了。安装过程如下：先切换到你下载的lantern的安装文件目录下，直接使用\n>sudo gdebi lantern-installer-beta-64-bit.deb \n\n(这个是我的安装文件名)，这样就成功安装了。\n安装好了我并没找到它的启动图标（重启系统后可以搜索到它的启动图标），我们可以直接在终端输入\n>lantern\n\n这样就开启lantern了，然后就可以直接使用google搜索引擎了。但是从个人的使用经验来说，我需要说明一点：如果打开lantern后，立即访问被墙的网站，可能会访问不到，因为那个时候lantern还可能在寻找可用的ip。但是这个最长时间持续不到5分钟。之后就能很快的上google、facebook、youtube等网站了，速度和付费的vpn来比也丝毫不逊色。\nPS：相对于百度搜索和360搜索等搜索引擎，google搜索结果更精准，更没有将那些恶心的推广链接放在首位，我并不是谷歌吹，谁用谁知道，特别是对于开发者而言。而国内诸如百度等搜索引擎，个人感觉是没多少社会责任感和企业价值观的，还是少用为好',3,'科学上网',1466484236,0,90,0,1,1),(41,'Wampp For Linux的mysql密码修改和字符编码的设置','&lt;p&gt;折腾了半天的wampp for linux 了，最先是<strong>mysql默认密码</strong>的修改，因为原始的默认密码为空，用起来总不舒服，后来就想到把mysql的默认密码改了，具体如下:\n先改掉mysql的默认密码．然后再在配置文件里改掉phpMyadmin里面的文件．步骤如下:\n先进入phpMyadmin,然后写一个sql语句修改mysql默认密码：&lt;/p&gt;\n&lt;p&gt;<code>update&gt;update user set password=password(\'New password\') where user=\'root\';</code>&lt;/p&gt;\n&lt;p&gt;这里的new password代表的是需要改的新密码,而root表示用户；然后再改phpMyadmin的密码，进入wampp的安装目录下的phpmyadmin文件夹,搜索找到config.inc.php文件，打开文件，找到　/<em> Authentication type </em>/　，然后将它后面的代码改为以下形式：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;$cfg[\'Servers\'][$i][\'auth_type\'] = \'config\';\n$cfg[\'Servers\'][$i][\'user\'] = \'root\';\n$cfg[\'Servers\'][$i][\'password\'] = \'123456\';&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这里\'123456\'代表的就是我改过后的数据库密码，这样子改过后就ok了．&lt;/p&gt;\n&lt;hr/&gt;\n&lt;p&gt;还有一个问题就是<strong>mysql的默认字符编码</strong>，wampp自带的mysql默认编码为latin1,所以在存储中文字符的时候会出现乱码，可以通过语句:show variables like \'character_set_%\';查看mysql数据库的编码是否支持中文(utf8或者gbk)，如果需要修改，步骤如下：\n打开mysql的配置文件<strong>my.cnf</strong>,wampp直接在面板里面就可以打开该配置文件了，然后在[mysqld]后面修改代码为：\n<code>[mysqld]\nuser = mysql\nport=3306\nsocket        = /opt/lampp/var/mysql/mysql.sock\nskip-external-locking\nkey_buffer = 16M\nmax_allowed_packet = 1M\ncharacter_set_server=utf8\ninit_connect=\'SET NAMES utf8\'\ntable_open_cache = 64\nsort_buffer_size = 512K\nnet_buffer_length = 8K\nread_buffer_size = 256K\nread_rnd_buffer_size = 512K\nmyisam_sort_buffer_size = 8M</code>\n红色部分为需要添加的代码，这样修改后默认编码就是<strong>uft8</strong>了&lt;/p&gt;','折腾了半天的wampp for linux 了，最先是**mysql默认密码**的修改，因为原始的默认密码为空，用起来总不舒服，后来就想到把mysql的默认密码改了，具体如下:\n先改掉mysql的默认密码．然后再在配置文件里改掉phpMyadmin里面的文件．步骤如下:\n先进入phpMyadmin,然后写一个sql语句修改mysql默认密码：\n\n```update>update user set password=password(\'New password\') where user=\'root\';```\n\n这里的new password代表的是需要改的新密码,而root表示用户；然后再改phpMyadmin的密码，进入wampp的安装目录下的phpmyadmin文件夹,搜索找到config.inc.php文件，打开文件，找到　/* Authentication type */　，然后将它后面的代码改为以下形式：\n> $cfg[\'Servers\'][$i][\'auth_type\'] = \'config\';\n$cfg[\'Servers\'][$i][\'user\'] = \'root\';\n$cfg[\'Servers\'][$i][\'password\'] = \'123456\';\n\n这里\'123456\'代表的就是我改过后的数据库密码，这样子改过后就ok了．\n\n---\n　　还有一个问题就是**mysql的默认字符编码**，wampp自带的mysql默认编码为latin1,所以在存储中文字符的时候会出现乱码，可以通过语句:show variables like \'character\\_set\\_%\';查看mysql数据库的编码是否支持中文(utf8或者gbk)，如果需要修改，步骤如下：\n打开mysql的配置文件**my.cnf**,wampp直接在面板里面就可以打开该配置文件了，然后在[mysqld]后面修改代码为：\n```\n[mysqld]\nuser = mysql\nport=3306\nsocket        = /opt/lampp/var/mysql/mysql.sock\nskip-external-locking\nkey_buffer = 16M\nmax_allowed_packet = 1M\ncharacter_set_server=utf8\ninit_connect=\'SET NAMES utf8\'\ntable_open_cache = 64\nsort_buffer_size = 512K\nnet_buffer_length = 8K\nread_buffer_size = 256K\nread_rnd_buffer_size = 512K\nmyisam_sort_buffer_size = 8M\n```\n红色部分为需要添加的代码，这样修改后默认编码就是**uft8**了',1,'数据库',1466485085,0,68,0,1,1),(42,'Markdown语法简要说明','&lt;h2&gt;说明：这个是我在为知笔记上看到的markdown语法，感觉常用的都概括了，而且很简明易懂，所以转过来了，并且适当的补充了一些自己写作需要的语法&lt;/h2&gt;\n&lt;p&gt;先来个小技巧&lt;/p&gt;\n&lt;p&gt;不管我再怎么说 Markdown 的语法记忆负担小、简单，在最初你都会有点儿晕。在这里给大家分享个小技巧：&lt;/p&gt;\n&lt;p&gt;最初只需要记住 # 标题一、## 标题二、1. 第一点、<em> 这一点，用这几个写写日志、需求文档、小文章，排版上足够了；\n逐渐的你发现有些文字需要重点指出，那么还可以使用 <strong>加粗</strong>、</em>斜体* 来对文字做重点说明；\n如果你是名程序员，那么可以用 ``` 把代码块包起来，渲染后可以关键字高亮，用 &gt; 可以做引用 ；\n学生的话，就去了解一下 LaTex 吧，为知笔记 Markdown 支持 Mathjax 公式渲染哦~\nMarkdown 格式标记符号说明&lt;/p&gt;\n&lt;hr/&gt;\n<ul>\n<li>标题</li>\n</ul>\n&lt;p&gt;在行首插入 1 到 6个#，分别表示标题 1 到标题 6&lt;/p&gt;\n&lt;p&gt;# 这是标题1&lt;/p&gt;\n&lt;p&gt;## 这是标题2&lt;/p&gt;\n&lt;p&gt;###### 这是标题6&lt;/p&gt;\n&lt;h1&gt;这是标题1&lt;/h1&gt;\n&lt;h2&gt;这是标题2&lt;/h2&gt;\n&lt;h6&gt;这是标题6&lt;/h6&gt;\n&lt;hr/&gt;\n<ul>\n<li>有序列表</li>\n</ul>\n&lt;p&gt;在行首增加 1.、2.、3.，即数字和英文句点, 不要求数字一定要连续，可以都是1.&lt;/p&gt;\n&lt;p&gt;1.(这里有一个空格)有序列表&lt;/p&gt;\n&lt;p&gt;1.(这里有一个空格)有序列表&lt;/p&gt;\n&lt;p&gt;4.(这里有一个空格)有序列表&lt;/p&gt;\n&lt;p&gt;效果：&lt;/p&gt;\n<ol>\n<li>有序列表</li>\n<li>有序列表</li>\n<li>有序列表</li>\n</ol>\n&lt;hr/&gt;\n<ul>\n<li>无序列表</li>\n</ul>\n&lt;p&gt;在行首增加 * 或 -：&lt;/p&gt;\n&lt;p&gt;* 无序列表&lt;/p&gt;\n&lt;p&gt;* 无序列表&lt;/p&gt;\n&lt;p&gt;* 无序列表&lt;/p&gt;\n&lt;p&gt;效果：&lt;/p&gt;\n<ul>\n<li>无序列表</li>\n<li>无序列表</li>\n</ul>\n&lt;hr/&gt;\n<ul>\n<li>插入图片</li>\n</ul>\n<p>标准的Markdown语法为：![介绍](链接),如：</p>\n<p>![](<a href=\"http://cdn.wiz.cn/wp-content/uploads/2015/06/wiz_logo.png\" rel=\"nofollow\">http://cdn.wiz.cn/wp-content/uploads/2015/06/wiz_logo.png</a>)</p>\n<p>效果如下：</p>\n<p><img alt=\"\" rel=\"nofollow\" src=\"<a href=\"><a href=\"http://cdn.wiz.cn/wp-content/uploads/2015/06/wiz_logo.png\" rel=\"nofollow\">http://cdn.wiz.cn/wp-content/uploads/2015/06/wiz_logo.png</a>\"/&gt;</p>\n<hr>\n<ul>\n<li>插入链接</li>\n</ul>\n<p>[描述](链接地址) ，例如：</p>\n<p>[为知笔记](<a href=\"http://www.wiz.cn\" rel=\"nofollow\">http://www.wiz.cn</a>)，</p>\n<p>效果如下：</p>\n<p></p><a href=\"http://www.wiz.cn\" rel=\"nofollow\">为知笔记</a>，&lt;/p&gt;\n&lt;p&gt;注意要使用英文符号&lt;/p&gt;\n&lt;hr/&gt;\n<ul>\n<li>粗体、斜体、删除线</li>\n</ul>\n&lt;p&gt;粗体：在文字前后添加 ** (注意符号与文字间不要有空格）&lt;/p&gt;\n&lt;p&gt;斜体：在文字前后添加 *&lt;/p&gt;\n&lt;p&gt;删除线：在文字前后添加 ~~&lt;/p&gt;\n&lt;p&gt;**粗体**&lt;/p&gt;\n&lt;p&gt;效果：<strong>粗体</strong>&lt;/p&gt;\n&lt;p&gt;其它两个用法也一样&lt;/p&gt;\n&lt;p&gt;*斜体*&lt;/p&gt;\n&lt;p&gt;\\~\\~\\~删除线\\~\\~\\~&lt;/p&gt;\n&lt;p&gt;效果如下：&lt;/p&gt;\n&lt;p&gt;<em>斜体</em>&lt;/p&gt;\n&lt;p&gt;~~~删除线~~~&lt;/p&gt;\n&lt;hr/&gt;\n<ul>\n<li>引用</li>\n</ul>\n&lt;p&gt;在文字前 添加 &gt;&lt;/p&gt;\n&lt;p&gt;比如：&gt; 如果你无法简洁的表达你的想法，那只说明你还不够了解它。 -- 阿尔伯特·爱因斯坦\n效果：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;如果你无法简洁的表达你的想法，那只说明你还不够了解它。 -- 阿尔伯特·爱因斯坦&lt;/p&gt;\n</blockquote>\n&lt;hr/&gt;\n<ul>\n<li>表格\n语法为：</li>\n</ul>\n&lt;p&gt;| 为知笔记|更新 | 版本 |&lt;br&gt;\n|------------|-----------|--------|&lt;br&gt;\n| WizNote | Markdown| Latest |&lt;br&gt;&lt;/p&gt;\n&lt;hr/&gt;\n<ul>\n<li>代码</li>\n</ul>\n&lt;p&gt;在代码前后增加 三个反单引号：```&lt;/p&gt;\n&lt;p&gt;<strong>这里的“<code>”不是单引号的“‘”,而是esc键下面的那个“~”键**的‘**</code></strong>’,这个也坑了我不少，找了很久才发现是这个！&lt;/p&gt;\n&lt;p&gt;```&lt;/p&gt;\n&lt;p&gt;int i = 0; i = 1; &lt;/p&gt;\n&lt;p&gt;for (int i = 0; i &lt; 100; i++)&lt;/p&gt;\n&lt;p&gt;{&lt;/p&gt;\n&lt;pre&gt;<code>  printf(\"hello markdown!\\n\");\n</code>&lt;/pre&gt;\n&lt;p&gt;}\n```&lt;/p&gt;\n&lt;p&gt;效果：&lt;/p&gt;\n&lt;p&gt;<code>int i = 0; i = 1;\nfor (int i = 0; i &lt; 100; i++)\n{\n      printf(\"hello markdown!\\n\");\n}</code>&lt;/p&gt;\n&lt;hr/&gt;\n<ul>\n<li>分割线</li>\n</ul>\n&lt;p&gt;使用三个及以上的“-”、“*”等符号制作分割线，它们之中需要加上空格\n- - -\n效果：&lt;/p&gt;\n&lt;hr/&gt;\n<ul>\n<li>换行</li>\n</ul>\n&lt;p&gt;使用‘&lt; br /&gt;’进行换行&lt;/p&gt;\n&lt;hr/&gt;\n&lt;p&gt;<strong>ps:</strong>&lt;/p&gt;\n<ul>\n<li>\n&lt;p&gt;上面我介绍的都差不多是用的最多的知识。关于公式到时序图那一块我这里省略了，因为对于不同的markdown编辑器，可能会支持也可能不支持，而我自己用的就不支持，所以这里没办法演示他们的效果,也就省略了。如果有需要，可以再查看markdown官方说明&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;大家如果有兴趣可以使用一些功能更强大的markdown编辑器，为知笔记就是一款很好的云笔记，当时因为它的跨平台所以我舍弃了有道云笔记,它很早以前就支持markdown了，使用对比后才发现它比有道云笔记强大得多。windows我还推荐使用haroopad,很好用，免费软件，下载地址:<a href=\"http://pad.haroopress.com/user.html\" rel=\"nofollow\">这里</a>。此外，很多博客系统也支持markdown了，比如简书，很好用。我自己的个人博客也是用的markdown，在github上开源了，有兴趣的可以试试:<a href=\"https://github.com/ResolveWang/myblog\" rel=\"nofollow\">myblog</a>&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;还有就是使用markdown写作的时候每个段落最好隔一个空格，以免出现显示和预期不符的情况&lt;/p&gt;\n</li>\n</ul>','## 说明：这个是我在为知笔记上看到的markdown语法，感觉常用的都概括了，而且很简明易懂，所以转过来了，并且适当的补充了一些自己写作需要的语法\n先来个小技巧\n\n不管我再怎么说 Markdown 的语法记忆负担小、简单，在最初你都会有点儿晕。在这里给大家分享个小技巧：\n\n最初只需要记住 # 标题一、## 标题二、1. 第一点、* 这一点，用这几个写写日志、需求文档、小文章，排版上足够了；\n逐渐的你发现有些文字需要重点指出，那么还可以使用 **加粗**、*斜体* 来对文字做重点说明；\n如果你是名程序员，那么可以用 ``` 把代码块包起来，渲染后可以关键字高亮，用 > 可以做引用 ；\n学生的话，就去了解一下 LaTex 吧，为知笔记 Markdown 支持 Mathjax 公式渲染哦~\nMarkdown 格式标记符号说明\n\n---\n* 标题\n\n在行首插入 1 到 6个#，分别表示标题 1 到标题 6\n\n\\# 这是标题1\n\n\\## 这是标题2\n\n\\###### 这是标题6\n\n# 这是标题1\n## 这是标题2\n###### 这是标题6\n\n---\n* 有序列表\n\n在行首增加 1.、2.、3.，即数字和英文句点, 不要求数字一定要连续，可以都是1.\n\n1.(这里有一个空格)有序列表\n\n1.(这里有一个空格)有序列表\n\n4.(这里有一个空格)有序列表\n\n效果：\n\n1. 有序列表\n1. 有序列表\n4. 有序列表\n\n---\n* 无序列表\n\n在行首增加 * 或 -：\n\n\\* 无序列表\n\n\\* 无序列表\n\n\\* 无序列表\n\n效果：\n\n* 无序列表\n* 无序列表\n\n---\n\n* 插入图片\n\n标准的Markdown语法为：![介绍]\\(链接),如：\n\n \\!\\[]\\(http://cdn.wiz.cn/wp-content/uploads/2015/06/wiz_logo.png)\n\n 效果如下：\n\n ![](http://cdn.wiz.cn/wp-content/uploads/2015/06/wiz_logo.png)\n\n---\n* 插入链接\n\n\\[描述]\\(链接地址) ，例如：\n\n\\[为知笔记]\\(http://www.wiz.cn)，\n\n效果如下：\n\n[为知笔记](http://www.wiz.cn)，\n\n注意要使用英文符号\n\n---\n* 粗体、斜体、删除线\n\n粗体：在文字前后添加 ** (注意符号与文字间不要有空格）\n\n斜体：在文字前后添加 *\n\n删除线：在文字前后添加 ~~\n\n\\*\\*粗体\\*\\*\n\n效果：**粗体**\n\n其它两个用法也一样\n\n\\*斜体\\*\n\n\\~\\~\\~删除线\\~\\~\\~\n\n效果如下：\n\n*斜体*\n\n~~~删除线~~~\n\n---\n* 引用\n\n在文字前 添加 >\n\n比如：\\> 如果你无法简洁的表达你的想法，那只说明你还不够了解它。 -- 阿尔伯特·爱因斯坦\n效果：\n\n> 如果你无法简洁的表达你的想法，那只说明你还不够了解它。 -- 阿尔伯特·爱因斯坦\n\n---\n* 表格\n语法为：\n\n| 为知笔记|更新 | 版本 |<br>\n|------------|-----------|--------|<br>\n| WizNote | Markdown| Latest |<br>\n\n---\n\n* 代码\n\n\n在代码前后增加 三个反单引号：```\n\n**这里的“`”不是单引号的“‘”,而是esc键下面的那个“~”键**的‘**`**’,这个也坑了我不少，找了很久才发现是这个！\n\n\\```\n\nint i = 0; i = 1; \n\nfor (int i = 0; i < 100; i++)\n\n{\n\n      printf(\"hello markdown!\\n\");\n\n}\n\\```\n\n效果：\n\n```\nint i = 0; i = 1;\nfor (int i = 0; i < 100; i++)\n{\n      printf(\"hello markdown!\\n\");\n}\n```\n\n---\n* 分割线\n\n使用三个及以上的“-”、“*”等符号制作分割线，它们之中需要加上空格\n\\- - -\n效果：\n\n---\n\n* 换行\n\n使用‘< br />’进行换行\n\n---\n**ps:**\n\n* 上面我介绍的都差不多是用的最多的知识。关于公式到时序图那一块我这里省略了，因为对于不同的markdown编辑器，可能会支持也可能不支持，而我自己用的就不支持，所以这里没办法演示他们的效果,也就省略了。如果有需要，可以再查看markdown官方说明\n\n* 大家如果有兴趣可以使用一些功能更强大的markdown编辑器，为知笔记就是一款很好的云笔记，当时因为它的跨平台所以我舍弃了有道云笔记,它很早以前就支持markdown了，使用对比后才发现它比有道云笔记强大得多。windows我还推荐使用haroopad,很好用，免费软件，下载地址:[这里](http://pad.haroopress.com/user.html)。此外，很多博客系统也支持markdown了，比如简书，很好用。我自己的个人博客也是用的markdown，在github上开源了，有兴趣的可以试试:[myblog](https://github.com/ResolveWang/myblog)\n\n* 还有就是使用markdown写作的时候每个段落最好隔一个空格，以免出现显示和预期不符的情况\n\n',3,'markdown',1466488597,0,119,0,1,1),(43,'flask-sqlalchemy遇到的错误','&lt;p&gt;<strong>No module named MySqldb</strong>&lt;/p&gt;\n&lt;hr/&gt;\n&lt;p&gt;<em>解决方法：</em>\npython2.x:安装mysql-python。最方便的方式是通过<a href=\"http://www.lfd.uci.edu/~gohlke/pythonlibs/#mysql-python\" rel=\"nofollow\">这个网址</a>  下载对应的mysql-python包进行安装。下载下来的是.whl文件。所以我们需要先通过pip或者easy_install方式安装wheel模块：\n’’’\npip install wheel&lt;/p&gt;\n&lt;p&gt;然后直接通过&lt;/p&gt;\n<blockquote>\n&lt;p&gt;pip install mysql-python.whl(这里是文件名)\n就能安装了&lt;/p&gt;\n</blockquote>\n&lt;p&gt;python3.x:由于MySqldb没有python3的版本实现，但是有一个从mysqldb fork过来的实现，也是可以用于解决这个问题的，名字是<em>mysqlclient</em>,驱动文件地址为<a href=\"http://www.lfd.uci.edu/~gohlke/pythonlibs/#mysql-python\" rel=\"nofollow\">http://www.lfd.uci.edu/~gohlke/pythonlibs/#mysql-python</a>  。文件格式是.whl，所以安装方式和上面说的一样&lt;/p&gt;\n&lt;p&gt;&lt;br/&gt;\n<strong>if track_modifications is None:warnings.warn(\'SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future. Set it to True to suppress this warning.\')</strong>&lt;/p&gt;\n&lt;hr/&gt;\n&lt;p&gt;<em>解决方法：</em>\n在应用文件比如说manage.py中设置：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;app.config[\'SQLALCHEMY_TRACK_MODIFICATIONS\'] = True&lt;/p&gt;\n</blockquote>','**No module named MySqldb**\n- - -\n*解决方法：*\npython2.x:安装mysql-python。最方便的方式是通过[这个网址](http://www.lfd.uci.edu/~gohlke/pythonlibs/#mysql-python)  下载对应的mysql-python包进行安装。下载下来的是.whl文件。所以我们需要先通过pip或者easy_install方式安装wheel模块：\n’’’\npip install wheel\n\n然后直接通过\n >pip install mysql-python.whl(这里是文件名)\n就能安装了\n \npython3.x:由于MySqldb没有python3的版本实现，但是有一个从mysqldb fork过来的实现，也是可以用于解决这个问题的，名字是*mysqlclient*,驱动文件地址为[http://www.lfd.uci.edu/~gohlke/pythonlibs/#mysql-python](http://www.lfd.uci.edu/~gohlke/pythonlibs/#mysql-python)  。文件格式是.whl，所以安装方式和上面说的一样\n\n<br />\n**if track_modifications is None:warnings.warn(\'SQLALCHEMY_TRACK_MODIFICATIONS adds significant overhead and will be disabled by default in the future. Set it to True to suppress this warning.\')**\n- - -\n*解决方法：*\n在应用文件比如说manage.py中设置：\n> app.config[\'SQLALCHEMY_TRACK_MODIFICATIONS\'] = True',1,'flask',1467036252,0,56,0,1,1),(44,'sqlalchemy常见查询','&lt;h1&gt;简单查询&lt;/h1&gt;\n<blockquote>\n<p>print(session.query(User).all())\nprint(session.query(<a href=\"http://User.name\" rel=\"nofollow\">User.name</a>, User.fullname).all())\nprint(session.query(User, <a href=\"http://User.name\" rel=\"nofollow\">User.name</a>).all())</p>\n</blockquote>\n&lt;hr&gt;\n\n&lt;h1&gt;带条件查询&lt;/h1&gt;\n<blockquote>\n<p>print(session.query(User).filter_by(name=\'user1\').all())\nprint(session.query(User).filter(<a href=\"http://User.name\" rel=\"nofollow\">User.name</a> == \"user\").all())\nprint(session.query(User).filter(User.name.like(\"user%\")).all())</p>\n</blockquote>\n&lt;hr&gt;\n\n&lt;h1&gt;多条件查询&lt;/h1&gt;\n<blockquote>\n&lt;p&gt;print(session.query(User).filter(and_(User.name.like(\"user%\"),User.fullname.like(\"first%\")).all())&lt;/p&gt;\n&lt;p&gt;print(session.query(User).filter(or_(User.name.like(\"user%\"), User.password != None)).all())&lt;/p&gt;\n</blockquote>\n&lt;hr&gt;\n\n&lt;h1&gt;sql过滤&lt;/h1&gt;\n<blockquote>\n&lt;p&gt;print(session.query(User).filter(\"id&gt;:id\").params(id=1).all())&lt;/p&gt;\n</blockquote>\n&lt;hr&gt;\n\n&lt;h1&gt;关联查询&lt;/h1&gt;\n<blockquote>\n<p>print(session.query(User, Address).filter(<a href=\"http://User.id\" rel=\"nofollow\">User.id</a> == Address.user_id).all())\nprint(session.query(User).join(User.addresses).all())\nprint(session.query(User).outerjoin(User.addresses).all())</p>\n</blockquote>\n&lt;hr&gt;\n\n&lt;h1&gt;聚合查询&lt;/h1&gt;\n<blockquote>\n<p>print(session.query(<a href=\"http://User.name\" rel=\"nofollow\">User.name</a>,func.count(\'*\').label(\"user_count\")).group_by(<a href=\"http://User.name\" rel=\"nofollow\">User.name</a>).all())</p>\n<p>print(session.query(<a href=\"http://User.name\" rel=\"nofollow\">User.name</a>,func.sum(<a href=\"http://User.id\" rel=\"nofollow\">User.id</a>).label(\"user_id_sum\")).group_by(<a href=\"http://User.name\" rel=\"nofollow\">User.name</a>).all())</p>\n</blockquote>\n&lt;hr&gt;\n\n&lt;h1&gt;子查询&lt;/h1&gt;\n<blockquote>\n<p>stmt =session.query(Address.user_id,func.count(\'*\').label(\"address_count\")).\ngroup_by(Address.user_id).subquery()</p>\n<p>print(session.query(User, stmt.c.address_count).outerjoin((stmt, <a href=\"http://User.id\" rel=\"nofollow\">User.id</a> == stmt.c.user_id)) .order_by(<a href=\"http://User.id\" rel=\"nofollow\">User.id</a>).all())</p>\n</blockquote>\n&lt;hr&gt;\n\n&lt;h1&gt;exists&lt;/h1&gt;\n<blockquote>\n<p>print(session.query(User).filter(exists().where(Address.user_id == <a href=\"http://User.id\" rel=\"nofollow\">User.id</a>)))\nprint(session.query(User).filter(User.addresses.any()))</p>\n</blockquote>\n&lt;hr&gt;\n\n&lt;h1&gt;限制返回字段查询&lt;/h1&gt;\n<blockquote>\n<p>person = session.query(<a href=\"http://Person.name\" rel=\"nofollow\">Person.name</a>, Person.created_at,                    Person.updated_at).filter_by(name=\"zhongwei\").order_by(Person.created_at).first()</p>\n</blockquote>\n&lt;hr&gt;\n\n&lt;h1&gt;记录总数查询：&lt;/h1&gt;\n<blockquote>\n<p>from sqlalchemy import func\n<br>\n# count User records, without\n<br>\n# using a subquery.\n<br>\nsession.query(func.count(<a href=\"http://User.id\" rel=\"nofollow\">User.id</a>))\n<br>\n# return count of user \"id\" grouped\n<br>\n# by \"name\"\n<br>\nsession.query(func.count(<a href=\"http://User.id\" rel=\"nofollow\">User.id</a>)).group_by(<a href=\"http://User.name\" rel=\"nofollow\">User.name</a>)\nfrom sqlalchemy import distinct\n<br>\n# count distinct \"name\" values\n<br>\nsession.query(func.count(distinct(<a href=\"http://User.name\" rel=\"nofollow\">User.name</a>)))</p>\n</blockquote>\n&lt;p&gt;文章出处来源：<a href=\"http://my.oschina.net/freegeek/blog/222725\" rel=\"nofollow\">此处</a> &lt;/p&gt;','#简单查询\n>print(session.query(User).all())\nprint(session.query(User.name, User.fullname).all())\nprint(session.query(User, User.name).all())\n\n<hr>\n\n#带条件查询\n>print(session.query(User).filter_by(name=\'user1\').all())\nprint(session.query(User).filter(User.name == \"user\").all())\nprint(session.query(User).filter(User.name.like(\"user%\")).all())\n\n\n<hr>\n\n#多条件查询\n\n>print(session.query(User).filter(and_(User.name.like(\"user%\"),User.fullname.like(\"first%\")).all())\n\n\n>print(session.query(User).filter(or_(User.name.like(\"user%\"), User.password != None)).all())\n\n<hr>\n\n#sql过滤\n\n>print(session.query(User).filter(\"id>:id\").params(id=1).all())\n\n<hr>\n\n#关联查询 \n\n>print(session.query(User, Address).filter(User.id == Address.user_id).all())\nprint(session.query(User).join(User.addresses).all())\nprint(session.query(User).outerjoin(User.addresses).all())\n\n<hr>\n\n#聚合查询\n> print(session.query(User.name,func.count(\'*\').label(\"user_count\")).group_by(User.name).all())\n\n>print(session.query(User.name,func.sum(User.id).label(\"user_id_sum\")).group_by(User.name).all())\n\n<hr>\n\n#子查询\n>stmt =session.query(Address.user_id,func.count(\'*\').label(\"address_count\")).\ngroup_by(Address.user_id).subquery()\n\n>print(session.query(User, stmt.c.address_count).outerjoin((stmt, User.id == stmt.c.user_id)) .order_by(User.id).all())\n\n<hr>\n\n#exists\n>print(session.query(User).filter(exists().where(Address.user_id == User.id)))\nprint(session.query(User).filter(User.addresses.any()))\n\n<hr>\n\n# 限制返回字段查询\n> person = session.query(Person.name, Person.created_at,                    Person.updated_at).filter_by(name=\"zhongwei\").order_by(Person.created_at).first()\n\n<hr>\n\n#记录总数查询：\n\n>from sqlalchemy import func\n<br>\n>\\# count User records, without\n<br>\n>\\# using a subquery.\n<br>\nsession.query(func.count(User.id))\n<br>\n>\\# return count of user \"id\" grouped\n<br>\n\\# by \"name\"\n<br>\nsession.query(func.count(User.id)).group_by(User.name)\nfrom sqlalchemy import distinct\n<br>\n\\# count distinct \"name\" values\n<br>\nsession.query(func.count(distinct\\(User.name\\)))\n\n\n文章出处来源：[此处](http://my.oschina.net/freegeek/blog/222725) ',1,'sqlalchemy',1467099389,0,220,0,1,1),(45,'查看oracle数据库的编码及修改编码格式的方法(转)','&lt;p&gt;<strong> 首先查看oracle数据库的编码 </strong>&lt;/p&gt;\n<blockquote>\n&lt;p&gt;SQL&gt; select * from nls_database_parameters where parameter =\'NLS_CHARACTERSET\';&lt;/p&gt;\n</blockquote>\n&lt;p&gt;<em>PARAMETEr: NLS_CHARACTERSET</em>&lt;/p&gt;\n&lt;p&gt;<em>VALUE: AL32UTF8</em>&lt;/p&gt;\n&lt;p&gt;这其来源于props$，这是表示数据库的字符集。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;<strong> oracle客户端编码 </strong>&lt;/p&gt;\n<blockquote>\n&lt;p&gt;SQL&gt; select * from nls_instance_parameters where parameter=\'NLS_LANGUAGE\';&lt;/p&gt;\n</blockquote>\n&lt;p&gt;<em>PARAMETER: NLS_LANGUAGE</em>&lt;/p&gt;\n&lt;p&gt;<em>VALUE: SIMPLIFIED CHINESE</em>&lt;/p&gt;\n&lt;p&gt;其来源于v$parameter，表示客户端的字符集的设置，可能是参数文件，环境变量或者是注册表会话字符集环境&lt;/p&gt;\n&lt;p&gt;select * from nls_session_parameters，其来源于v$nls_parameters，表示会话自己的设置，可能是会话的环境变量或者是alter session完成，如果会话没有特殊的设置，将与nls_instance_parameters一致。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;<strong> 再来说一下怎么修改oracle的字符集：</strong>&lt;/p&gt;\n&lt;p&gt;目前我的数据库环境的字符集是AL32UTF8，那么把它改成ZHS16GBK&lt;/p&gt;\n&lt;p&gt;1.首先以sysdba的身份登录上去 conn /as sysdba&lt;/p&gt;\n&lt;p&gt;2.关闭数据库shutdown immediate;&lt;/p&gt;\n&lt;p&gt;3.以mount打来数据库，startup mount&lt;/p&gt;\n&lt;p&gt;4.设置session&lt;/p&gt;\n<blockquote>\n&lt;p&gt;SQL&gt;ALTER SYSTEM ENABLE RESTRICTED SESSION;&lt;/p&gt;\n&lt;p&gt;SQL&gt; ALTER SYSTEM SET JOB_QUEUE_PROCESSES=0;&lt;/p&gt;\n&lt;p&gt;SQL&gt; ALTER SYSTEM SET AQ_TM_PROCESSES=0;&lt;/p&gt;\n</blockquote>\n&lt;p&gt;5.启动数据库&lt;/p&gt;\n<blockquote>\n&lt;p&gt;alter database open;&lt;/p&gt;\n</blockquote>\n&lt;p&gt;6.修改字符集&lt;/p&gt;\n<blockquote>\n&lt;p&gt;ALTER DATABASE CHARACTER SET ZHS16GBK;&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这会可能会报错，提示我们的字符集：新字符集必须为旧字符集的超集，这时我们可以跳过超集的检查做更改：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;ALTER DATABASE character set INTERNAL_USE ZHS16GBK;&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这条语句就可以了，TERNAL_USE提供的帮助就会使oracle绕过了子集与超集的验证，这条语句和上面的语句内部操作时完全相同的。&lt;/p&gt;\n&lt;p&gt;7.关闭，重新启动&lt;/p&gt;\n<blockquote>\n&lt;p&gt;SQL&gt;shutdown immediate;\nSQL&gt; startup&lt;/p&gt;\n</blockquote>\n&lt;p&gt;当然字符集最好不要轻易修改，因为这会对数据库的数据有直接的影响，如果是生产环境的话，可能会造成不可估计得损失。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;<strong> oracle数据库更改默认编码的语句是什？</strong>\nOracle 在安装过程中会要求选择编码方式\n选择之后不可更改\n只能更改PL-SQL的编码方式&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;<strong> 怎更改Oracle的编码格式  </strong>&lt;/p&gt;\n&lt;p&gt;utf8:&lt;/p&gt;\n&lt;p&gt;ALTER DATABASE <code>数据库</code> DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci &lt;/p&gt;\n&lt;p&gt;ALTER TABLE <code>数据表</code> DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci &lt;/p&gt;\n&lt;p&gt;gbk (包含gb2312):&lt;/p&gt;\n&lt;p&gt;ALTER DATABASE <code>数据库</code> DEFAULT CHARACTER SET gbk COLLATE gbk_chinese_ci &lt;/p&gt;\n&lt;p&gt;ALTER TABLE <code>数据表</code> DEFAULT CHARACTER SET gbk COLLATE gbk_chinese_ci&lt;/p&gt;\n&lt;p&gt;来源：<a href=\"http://www.bkjia.com/oracle/854332.html\" rel=\"nofollow\">此处</a>&lt;/p&gt;','** 首先查看oracle数据库的编码 **\n\n> SQL> select * from nls_database_parameters where parameter =\'NLS_CHARACTERSET\';\n\n\n*PARAMETEr: NLS_CHARACTERSET*\n\n*VALUE: AL32UTF8*\n\n\n这其来源于props$，这是表示数据库的字符集。\n\n<hr>\n\n** oracle客户端编码 **\n\n>SQL> select * from nls_instance_parameters where parameter=\'NLS_LANGUAGE\';\n\n*PARAMETER: NLS_LANGUAGE*\n\n*VALUE: SIMPLIFIED CHINESE*\n\n其来源于v$parameter，表示客户端的字符集的设置，可能是参数文件，环境变量或者是注册表会话字符集环境\n\nselect * from nls_session_parameters，其来源于v$nls_parameters，表示会话自己的设置，可能是会话的环境变量或者是alter session完成，如果会话没有特殊的设置，将与nls_instance_parameters一致。\n\n<hr>\n\n** 再来说一下怎么修改oracle的字符集：**\n\n目前我的数据库环境的字符集是AL32UTF8，那么把它改成ZHS16GBK\n\n1.首先以sysdba的身份登录上去 conn /as sysdba\n\n2.关闭数据库shutdown immediate;\n\n3.以mount打来数据库，startup mount\n\n4.设置session\n\n>SQL>ALTER SYSTEM ENABLE RESTRICTED SESSION;\n\n>SQL> ALTER SYSTEM SET JOB_QUEUE_PROCESSES=0;\n\n>SQL> ALTER SYSTEM SET AQ_TM_PROCESSES=0;\n\n5.启动数据库\n\n>alter database open;\n\n6.修改字符集\n\n>ALTER DATABASE CHARACTER SET ZHS16GBK;\n\n这会可能会报错，提示我们的字符集：新字符集必须为旧字符集的超集，这时我们可以跳过超集的检查做更改：\n\n>ALTER DATABASE character set INTERNAL_USE ZHS16GBK;\n\n这条语句就可以了，TERNAL_USE提供的帮助就会使oracle绕过了子集与超集的验证，这条语句和上面的语句内部操作时完全相同的。\n\n7.关闭，重新启动\n\n>SQL>shutdown immediate;\nSQL> startup\n\n当然字符集最好不要轻易修改，因为这会对数据库的数据有直接的影响，如果是生产环境的话，可能会造成不可估计得损失。\n\n<hr>\n\n** oracle数据库更改默认编码的语句是什？**\nOracle 在安装过程中会要求选择编码方式\n选择之后不可更改\n只能更改PL-SQL的编码方式\n \n<hr>\n\n** 怎更改Oracle的编码格式  **\n\nutf8:\n\nALTER DATABASE `数据库` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci \n\nALTER TABLE `数据表` DEFAULT CHARACTER SET utf8 COLLATE utf8_general_ci \n\ngbk (包含gb2312):\n\nALTER DATABASE `数据库` DEFAULT CHARACTER SET gbk COLLATE gbk_chinese_ci \n\nALTER TABLE `数据表` DEFAULT CHARACTER SET gbk COLLATE gbk_chinese_ci\n\n\n来源：[此处](http://www.bkjia.com/oracle/854332.html)',1,'oracle',1467100818,0,76,0,1,1),(46,'windows的flask部署方案一：flask+nginx','&lt;h3&gt;前言&lt;/h3&gt;\n&lt;p&gt;前段时间用flask重构了个人博客系统，所以需要部署到云服务器上。由于服务器用的是winserver2012,而win平台下关于flask和nginx的配置说明并不多，所以把过程记录下来，或许对别人有帮助，这篇文章也参考了另外一位网友的<a href=\"http://www.christiansheng.com/?p=192\" rel=\"nofollow\">文章</a>&lt;/p&gt;\n&lt;h3&gt;部署环境&lt;/h3&gt;\n<ul>\n<li>winserver2012/win10</li>\n<li>python3.5</li>\n<li>nginx1.6.3</li>\n<li>tornado</li>\n</ul>\n&lt;h3&gt;过程&lt;/h3&gt;\n&lt;p&gt;1.下载及配置<strong>nginx</strong>&lt;/p&gt;\n&lt;p&gt;直接在<a href=\"http://nginx.org/en/download.html\" rel=\"nofollow\">nginx官网</a>即可下载到nginx服务器，我用的版本是1.6.3.下载后直接把它解压,文件夹重命名为<em>nginx</em>,然后把它放到c盘根目录下。启动nginx的方法：我发现直接把<em>nginx.exe</em>拖拽到命令行执行会报错：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;nginx: [alert] could not open error log file: CreateFile() \"logs/error.log\" failed (3: The  system cannot find the path specified)&lt;/p&gt;\n&lt;p&gt;2016/06/29 13:24:02  [emerg] 9040#12584: CreateFile() \"C:\\Users\\rookiecoder/conf/nginx.conf\" failed (3: The system cannot find the path specified)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;正确的做法是:先切换到c盘的nginx文件夹下，再直接运行nginx.exe,命令如下：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;cd C:/nginx\n&lt;br&gt;\nnginx.exe&lt;/p&gt;\n</blockquote>\n&lt;p&gt;如果启动不报错，那么说明nginx启动成功&lt;/p&gt;\n&lt;p&gt;再编辑配置文件<em>C:/nginx/conf/nginx.conf</em>,搜索<strong>http{}</strong>,在http{}中加入如下配置信息：\n&lt;pre&gt;<code>\nupstream testserver {\n　　server 127.0.0.1:5000;\n　　# server 127.0.0.1:5001;\n　　# server 127.0.0.1:5002;\n　　# ...\n　　# 可加入多个，由 nginx 负责负载均衡\n}\nserver {\n　　listen 80;\n　　# 这里填写你自己的域名(或者ip)\n　　server_name <a href=\"http://www.rookiefly.me\" rel=\"nofollow\">www.rookiefly.me</a>;\n　　charset utf-8;\n　　location / {\n　　proxy_pass http://testserver;\n　　proxy_set_header X-Real-IP $remote_addr;\n　　proxy_pass_header Set-Cookie;\n　}\n }\n</code>&lt;/pre&gt;\n保存后再启动nginx，如果不报错说明配置成功。&lt;/p&gt;\n&lt;p&gt;2.用<strong>tornado</strong>架起<strong>flask app</strong>&lt;/p&gt;\n&lt;p&gt;如果你没有安装tornado,那么先安装它：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;pip install tornado&lt;/p&gt;\n</blockquote>\n&lt;p&gt;由于<em>tornado</em>的某些应用使用了pycurl,为了防止出现莫名其妙的bug，推荐安装:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;pip install pycurl&lt;/p&gt;\n</blockquote>\n&lt;p&gt;在你的flask app根目录中，新建一个py文件，这里命令为<strong><a href=\"http://home.py\" rel=\"nofollow\">home.py</a></strong>\n写入如下代码：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;import sys\n&lt;br&gt;\nfrom tornado.wsgi import WSGIContainer\n&lt;br&gt;\nfrom tornado.httpserver import HTTPServer\n&lt;br&gt;\nfrom tornado.ioloop import IOLoop\n&lt;br&gt;\nfrom run import app\n&lt;br&gt;\nif len(sys.argv) == 2:\n&lt;br&gt;\n　　port = sys.argv[1]\n  &lt;br&gt;\nelse:\n&lt;br&gt;\n　　port = 5000\n  &lt;br&gt;&lt;/p&gt;\n&lt;p&gt;http_server = HTTPServer(WSGIContainer(app))\n&lt;br&gt;\nhttp_server.listen(port)\n&lt;br&gt;\nIOLoop.instance().start()&lt;/p&gt;\n</blockquote>\n&lt;p&gt;我这里的<strong>run</strong>是我的博客系统(我的博客系统github地址:<a href=\"https://github.com/ResolveWang/myblog\" rel=\"nofollow\">此处</a>)的主入口文件\nrun.py的代码如下：&lt;/p&gt;\n&lt;pre&gt;\nfrom app.views import app\nif __name__ == \'__main__\':\n　　app.run(host=\'0.0.0.0\')\n&lt;/pre&gt;\n\n&lt;p&gt;3.开启nginx服务器，运行flask app&lt;/p&gt;\n<blockquote>\n<p>cd C:/nginx\n<br>\nnginx.exe\n<br>\npython <a href=\"http://home.py\" rel=\"nofollow\">home.py</a></p>\n</blockquote>\n<p>4.访问\n直接在浏览器输入www.rookiefly.me进行访问，成功！</p>\n<p>ps:后面我又想让让后台管理系统配置到nginx服务器上，由于博客的前台和后台都是使用flask写的，路由有冲突，所以需要nginx监听不同端口(前台为5000，后台为10000),如果像上面配置那样，nginx映射的端口都为80，就不能区分到底是前台还是后台的请求了。所以配置需要改成如下：</p>\n<pre>http {\n    include       mime.types;\n    default_type  application/octet-stream;\n    keepalive_timeout  65;\n    upstream home{\n        server 127.0.0.1:5000;\n    }\n    upstream admin{\n        server 127.0.0.1:10000;\n    }\n\n    server {\n        listen       80;\n        server_name  <a href=\"http://www.rookiefly.me\" rel=\"nofollow\">www.rookiefly.me</a>;\n        charset utf-8;\n        #access_log  logs/host.access.log  main;\n        location / {\n            proxy_pass http://home;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_pass_header Set-Cookie;\n        }\n    }\n\n    server {\n        listen       10000;\n        server_name  <a href=\"http://www.rookiefly.me\" rel=\"nofollow\">www.rookiefly.me</a>;\n\n        charset utf-8;\n\n        #access_log  logs/host.access.log  main;\n\n        location / {\n            proxy_pass http://admin;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_pass_header Set-Cookie;\n        }\n    }\n\n}\n</pre>\n\n<p>这样博客前台页面可以直接通过</p><strong><a href=\"http://www.rookiefly.me\" rel=\"nofollow\">www.rookiefly.me</a></strong> 访问了，后台页面需要通过 <strong><a href=\"http://www.rookiefly.me:10000\" rel=\"nofollow\">www.rookiefly.me:10000</a></strong> 进行访问&lt;/p&gt;','### 前言\n前段时间用flask重构了个人博客系统，所以需要部署到云服务器上。由于服务器用的是winserver2012,而win平台下关于flask和nginx的配置说明并不多，所以把过程记录下来，或许对别人有帮助，这篇文章也参考了另外一位网友的[文章](http://www.christiansheng.com/?p=192)\n\n### 部署环境\n- winserver2012/win10\n- python3.5\n- nginx1.6.3\n- tornado\n\n### 过程\n\n1.下载及配置**nginx**\n\n直接在[nginx官网](http://nginx.org/en/download.html)即可下载到nginx服务器，我用的版本是1.6.3.下载后直接把它解压,文件夹重命名为*nginx*,然后把它放到c盘根目录下。启动nginx的方法：我发现直接把*nginx.exe*拖拽到命令行执行会报错：\n>nginx: [alert] could not open error log file: CreateFile() \"logs/error.log\" failed (3: The  system cannot find the path specified)\n\n>2016/06/29 13:24:02  [emerg] 9040#12584: CreateFile() \"C:\\Users\\rookiecoder/conf/nginx.conf\" failed (3: The system cannot find the path specified)\n\n正确的做法是:先切换到c盘的nginx文件夹下，再直接运行nginx.exe,命令如下：\n> cd C:/nginx\n<br>\nnginx.exe\n\n如果启动不报错，那么说明nginx启动成功\n\n再编辑配置文件*C:/nginx/conf/nginx.conf*,搜索**http{}**,在http{}中加入如下配置信息：\n<pre><code>\nupstream testserver {\n　　server 127.0.0.1:5000;\n　　\\# server 127.0.0.1:5001;\n　　\\# server 127.0.0.1:5002;\n　　\\# ...\n　　\\# 可加入多个，由 nginx 负责负载均衡\n}\nserver {\n　　listen 80;\n　　\\# 这里填写你自己的域名(或者ip)\n　　server_name www.rookiefly.me;\n　　charset utf-8;\n　　location / {\n　　proxy_pass http://testserver;\n　　proxy_set_header X-Real-IP $remote_addr;\n　　proxy_pass_header Set-Cookie;\n　}\n }\n</code></pre>\n保存后再启动nginx，如果不报错说明配置成功。\n\n\n2.用**tornado**架起**flask app**\n\n如果你没有安装tornado,那么先安装它：\n>pip install tornado\n\n由于*tornado*的某些应用使用了pycurl,为了防止出现莫名其妙的bug，推荐安装:\n>pip install pycurl\n\n在你的flask app根目录中，新建一个py文件，这里命令为**home.py**\n写入如下代码：\n>import sys\n<br>\nfrom tornado.wsgi import WSGIContainer\n<br>\nfrom tornado.httpserver import HTTPServer\n<br>\nfrom tornado.ioloop import IOLoop\n<br>\nfrom run import app\n<br>\n>if len(sys.argv) == 2:\n<br>\n　　port = sys.argv[1]\n  <br>\nelse:\n<br>\n　　port = 5000\n  <br>\n\n>http_server = HTTPServer(WSGIContainer(app))\n<br>\nhttp_server.listen(port)\n<br>\nIOLoop.instance().start()\n\n我这里的**run**是我的博客系统(我的博客系统github地址:[此处](https://github.com/ResolveWang/myblog))的主入口文件\nrun.py的代码如下：\n\n<pre>\nfrom app.views import app\nif __name__ == \'__main__\':\n　　app.run(host=\'0.0.0.0\')\n</pre>\n\n\n3.开启nginx服务器，运行flask app\n>cd C:/nginx\n<br>\nnginx.exe\n<br>\npython home.py\n\n4.访问\n直接在浏览器输入www.rookiefly.me进行访问，成功！\n\nps:后面我又想让让后台管理系统配置到nginx服务器上，由于博客的前台和后台都是使用flask写的，路由有冲突，所以需要nginx监听不同端口(前台为5000，后台为10000),如果像上面配置那样，nginx映射的端口都为80，就不能区分到底是前台还是后台的请求了。所以配置需要改成如下：\n\n<pre>\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n    keepalive_timeout  65;\n    upstream home{\n        server 127.0.0.1:5000;\n    }\n    upstream admin{\n        server 127.0.0.1:10000;\n    }\n\n    server {\n        listen       80;\n        server_name  www.rookiefly.me;\n        charset utf-8;\n        #access_log  logs/host.access.log  main;\n        location / {\n            proxy_pass http://home;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_pass_header Set-Cookie;\n        }\n    }\n\n    server {\n        listen       10000;\n        server_name  www.rookiefly.me;\n\n        charset utf-8;\n\n        #access_log  logs/host.access.log  main;\n\n        location / {\n            proxy_pass http://admin;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_pass_header Set-Cookie;\n        }\n    }\n\n}\n</pre>\n\n这样博客前台页面可以直接通过**www.rookiefly.me** 访问了，后台页面需要通过 **www.rookiefly.me:10000** 进行访问',1,'flask,nginx',1467180020,0,237,0,1,1),(47,'‘gbk’ codec can’t encode character ‘\\U0001f64f’ in position 10: illegal multibyte sequence的解决方法','&lt;p&gt;今天，在解析新浪微博用户资料的时候，如果个人简介中包含有符号表情，就会出现上述问题，我确定不是我代码的问题，因为我在终端打印用户信息就是正确的，不会产生编码错误，在存的时候就会产生上述编码错误。我初步判断是oracle那边设置的字符集可能是gbk或者gb2312,它并不会识别一些特殊的utf-8字符编码，但是oracle服务器如果要重设字符集必须重启服务，而很多程序都依赖这个数据库，所以重启服务是一个不好的选择。于是，我便产生了一个想法，如果直接忽略个人简介中的表情符号，那么存储数据就不会出现问题了。如何识别哪一个字符不能编码呢？查找过后，看到encode()和decode()方法中带有一个error参数，用于处理不能转换的编码，我把代码改为：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;get_personalinfo.get_detail(source).description.encode(\'gbk\', \'ignore\').decode(\'gbk\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这样直接就忽略了不能使用gbk编码的字符了。\n推荐查看：<a href=\"http://www.crifan.com/unicodeencodeerror_gbk_codec_can_not_encode_character_in_position_illegal_multibyte_sequence/\" rel=\"nofollow\">参考文章</a>&lt;/p&gt;','今天，在解析新浪微博用户资料的时候，如果个人简介中包含有符号表情，就会出现上述问题，我确定不是我代码的问题，因为我在终端打印用户信息就是正确的，不会产生编码错误，在存的时候就会产生上述编码错误。我初步判断是oracle那边设置的字符集可能是gbk或者gb2312,它并不会识别一些特殊的utf-8字符编码，但是oracle服务器如果要重设字符集必须重启服务，而很多程序都依赖这个数据库，所以重启服务是一个不好的选择。于是，我便产生了一个想法，如果直接忽略个人简介中的表情符号，那么存储数据就不会出现问题了。如何识别哪一个字符不能编码呢？查找过后，看到encode()和decode()方法中带有一个error参数，用于处理不能转换的编码，我把代码改为：\n\n> get_personalinfo.get_detail(source).description.encode(\'gbk\', \'ignore\').decode(\'gbk\')\n\n\n这样直接就忽略了不能使用gbk编码的字符了。\n推荐查看：[参考文章](http://www.crifan.com/unicodeencodeerror_gbk_codec_can_not_encode_character_in_position_illegal_multibyte_sequence/)',1,'python',1467363412,0,113,0,1,1),(48,'ubuntu下切换python版本','<ul>\n<li><strong>问题描述：</strong>\nubuntu15.04 中默认就自带了python的2.7版本，我自己安装了一个python3.4的版本，可是如果你不设置环境变量，那么在终端中运行的python都是系统默认的版本，这样就会导致3.4的程序在终端下无法运行，没有办法必须要将默认的python版本换到3.4.</li>\n<li><strong>问题分析：</strong>\n其实在linux系统中多个python版本是可以共存的，只不过在终端中运行的时候，输入 python2.7 或者 python3.4就能进入不同的版本了，而且在你的*.py文件中可以用 ＃!/usr/bin/python  来指定程序的解释器版本，不过这样使用起来有些不方便，所以就把/usr/bin/python这个快捷方式的指向修改下好了。</li>\n<li><strong>解决方法：</strong></li>\n</ul>\n<blockquote>\n&lt;p&gt;sudo cp /usr/bin/python /usr/bin/python_bak，先备份&lt;/p&gt;\n&lt;p&gt;sudo rm /usr/bin/python，删除&lt;/p&gt;\n&lt;p&gt;sudo ln -s /usr/bin/python3.4   /usr/bin/python，默认设置成python3.4&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这样在终端中输入python默认就是 3.4版本了&lt;/p&gt;\n&lt;p&gt;此外，也可以尝试pythonbrew这个python版本管理器，很遗憾的是它已经停止维护了，它的衍生版本pythonz也在github上可以找到，但是我也试过这两个软件，效果并不理想啊&lt;/p&gt;','- **问题描述：**\nubuntu15.04 中默认就自带了python的2.7版本，我自己安装了一个python3.4的版本，可是如果你不设置环境变量，那么在终端中运行的python都是系统默认的版本，这样就会导致3.4的程序在终端下无法运行，没有办法必须要将默认的python版本换到3.4.\n- **问题分析：**\n其实在linux系统中多个python版本是可以共存的，只不过在终端中运行的时候，输入 python2.7 或者 python3.4就能进入不同的版本了，而且在你的*.py文件中可以用 ＃!/usr/bin/python  来指定程序的解释器版本，不过这样使用起来有些不方便，所以就把/usr/bin/python这个快捷方式的指向修改下好了。\n- **解决方法：**\n\n> sudo cp /usr/bin/python /usr/bin/python_bak，先备份\n\n> sudo rm /usr/bin/python，删除\n\n> sudo ln -s /usr/bin/python3.4   /usr/bin/python，默认设置成python3.4\n\n这样在终端中输入python默认就是 3.4版本了\n\n此外，也可以尝试pythonbrew这个python版本管理器，很遗憾的是它已经停止维护了，它的衍生版本pythonz也在github上可以找到，但是我也试过这两个软件，效果并不理想啊',1,'python',1467363478,0,98,0,1,1),(49,'Python第三方库的安装技巧','&lt;p&gt;相信大家对于pip install和easy install的方式安装python第三方库都比较熟悉了吧，这里我就说这两种安装方式了，说一说另外一种比较好的方式,比如当用pip安装的时候撞墙了就可以用此方法。\n首先，介绍一个网址：<strong><a href=\"http://www.lfd.uci.edu/~gohlke/pythonlibs/\" rel=\"nofollow\">http://www.lfd.uci.edu/~gohlke/pythonlibs/</a></strong>,这是加州大学 欧文分校的Christoph Gohlke提供的大量python非官方 插件模块安装包。这里以安装scrapy为例，因为安装scrapy的时候很多朋友都会碰到unable to find vcvarsall.bat这个错误。最简单的方法就是直接在该网站下载已经编译好的scrapy包，在网页通过ctrl+f搜索关键词Scrapy(注意大小写)，然后下载后缀为.whl的压缩文件，下载下来之后将文件后缀改为.zip,然后解压，会得到一个叫scrapy的文件夹，这个文件夹就是我们需要的scrapy框架了，直接打开python的安装目录，找到Lib文件夹，将scrapy文件夹拷进去就可以用了。这样是不是方便了很多\n在知乎上又看到一种方法，以安装lxml为例：\n<strong><a href=\"http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml\" rel=\"nofollow\">http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml</a></strong>\nCtrl + F，输入lxml，找到下面这段&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Lxml, a binding for the libxml2 and libxslt libraries.\nlxml?3.4.4?cp27?none?win32.whl\nlxml?3.4.4?cp27?none?win_amd64.whl\nlxml?3.4.4?cp33?none?win32.whl\nlxml?3.4.4?cp33?none?win_amd64.whl\nlxml?3.4.4?cp34?none?win32.whl\nlxml?3.4.4?cp34?none?win_amd64.whl\nlxml?3.4.4?cp35?none?win32.whl\nlxml?3.4.4?cp35?none?win_amd64.whl&lt;/p&gt;\n</blockquote>\n&lt;p&gt;cp后面是Python的版本号，27表示2.7，根据你的Python版本选择下载。\n进入.whl所在的文件夹，执行命令即可完成安装&lt;/p&gt;\n<blockquote>\n&lt;p&gt;pip install 带后缀的完整文件名&lt;/p&gt;\n</blockquote>\n&lt;p&gt;PS：后来我发现可以先安装一个叫wheel的扩展，直接用pip就能安装.whl文件了&lt;/p&gt;\n<blockquote>\n&lt;p&gt;pip install wheel\npip install lxml?3.4.4?cp35?none?win_amd64.whl&lt;/p&gt;\n</blockquote>','相信大家对于pip install和easy install的方式安装python第三方库都比较熟悉了吧，这里我就说这两种安装方式了，说一说另外一种比较好的方式,比如当用pip安装的时候撞墙了就可以用此方法。\n首先，介绍一个网址：**http://www.lfd.uci.edu/~gohlke/pythonlibs/**,这是加州大学 欧文分校的Christoph Gohlke提供的大量python非官方 插件模块安装包。这里以安装scrapy为例，因为安装scrapy的时候很多朋友都会碰到unable to find vcvarsall.bat这个错误。最简单的方法就是直接在该网站下载已经编译好的scrapy包，在网页通过ctrl+f搜索关键词Scrapy(注意大小写)，然后下载后缀为.whl的压缩文件，下载下来之后将文件后缀改为.zip,然后解压，会得到一个叫scrapy的文件夹，这个文件夹就是我们需要的scrapy框架了，直接打开python的安装目录，找到Lib文件夹，将scrapy文件夹拷进去就可以用了。这样是不是方便了很多\n在知乎上又看到一种方法，以安装lxml为例：\n**http://www.lfd.uci.edu/~gohlke/pythonlibs/#lxml**\nCtrl + F，输入lxml，找到下面这段\n>Lxml, a binding for the libxml2 and libxslt libraries.\nlxml?3.4.4?cp27?none?win32.whl\nlxml?3.4.4?cp27?none?win_amd64.whl\nlxml?3.4.4?cp33?none?win32.whl\nlxml?3.4.4?cp33?none?win_amd64.whl\nlxml?3.4.4?cp34?none?win32.whl\nlxml?3.4.4?cp34?none?win_amd64.whl\nlxml?3.4.4?cp35?none?win32.whl\nlxml?3.4.4?cp35?none?win_amd64.whl\n\ncp后面是Python的版本号，27表示2.7，根据你的Python版本选择下载。\n进入.whl所在的文件夹，执行命令即可完成安装\n>pip install 带后缀的完整文件名\n\nPS：后来我发现可以先安装一个叫wheel的扩展，直接用pip就能安装.whl文件了\n>pip install wheel\npip install lxml?3.4.4?cp35?none?win_amd64.whl',1,'python',1467363628,0,58,0,1,1),(50,'在utuntu15.04下安装github(转)','&lt;p&gt;Github在mac和win上面都有图形化安装工具，而在linux下面却是以命令行的方式安装，utuntu下面安装方式如下：&lt;/p&gt;\n&lt;p&gt;<strong>1.安装SSH key…</strong>\n你已经在github创建了用户，并想从你的终端操作工作。&lt;/p&gt;\n&lt;p&gt;(1)在开始安装GitHub之前, 你应该<strong>安装ssh keys</strong>:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;cd ~/.ssh&lt;/p&gt;\n</blockquote>\n&lt;p&gt;回车之后得到信息： <strong>“bash: cd: ./.ssh No such file or directory” </strong>, 那就意味着没有产生key, 就要继续操作第（２）步。 如果你能够切换到此目录， 继续第（３）步。&lt;/p&gt;\n&lt;p&gt;(2)打开你的终端并打入：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;ssh-keygen -t rsa -C “your_email@youremail.com（这里填你自己github的邮箱）”&lt;/p&gt;\n</blockquote>\n&lt;p&gt;你将获取到以下的行：<strong>“产生 公共/私有(public/private) rsa 密匙配对”</strong>。 打入文件来保存密匙<strong>（/Home/ubuntu/.ssh_id_rsa）</strong>: 现在回车，它会询问你打入通行码，此通行码必须大于4位， 否则你将重新所有的过程。&lt;/p&gt;\n&lt;p&gt;<strong>重要一步： 添加新的Key到ssh-agent</strong>&lt;/p&gt;\n<blockquote>\n&lt;p&gt;eval “$(ssh-agent -s)”\n$ ssh-add ~/.ssh/id_rsa&lt;/p&gt;\n</blockquote>\n&lt;p&gt;(3)备份并移除存在的ssh keys, 敲入 “ls” 会显示一些文件，现在一个一个敲入以下的命令：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;$mkdir key_backup\n$cp id_rsa<em> key_backup\n$rm id_rsa</em>&lt;/p&gt;\n</blockquote>\n&lt;p&gt;(4)添加你的ssh key 到 Github&lt;/p&gt;\n<blockquote>\n&lt;p&gt;gedit id_rsa.pub&lt;/p&gt;\n</blockquote>\n&lt;p&gt;如果这一步打开为空文件，那么就退出，切换到key_backup目录:cd key_backup/,再执行gedit id_rsa.pub\n拷贝全部的内容，打开github网站并登录， 进入到”Account Settings” &gt; 点击 “SSH Public Keys” &gt; 点击”Add another public key” 并粘贴到”key field”，title名字自己随意取，然后点击Add key.\n现在你已经成功安装了ssh key 并准备在终端安装github.&lt;/p&gt;\n&lt;p&gt;<strong>2. 安装github</strong>\n在你的终端打入下面命令&lt;/p&gt;\n<blockquote>\n&lt;p&gt;$sudo apt-get install git-core git-gui git-doc&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这时会询问你是否安装，<strong>选择“Ｙ”</strong>就可以了&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;使用git工作（简单介绍，具体的命令自己查询）&lt;/p&gt;\n&lt;p&gt;克隆：\n在终端敲入： &lt;/p&gt;\n<blockquote>\n&lt;p&gt;$git clone git@github.com:username/projectname.git &lt;/p&gt;\n</blockquote>\n&lt;p&gt;来下载分支代码的一个本地拷贝。你将需要你自己的GitHub 用户名和在github上的工程名取代“username”和“projectname”。&lt;/p&gt;\n&lt;p&gt;配置git:\n使用自己的用户名和email地址安装git&lt;/p&gt;\n<blockquote>\n<p>git config –global <a href=\"http://user.name\" rel=\"nofollow\">user.name</a> “Your Name”\ngit config –global user.email “your@email.com”</p>\n</blockquote>\n&lt;p&gt;其它命令就不详细讲解了，这里主要是讲的安装过程，主要就是安装ssh　key,然后即可安装github&lt;/p&gt;','Github在mac和win上面都有图形化安装工具，而在linux下面却是以命令行的方式安装，utuntu下面安装方式如下：\n\n**1.安装SSH key…**\n你已经在github创建了用户，并想从你的终端操作工作。\n\n(1)在开始安装GitHub之前, 你应该**安装ssh keys**:\n>cd ~/.ssh\n\n回车之后得到信息： **“bash: cd: ./.ssh No such file or directory” **, 那就意味着没有产生key, 就要继续操作第（２）步。 如果你能够切换到此目录， 继续第（３）步。\n\n(2)打开你的终端并打入：\n>ssh-keygen -t rsa -C “your_email@youremail.com（这里填你自己github的邮箱）”\n\n你将获取到以下的行：**“产生 公共/私有(public/private) rsa 密匙配对”**。 打入文件来保存密匙**（/Home/ubuntu/.ssh_id_rsa）**: 现在回车，它会询问你打入通行码，此通行码必须大于4位， 否则你将重新所有的过程。\n\n**重要一步： 添加新的Key到ssh-agent**\n>eval “$(ssh-agent -s)”\n$ ssh-add ~/.ssh/id_rsa\n\n(3)备份并移除存在的ssh keys, 敲入 “ls” 会显示一些文件，现在一个一个敲入以下的命令：\n>$mkdir key_backup\n$cp id_rsa* key_backup\n$rm id_rsa*\n\n(4)添加你的ssh key 到 Github\n>gedit id_rsa.pub\n\n如果这一步打开为空文件，那么就退出，切换到key_backup目录:cd key_backup/,再执行gedit id_rsa.pub\n拷贝全部的内容，打开github网站并登录， 进入到”Account Settings” > 点击 “SSH Public Keys” > 点击”Add another public key” 并粘贴到”key field”，title名字自己随意取，然后点击Add key.\n现在你已经成功安装了ssh key 并准备在终端安装github.\n\n**2. 安装github**\n在你的终端打入下面命令\n>$sudo apt-get install git-core git-gui git-doc\n\n这时会询问你是否安装，**选择“Ｙ”**就可以了\n\n<hr>\n\n使用git工作（简单介绍，具体的命令自己查询）\n\n克隆：\n在终端敲入： \n>$git clone git@github.com:username/projectname.git \n\n来下载分支代码的一个本地拷贝。你将需要你自己的GitHub 用户名和在github上的工程名取代“username”和“projectname”。\n\n配置git:\n使用自己的用户名和email地址安装git\n>git config –global user.name “Your Name”\ngit config –global user.email “your@email.com”\n\n其它命令就不详细讲解了，这里主要是讲的安装过程，主要就是安装ssh　key,然后即可安装github',1,'git,github',1467364051,0,59,0,1,1),(51,'utuntu下添加软件启动图标','&lt;p&gt;有的软件在安装后找不到启动图标，这时候可以通过下面方式进行添加：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;cd /usr/share/applications&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这里我以pycharm为例，先建立一个.desktop文件（注意必须要管理员权限)：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;sudo gedit pycharm.desktop&lt;/p&gt;\n</blockquote>\n<p>然后在打开的文件中输入以下文字：</p>\n<pre>[Desktop Entry]\nType=Application\nName=Pycharm\nGenericName=Pycharm3\nComment=Pycharm3:The Python IDE\nExec=\"/home/rookiefly/program/linux安装软件/pycharm-5.0.2/bin/<a href=\"http://pycharm.sh\" rel=\"nofollow\">pycharm.sh</a>\" %f\nIcon=/home/rookiefly/program/linux安装软件/pycharm-5.0.2/bin/pycharm.png\nTerminal=pycharm\nCategories=Pycharm;\n</pre>\n\n<p>这里我做一下说明：其中Name和GenericName,Comment,Terminal，Categoriges都不是很重要的信息，可以根据你的软件名字来填写，</p><strong>Type填法固定为Application,而Exec=“”这里填写软件可执行文件(*.sh)的绝对路径，Icon就是填写软件图标的绝对路径</strong>，填写完成保存<strong>.desktop文件</strong>\n最后一步，将.desktop文件改成可执行文件&lt;/p&gt;\n<blockquote>\n&lt;p&gt;sudo chmod +x Pycharm.desktop&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这样就能在启动器中找到它的快捷方式了&lt;/p&gt;','有的软件在安装后找不到启动图标，这时候可以通过下面方式进行添加：\n\n> cd /usr/share/applications\n\n这里我以pycharm为例，先建立一个.desktop文件（注意必须要管理员权限)：\n\n> sudo gedit pycharm.desktop\n\n然后在打开的文件中输入以下文字：\n\n<pre>\n[Desktop Entry]\nType=Application\nName=Pycharm\nGenericName=Pycharm3\nComment=Pycharm3:The Python IDE\nExec=\"/home/rookiefly/program/linux安装软件/pycharm-5.0.2/bin/pycharm.sh\" %f\nIcon=/home/rookiefly/program/linux安装软件/pycharm-5.0.2/bin/pycharm.png\nTerminal=pycharm\nCategories=Pycharm;\n</pre>\n\n这里我做一下说明：其中Name和GenericName,Comment,Terminal，Categoriges都不是很重要的信息，可以根据你的软件名字来填写，**Type填法固定为Application,而Exec=“”这里填写软件可执行文件(*.sh)的绝对路径，Icon就是填写软件图标的绝对路径**，填写完成保存**.desktop文件**\n最后一步，将.desktop文件改成可执行文件\n\n> sudo chmod +x Pycharm.desktop\n\n这样就能在启动器中找到它的快捷方式了',1,'ubuntu',1467364108,0,58,0,1,1),(52,'常见搜索算法之二分搜索法','&lt;p&gt;先附上二分搜索法的python实现，再具体解释：&lt;/p&gt;\n&lt;pre&gt;\n# if-else嵌套太多了，不够优雅\ndef t_search(sorted_list, x):\n    i = 0\n    j = len(sorted_list)-1\n    while True:\n        # 判断临界点，如果列表中不存在该数，就返回-1\n        if i &gt; j:\n            return -1\n        if (j+i) % 2 == 0:\n            pos = int((j+i)/2)\n        else:\n            pos = int((j+i+1)/2)\n        if sorted_list[pos] == x:\n            return pos\n        else:\n            if sorted_list[pos] &lt; x:\n                i = pos+1\n            else:\n                j = pos-1\n&lt;/pre&gt;\n\n&lt;p&gt;结合上述代码简要说明二分法的思想：&lt;/p&gt;\n&lt;p&gt;先从一个有序数组/列表(sorted_list)之中取出中间那个数sorted_list[pos],如果sorted_list长度为奇数，就可以直接取中间那个数，长度为偶数的话可以取中间偏左也可以取偏右的那个数，这里我取的是偏,和待搜索的数(x)进行比较，如果小于待搜索的数，那么头指针(i)就移动到中间那个数sorted_list[pos]的后面一位，即为i=pos+i+1，如果x &lt; sorted_list[pos],那么就把尾指针j移动到sorted_list[pos]的前一个，即为j=pos-1,如果找到了和x相等的列表中的元素，否则重复这个查找的过程直到列表中所有元素都遍历完了，即为i大于j&lt;/p&gt;','先附上二分搜索法的python实现，再具体解释：\n\n<pre>\n# if-else嵌套太多了，不够优雅\ndef t_search(sorted_list, x):\n    i = 0\n    j = len(sorted_list)-1\n    while True:\n        # 判断临界点，如果列表中不存在该数，就返回-1\n        if i > j:\n            return -1\n        if (j+i) % 2 == 0:\n            pos = int((j+i)/2)\n        else:\n            pos = int((j+i+1)/2)\n        if sorted_list[pos] == x:\n            return pos\n        else:\n            if sorted_list[pos] < x:\n                i = pos+1\n            else:\n                j = pos-1\n</pre>\n\n结合上述代码简要说明二分法的思想：\n\n先从一个有序数组/列表(sorted_list)之中取出中间那个数sorted_list[pos],如果sorted_list长度为奇数，就可以直接取中间那个数，长度为偶数的话可以取中间偏左也可以取偏右的那个数，这里我取的是偏,和待搜索的数(x)进行比较，如果小于待搜索的数，那么头指针(i)就移动到中间那个数sorted_list[pos]的后面一位，即为i=pos+i+1，如果x < sorted_list[pos],那么就把尾指针j移动到sorted_list[pos]的前一个，即为j=pos-1,如果找到了和x相等的列表中的元素，否则重复这个查找的过程直到列表中所有元素都遍历完了，即为i大于j',1,'算法',1467364436,0,66,0,1,1),(53,'windows平台上redis的部署','&lt;p&gt;最近，由于微博爬虫项目需要使用到redis，而开发平台和服务器都是基于windows的。<a href=\"http://www.redis.cn/download.html\" rel=\"nofollow\">Redis官方</a>并没有提供windows平台的版本，只有微软一个开发小组开源了一个基于win平台的实现，并开源在了github上。<strong>点击下载： <a href=\"https://github.com/MSOpenTech/redis/releases\" rel=\"nofollow\">windows版本的redis数据库</a></strong>,我直接下载的是<strong>.msi</strong>文件，下载后直接安装即可。安装过程配置都按默认即可，只是在<strong>选择是否添加入环境变量的时候我勾选了添加</strong>。&lt;/p&gt;\n&lt;p&gt;说了下载和安装，再说说启动redis。windows下redis的启动就是坑爹，如果像我一样是<strong>直接安装的.msi文件</strong>，那么系统<strong>默认redis是以系统服务开启的</strong>，也就是说redis本身就启动了！我们可以在windows的服务列表中看到redis正在运行，并且启动方式是自动。这个时候如果还按照常规方式启动，就会报错：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;[9252] 04 Jul 12:31:44.065 # Creating Server TCP listening socket 127.0.0.1:6379: bind: No error&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这样根本找不到是哪里的问题。如果你不想自动启动redis服务，那么需要将windows服务列表的redis服务的属性一项改为手动启动。这样就可以用常规方式启动了：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;cd /path/redis (切换到redis的安装文件夹)\nredis-server.exe redis.windows.conf (注意这里的redis.windows.conf是redis的配置文件，这个你要<strong>看自己的redis的安装文件夹中到底是叫redis.windows.conf还是叫redis.conf!</strong>)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这样就能在windows上启动redis了！&lt;/p&gt;\n&lt;p&gt;再简单说一下redis的配置：&lt;/p&gt;\n<ul>\n<li>\n&lt;p&gt;绑定ip&lt;/p&gt;\n<blockquote>\n&lt;p&gt;“bind 127.0.0.1″ -&gt; “bind yourip″&lt;/p&gt;\n</blockquote>\n</li>\n<li>\n&lt;p&gt;将磁盘同步改为不同步&lt;/p&gt;\n<blockquote>\n&lt;p&gt;“appendfsync everysec” -&gt; “appendfsync no”&lt;/p&gt;\n</blockquote>\n</li>\n<li>\n&lt;p&gt;连接超时时间&lt;/p&gt;\n<blockquote>\n&lt;p&gt;timeout 300&lt;/p&gt;\n</blockquote>\n</li>\n<li>\n&lt;p&gt;运行级别&lt;/p&gt;\n<blockquote>\n&lt;p&gt;loglevel notice  (个人认为默认的这个就挺好，非出现大异常，不用改为debug )&lt;/p&gt;\n</blockquote>\n</li>\n</ul>\n&lt;p&gt;当然，还有其它配置，具体可以参考<a href=\"http://redis.cn/topics/config.html\" rel=\"nofollow\">redis文档</a>&lt;/p&gt;','最近，由于微博爬虫项目需要使用到redis，而开发平台和服务器都是基于windows的。[Redis官方](http://www.redis.cn/download.html)并没有提供windows平台的版本，只有微软一个开发小组开源了一个基于win平台的实现，并开源在了github上。**点击下载： [windows版本的redis数据库](https://github.com/MSOpenTech/redis/releases)**,我直接下载的是**.msi**文件，下载后直接安装即可。安装过程配置都按默认即可，只是在**选择是否添加入环境变量的时候我勾选了添加**。\n\n说了下载和安装，再说说启动redis。windows下redis的启动就是坑爹，如果像我一样是**直接安装的.msi文件**，那么系统**默认redis是以系统服务开启的**，也就是说redis本身就启动了！我们可以在windows的服务列表中看到redis正在运行，并且启动方式是自动。这个时候如果还按照常规方式启动，就会报错：\n> [9252] 04 Jul 12:31:44.065 # Creating Server TCP listening socket 127.0.0.1:6379: bind: No error\n\n这样根本找不到是哪里的问题。如果你不想自动启动redis服务，那么需要将windows服务列表的redis服务的属性一项改为手动启动。这样就可以用常规方式启动了：\n\n> cd /path/redis (切换到redis的安装文件夹)\n> redis-server.exe redis.windows.conf (注意这里的redis.windows.conf是redis的配置文件，这个你要**看自己的redis的安装文件夹中到底是叫redis.windows.conf还是叫redis.conf!**)\n\n这样就能在windows上启动redis了！\n\n再简单说一下redis的配置：\n\n- 绑定ip\n>“bind 127.0.0.1″ -> “bind yourip″\n\n- 将磁盘同步改为不同步\n> “appendfsync everysec” -> “appendfsync no”\n\n- 连接超时时间\n>timeout 300\n\n- 运行级别\n>loglevel notice  (个人认为默认的这个就挺好，非出现大异常，不用改为debug )\n\n当然，还有其它配置，具体可以参考[redis文档](http://redis.cn/topics/config.html)',1,'redis',1467613337,0,109,0,1,1),(54,'Python操作Redis','&lt;p&gt;<strong>安装redis</strong>\n关于redis在windows的安装，请参照我<a href=\"http://www.rookiefly.me/detail/53\" rel=\"nofollow\">上一篇文章</a>&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;<strong>安装redis的python驱动模块</strong>&lt;/p&gt;\n<blockquote>\n&lt;p&gt;pip install redis&lt;/p&gt;\n</blockquote>\n&lt;hr&gt;\n\n&lt;p&gt;<strong>基本操作</strong>&lt;/p&gt;\n&lt;p&gt;连接到redis,这里数据库为0&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r = redis.Redis(host=\'localhost\',port=6379,db=0)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;<strong>注意，python是不支持select(选择/切换数据库命令的)</strong>&lt;/p&gt;\n&lt;p&gt;key-value数据类型赋值&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.set(\'test\', \'t\') 或者 r[\'test1\'] = 5\nr.getset(\'test\',\'ts\') 存新数据的时候返回上一次存储的数据\nr.incr(\'test1\') 每次执行+1\nr.decr(\'test1\') 每次执行-1&lt;/p&gt;\n</blockquote>\n&lt;p&gt;key-value数据类型取值&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.get(\'test\').decode(\'utf-8\') (如果不进行<strong>decode</strong>，取出来的是<strong>bytes</strong>)\nr.mget(\'test\', \'test1\') 批量取出\nr.keys(\'t<em>\') 取出以key为t</em>形式开头的数据&lt;/p&gt;\n</blockquote>\n&lt;p&gt;随机取出&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.randomkey()   取key\nr.get(randomkey()) 取value&lt;/p&gt;\n</blockquote>\n&lt;p&gt;获取数据库中所有的keys，包括了k-v形式和列表/集合类型等&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.keys()&lt;/p&gt;\n</blockquote>\n&lt;p&gt;当前数据库包含了多少条数据&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.dbsize()&lt;/p&gt;\n</blockquote>\n&lt;p&gt;删除数据&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.delete(\'test\')\nr.delete(\'test\', \'test1\') 批量删除&lt;/p&gt;\n</blockquote>\n&lt;p&gt;根据key查看数据是否存在&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.exists(\'test\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;设置数据过期时间&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.expire(\'test\', 60) 这里设置key=\'test\'的数据过期时间为60s,60s后就不能读取到它的值了\nr.ttl(\'test\') 查看数据过期时间&lt;/p&gt;\n</blockquote>\n&lt;p&gt;key重命名&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.rename(\'test\', \'mytest\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;将数据保存到硬盘&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.save()&lt;/p&gt;\n</blockquote>\n&lt;p&gt;获取上次save时间&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.lastsave()&lt;/p&gt;\n</blockquote>\n&lt;p&gt;清空数据库所有数据&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.flushdb()&lt;/p&gt;\n</blockquote>\n&lt;hr&gt;\n\n&lt;p&gt;<strong>操作list</strong>&lt;/p&gt;\n&lt;p&gt;插入列表,返回列表当前长度&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.lpush(\'mylist\', \'test1\') 从表头插入\nr.rpush(\'mylist\', \'test2\')  从表尾插入&lt;/p&gt;\n</blockquote>\n&lt;p&gt;获取列表的值&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.lindex(\'mylist\', 0).decode(\'utf-8\')  从mylist列表中取出索引为0的元素值&lt;/p&gt;\n</blockquote>\n&lt;p&gt;获取列表长度&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.llen(\'mylist\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;获取列表的部分值，<strong>注意，列表索引从0开始</strong>&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.lrange(\'mylist\', 0, 2)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;从列表删除元素并返回该元素&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.lpop(\'mylist\')  从表头删除\nr.rpop(\'mylist\') 从表尾删除&lt;/p&gt;\n</blockquote>\n&lt;hr&gt;\n\n&lt;p&gt;<strong>排序(set操作)</strong>&lt;/p&gt;\n&lt;p&gt;插入集合,如果插入值已经存在，那么则不会插入，返回实际插入的个数&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.sadd(\'myset\', \'a\')  往myset中插入‘a’\nr.sadd(\'myset\', \'b\',\'c\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;从集合中删除&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.srem(\'myset\', \'a\')\nr.spop(\'myset\') 从myset中随机删除一个元素&lt;/p&gt;\n</blockquote>\n&lt;p&gt;集合大小&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.scard(\'myset\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;判断集合中某个对象是否存在&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.sismember(\'myset\', \'b\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;查看集合所有元素&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.smembers(\'myset\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;求交集,集合myset(\'a\', \'b\' , \'c\') 和 msset(\'a\', \'d\')&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.sinter(\'myset\', \'msset\')\nr.sinterstore(\'interset\', \'myset\', \'msset\') 把myset和msset的交集赋值给新的set: interset&lt;/p&gt;\n</blockquote>\n&lt;p&gt;求并集&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.sunion(\'myset\', \'msset\')\nr.sunionstore(\'unionset\', \'myset\', \'msset\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;求差集&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.sdiff(\'myset\', \'msset\', \'mset\') 求myset有，但是msset和mset没有的元素&lt;/p&gt;\n&lt;p&gt;r.sdiffstore(\'difset\', \'myset\', \'msset\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;排序,下面的参数依次是待排序set,开始的位置，长度，排序字段，是否降序， 是否允许非数字，是否需要存储排序结果(是就存储到store的参数中)&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.sort(\'myset\',start=None,num=None,by=None,get=None,desc=True,alpha=True,store=\'sortedset\')&lt;/p&gt;\n</blockquote>\n&lt;hr&gt;\n\n&lt;p&gt;<strong> 有序set </strong>&lt;/p&gt;\n&lt;p&gt;\'zadd\',\'zcard\',\'zincr\',\'zrange\',\'zrangebyscore\',\'zrem\',\'zscore\' \n分别对应 \n添加, 数量, 自加1,取数据,按照积分(范围)取数据,删除,取积分\n我这里就不多说了，和set用法差不太多&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;<strong> 一些应用技巧和场景 </strong>&lt;/p&gt;\n&lt;p&gt;<em>链式操作</em>, 这样减少了服务器和客户端的反复的TCP数据包，大大提高了批量命令的性能&lt;/p&gt;\n<blockquote>\n&lt;p&gt;p.set(\'hello\',\'redis\').sadd(\'faz\',\'baz\').incr(\'num\').execute()&lt;/p&gt;\n</blockquote>\n&lt;p&gt;<em>页面点击数</em>(点击数特别多，修改特别频繁，如果用关系型数据库存储，可能存在大量的行级锁争用)&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.set(\'totals\', 0)\nr.incr(\'totals\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;<em>使用hash类型保存多样化对象</em>，从关系数据库来解释，就是“表”没有固定的列\n&lt;pre&gt;\n r.hset(\'users:resolvewang\', \'name\', \"John Doe\")\n r.hset(\'users:resolvewang\', \'email\', \'John@test.com\')\n r.hset(\'users:resolvewang\', \'phone\', \'1555313940\')\n # 获取“users:resolvewang”所有键值对，以dict形式返回\n r.hincrby(\'users:resolvewang\', \'visits\', 1)\n # 获取“users:resolvewang”所有键，以list形式返回\n r.hgetall(\'users:resolvewang\')\n&lt;/pre&gt;&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;<em>获取共同特征（求交集）</em>\n例子：在社交网站中，每一个圈子(circle)都有自己的用户群。通过圈子可以找到有共同特征（比如某一体育活动、游戏、电影等爱好者）的人。当一个用户加入一个或几个圈子后，系统可以向这个用户推荐圈子中的人。\n我们定义这样两个圈子,并加入一些圈子成员。\n&lt;pre&gt;\nr.sadd(\'circle:game:lol\',\'user:debugo\')\nr.sadd(\'circle:game:lol\',\'user:leo\')\nr.sadd(\'circle:game:lol\',\'user:Guo\')\nr.sadd(\'circle:soccer:InterMilan\',\'user:Guo\')\nr.sadd(\'circle:soccer:InterMilan\',\'user:Levis\')\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;获取玩lol的用户:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.smembers(\'circle:game:lol\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;通过集合运算获取所有用户：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.sunion(\'circle:game:lol\', \'circle:soccer:InterMilan\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;Ps:&lt;/p&gt;\n<ul>\n<li>\n&lt;p&gt;本文基于<strong>python3.x和redis3.2</strong>进行试验的&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;写作本文最主要原因是网上很多介绍python-redis API的文章都过时了，大多数API现在使用都会报错。&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;本文\"应用技巧和场景\"借鉴了<a href=\"http://debugo.com/python-redis/\" rel=\"nofollow\">使用Python操作Redis</a>&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;文章篇幅有限，只列举了最常用的一些python-redis的API，如果大家有别的一些需求，可以查看它的官方文档，很详细这个文档也找了好久...点击查看：<a href=\"http://redis-py.readthedocs.io/en/latest/\" rel=\"nofollow\">redis官方文档</a>&lt;/p&gt;\n</li>\n</ul>','**安装redis**\n关于redis在windows的安装，请参照我[上一篇文章](http://www.rookiefly.me/detail/53)\n\n<hr>\n\n**安装redis的python驱动模块**\n>pip install redis\n\n<hr>\n\n**基本操作**\n\n连接到redis,这里数据库为0\n> r = redis.Redis(host=\'localhost\',port=6379,db=0)\n\n**注意，python是不支持select(选择/切换数据库命令的)**\n\nkey-value数据类型赋值\n> r.set(\'test\', \'t\') 或者 r[\'test1\'] = 5\n> r.getset(\'test\',\'ts\') 存新数据的时候返回上一次存储的数据\n> r.incr(\'test1\') 每次执行+1\n> r.decr(\'test1\') 每次执行-1\n\nkey-value数据类型取值\n> r.get(\'test\').decode(\'utf-8\') (如果不进行**decode**，取出来的是**bytes**)\n>r.mget(\'test\', \'test1\') 批量取出\n> r.keys(\'t*\') 取出以key为t*形式开头的数据\n\n随机取出\n> r.randomkey()   取key\n>r.get(randomkey()) 取value\n\n获取数据库中所有的keys，包括了k-v形式和列表/集合类型等\n> r.keys()\n\n当前数据库包含了多少条数据\n> r.dbsize()\n\n删除数据\n> r.delete(\'test\')\n> r.delete(\'test\', \'test1\') 批量删除\n\n根据key查看数据是否存在\n> r.exists(\'test\')\n\n设置数据过期时间\n> r.expire(\'test\', 60) 这里设置key=\'test\'的数据过期时间为60s,60s后就不能读取到它的值了\n> r.ttl(\'test\') 查看数据过期时间\n\nkey重命名\n> r.rename(\'test\', \'mytest\')\n\n将数据保存到硬盘\n> r.save()\n\n获取上次save时间\n> r.lastsave()\n\n清空数据库所有数据\n> r.flushdb()\n\n<hr>\n\n**操作list**\n\n插入列表,返回列表当前长度\n> r.lpush(\'mylist\', \'test1\') 从表头插入\n> r.rpush(\'mylist\', \'test2\')  从表尾插入\n\n获取列表的值\n> r.lindex(\'mylist\', 0).decode(\'utf-8\')  从mylist列表中取出索引为0的元素值\n\n获取列表长度\n> r.llen(\'mylist\')\n\n获取列表的部分值，**注意，列表索引从0开始**\n> r.lrange(\'mylist\', 0, 2)\n\n从列表删除元素并返回该元素\n> r.lpop(\'mylist\')  从表头删除\n> r.rpop(\'mylist\') 从表尾删除\n\n<hr>\n\n**排序(set操作)**\n\n插入集合,如果插入值已经存在，那么则不会插入，返回实际插入的个数\n> r.sadd(\'myset\', \'a\')  往myset中插入‘a’\n> r.sadd(\'myset\', \'b\',\'c\')\n\n从集合中删除\n> r.srem(\'myset\', \'a\')\n> r.spop(\'myset\') 从myset中随机删除一个元素\n\n集合大小\n> r.scard(\'myset\')\n\n判断集合中某个对象是否存在\n> r.sismember(\'myset\', \'b\')\n\n查看集合所有元素\n> r.smembers(\'myset\')\n\n求交集,集合myset(\'a\', \'b\' , \'c\') 和 msset(\'a\', \'d\')\n> r.sinter(\'myset\', \'msset\')\n> r.sinterstore(\'interset\', \'myset\', \'msset\') 把myset和msset的交集赋值给新的set: interset\n\n求并集\n> r.sunion(\'myset\', \'msset\')\n> r.sunionstore(\'unionset\', \'myset\', \'msset\')\n\n求差集\n> r.sdiff(\'myset\', \'msset\', \'mset\') 求myset有，但是msset和mset没有的元素\n\n>r.sdiffstore(\'difset\', \'myset\', \'msset\')\n\n排序,下面的参数依次是待排序set,开始的位置，长度，排序字段，是否降序， 是否允许非数字，是否需要存储排序结果(是就存储到store的参数中)\n> r.sort(\'myset\',start=None,num=None,by=None,get=None,desc=True,alpha=True,store=\'sortedset\')\n\n<hr>\n\n** 有序set **\n\n\'zadd\',\'zcard\',\'zincr\',\'zrange\',\'zrangebyscore\',\'zrem\',\'zscore\' \n分别对应 \n添加, 数量, 自加1,取数据,按照积分(范围)取数据,删除,取积分\n我这里就不多说了，和set用法差不太多\n\n<hr>\n\n** 一些应用技巧和场景 **\n\n*链式操作*, 这样减少了服务器和客户端的反复的TCP数据包，大大提高了批量命令的性能\n>p.set(\'hello\',\'redis\').sadd(\'faz\',\'baz\').incr(\'num\').execute()\n\n*页面点击数*(点击数特别多，修改特别频繁，如果用关系型数据库存储，可能存在大量的行级锁争用)\n> r.set(\'totals\', 0)\n> r.incr(\'totals\')\n\n*使用hash类型保存多样化对象*，从关系数据库来解释，就是“表”没有固定的列\n<pre>\n r.hset(\'users:resolvewang\', \'name\', \"John Doe\")\n r.hset(\'users:resolvewang\', \'email\', \'John@test.com\')\n r.hset(\'users:resolvewang\', \'phone\', \'1555313940\')\n # 获取“users:resolvewang”所有键值对，以dict形式返回\n r.hincrby(\'users:resolvewang\', \'visits\', 1)\n # 获取“users:resolvewang”所有键，以list形式返回\n r.hgetall(\'users:resolvewang\')\n</pre>\n\n<hr>\n\n*获取共同特征（求交集）*\n例子：在社交网站中，每一个圈子(circle)都有自己的用户群。通过圈子可以找到有共同特征（比如某一体育活动、游戏、电影等爱好者）的人。当一个用户加入一个或几个圈子后，系统可以向这个用户推荐圈子中的人。\n我们定义这样两个圈子,并加入一些圈子成员。\n<pre>\nr.sadd(\'circle:game:lol\',\'user:debugo\')\nr.sadd(\'circle:game:lol\',\'user:leo\')\nr.sadd(\'circle:game:lol\',\'user:Guo\')\nr.sadd(\'circle:soccer:InterMilan\',\'user:Guo\')\nr.sadd(\'circle:soccer:InterMilan\',\'user:Levis\')\n</pre>\n\n获取玩lol的用户:\n> r.smembers(\'circle:game:lol\')\n\n通过集合运算获取所有用户：\n> r.sunion(\'circle:game:lol\', \'circle:soccer:InterMilan\')\n\n\nPs:\n\n- 本文基于**python3.x和redis3.2**进行试验的\n\n- 写作本文最主要原因是网上很多介绍python-redis API的文章都过时了，大多数API现在使用都会报错。\n\n- 本文\"应用技巧和场景\"借鉴了[使用Python操作Redis](http://debugo.com/python-redis/)\n\n- 文章篇幅有限，只列举了最常用的一些python-redis的API，如果大家有别的一些需求，可以查看它的官方文档，很详细这个文档也找了好久...点击查看：[redis官方文档](http://redis-py.readthedocs.io/en/latest/)\n',1,'python, redis',1467637031,0,217,0,1,1),(55,'windows平台搭建SFTP服务器','&lt;p&gt;<strong> 缘由 </strong>\n项目运行在winserver上，通过远程连接其实可以进行文件操作，内网也比较快，但是每次修改了代码就连远程比较麻烦，而且copy怎么都感觉不舒服。所以萌生了使用<em>FTP/SFTP</em>服务器进行文件上传。IDE使用的是<a href=\"https://www.jetbrains.com/pycharm/\">Pycharm</a>。这个工具自带FTP/SFTP客户端，操作起来很方便。由于STFP更安全，所以我选择了使用SFTP。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;<strong>具体过程</strong>&lt;/p&gt;\n&lt;p&gt;服务端配置过程&lt;/p&gt;\n&lt;p&gt;1.下载STFP服务器\n网上有很多可以搭建SFTP服务器的软件，免费的最好用的可能是freeSSHd了吧，操作很简单，而且很稳定。下载地址：<a href=\"http://www.freesshd.com/?ctt=download\">freeSSHd.exe</a>&lt;/p&gt;\n&lt;p&gt;2.安装SFTP服务器\n安装过程就和安装一般的软件一样，配置点击默认就行，当询问是否以系统服务的方式运行，根据你的喜好选择即可，我选择的<strong>否</strong>，当询问你是否添加Private Key的时候选择<strong>是</strong>&lt;/p&gt;\n&lt;p&gt;3.配置STFP服务器&lt;/p&gt;\n&lt;p&gt;添加用户&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Users-&gt;add 这里添加你的stfp用户，注意<strong>Authorization使用Password的方式</strong>，domain项不填写，User can use <strong>一定要勾选 SFTP</strong>,其它根据自己的情况而定&lt;/p&gt;\n</blockquote>\n&lt;p&gt;配置监听端口&lt;/p&gt;\n<blockquote>\n&lt;p&gt;SSH-&gt;Port 这里填写你监听的端口，我选择的默认：22.其它按照默认设置即可&lt;/p&gt;\n</blockquote>\n&lt;p&gt;配置STFP文件夹的根路径&lt;/p&gt;\n<blockquote>\n&lt;p&gt;STFP-&gt;SFTP home path, 这里的path是你项目上传的根路径&lt;/p&gt;\n</blockquote>\n&lt;p&gt;其它选项按照默认即可&lt;/p&gt;\n&lt;p&gt;开启SFTP服务器&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Server status-&gt; Click here to start it&lt;/p&gt;\n</blockquote>\n&lt;p&gt;如果不能正常开启，比如说<strong>端口已经被占用</strong>了，很有可能是在安装freeSSHd的时候就默认开启了，由于修改了配置，需要重启，这时候可以<strong>查看任务管理器或者系统服务先关闭freesshdservice</strong>，再次开启就OK了&lt;/p&gt;\n&lt;p&gt;客户端配置（我用的是Pycharm，所以用它举例）:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Tools-&gt;Deployment&gt;Configuration&lt;/p&gt;\n&lt;p&gt;点击“+\",输入项目名，自取就行了,Type选择SFTP&lt;/p&gt;\n&lt;p&gt;默认为Connection栏，然后出现这个界面:&lt;/p&gt;\n</blockquote>\n&lt;p&gt;&lt;img alt=\"pycharm的sftp配置\" src=\"http://o948iqcf0.bkt.clouddn.com/sftp1.png\" width=\"550px\" height=\"550px\"&gt;&lt;/p&gt;\n&lt;p&gt;Type选择<strong>SFTP</strong>，SFTP host:填写SFTP服务器的ip地址， port就是上面步骤配置的监听端口， Root path选择\"/\",如果有别的子文件夹也是可以进行选择的, 然后Auth Type选择“Password”,再输入前面配置的用户名和密码，点击“Test SFTP Connection”就可以测试是否连上了SFTP服务器。如果不成功，那么检查<strong>监听端口是否正确</strong>，<strong>SFTP服务器是否启动</strong>，还有就是<strong>用户名和密码</strong>是否正确，常见就这三种错误&lt;/p&gt;\n&lt;p&gt;另外&lt;/p&gt;\n<blockquote>\n&lt;p&gt;选择Mappings，可以配置本地和sftp服务器对应的文件目录&lt;/p&gt;\n</blockquote>\n&lt;p&gt;关于sftp的配置基本就这些了,如果配置过程中有啥问题，可在下方留言，我看到会回复的&lt;/p&gt;','** 缘由 **\n项目运行在winserver上，通过远程连接其实可以进行文件操作，内网也比较快，但是每次修改了代码就连远程比较麻烦，而且copy怎么都感觉不舒服。所以萌生了使用*FTP/SFTP*服务器进行文件上传。IDE使用的是[Pycharm](https://www.jetbrains.com/pycharm/)。这个工具自带FTP/SFTP客户端，操作起来很方便。由于STFP更安全，所以我选择了使用SFTP。\n\n<hr>\n\n**具体过程**\n\n服务端配置过程\n\n1.下载STFP服务器\n网上有很多可以搭建SFTP服务器的软件，免费的最好用的可能是freeSSHd了吧，操作很简单，而且很稳定。下载地址：[freeSSHd.exe](http://www.freesshd.com/?ctt=download)\n\n2.安装SFTP服务器\n安装过程就和安装一般的软件一样，配置点击默认就行，当询问是否以系统服务的方式运行，根据你的喜好选择即可，我选择的**否**，当询问你是否添加Private Key的时候选择**是**\n\n3.配置STFP服务器\n\n添加用户\n> Users->add 这里添加你的stfp用户，注意**Authorization使用Password的方式**，domain项不填写，User can use **一定要勾选 SFTP**,其它根据自己的情况而定\n\n配置监听端口\n> SSH->Port 这里填写你监听的端口，我选择的默认：22.其它按照默认设置即可\n\n配置STFP文件夹的根路径\n> STFP->SFTP home path, 这里的path是你项目上传的根路径\n\n其它选项按照默认即可\n\n开启SFTP服务器\n>Server status-> Click here to start it\n\n如果不能正常开启，比如说**端口已经被占用**了，很有可能是在安装freeSSHd的时候就默认开启了，由于修改了配置，需要重启，这时候可以**查看任务管理器或者系统服务先关闭freesshdservice**，再次开启就OK了\n\n客户端配置（我用的是Pycharm，所以用它举例）:\n\n> Tools->Deployment>Configuration\n\n> 点击“+\",输入项目名，自取就行了,Type选择SFTP\n\n> 默认为Connection栏，然后出现这个界面:\n\n<img alt=\'pycharm的sftp配置\' src=\'http://o948iqcf0.bkt.clouddn.com/sftp1.png\' width=\'550px\' height=\'550px\'>\n\nType选择**SFTP**，SFTP host:填写SFTP服务器的ip地址， port就是上面步骤配置的监听端口， Root path选择\"/\",如果有别的子文件夹也是可以进行选择的, 然后Auth Type选择“Password”,再输入前面配置的用户名和密码，点击“Test SFTP Connection”就可以测试是否连上了SFTP服务器。如果不成功，那么检查**监听端口是否正确**，**SFTP服务器是否启动**，还有就是**用户名和密码**是否正确，常见就这三种错误\n\n另外\n> 选择Mappings，可以配置本地和sftp服务器对应的文件目录\n\n关于sftp的配置基本就这些了,如果配置过程中有啥问题，可在下方留言，我看到会回复的',1,'sftp',1467954944,0,73,0,1,1),(56,'使用selenium出现StaleElementReferenceException异常','<p>最近一直在帮瑞数公司做RSA动态防护系统反爬虫测试。遇到很多知识点，无奈时间太紧迫，都没好好总结下来放到博客上。明天要做专题汇报了，手头的工作暂时松了，可以做些自己喜欢的事了！</p>\n<p>回到正题上来，今天我用<em>selenium</em>驱动<em>geckodriver</em>打开<em>firefox</em>抓取<a href=\"http://119.254.209.77/\">瑞数测试网址</a> 的左边各个url链接的地址的时候(我的目的是测试是否能够通过程序采集到左边url点击后呈现的数据)，出现了<strong>selenium.common.exceptions.StaleElementReferenceException</strong>这个异常。先说说为何不用<em>firefox</em>自带的<em>webdriver</em>?因为如果是自带的webdriver，那么在调用click()函数触发点击事件后会得到空白页，这也就达到了它防护的目的。而通过人手动打开firefox点击页面却可以得到正确的结果。它能检测出我们是否用程序进行点击url的原理在于它可以检测到浏览器是否加载了webdriver插件，如果加载了，就不返回任何数据。所以我猜它是把一些常见的webdriver的<strong>特征指纹</strong>收集起来了，然后用于对比。而<a href=\"https://github.com/mozilla/geckodriver\">geckodriver</a>是最新的webdriver，它可用于驱动<strong>firefox nightly和firefox48及以上版本</strong>，目前的稳定版（47）尚不支持。目标网站肯定还没有提取该webdriver的特征指纹。额，怎么说到反爬虫的一些东西了，走题了！背景大概就这么多，以后有空我会总结这段时间做微博和瑞数反爬虫的一系列经验。下面看看这个异常。</p>\n<p><strong>StaleElementReferenceException</strong>这个异常出现的原因有两个：\n1. <em>The element has been deleted entirely.</em> ,即该元素被删除了\n2. <em>The element is no longer attached to the DOM.</em>， 即在元素被找到之后页面变换了，和当前的页面不匹配\n如果想查看更详细的解释请看<a href=\"http://docs.seleniumhq.org/exceptions/stale_element_reference.jsp\">官网对此的解释</a></p>\n<p>比如我们要将页面提取的url都通过click()函数触发点击事件得到网页源码，代码大概是这样的：</p>\n<pre>\n    links = driver.find_elements_by_tag_name(\"a\")\n    for link in links:\n        link.click()\n        driver.back()\n</pre>\n\n<blockquote>\n<p>selenium.common.exceptions.StaleElementReferenceException: Message: u\'Element not found in the cache - perhaps the page has changed since it was looked up\'</p>\n</blockquote>\n<p>异常说明在cache中找不到元素，在元素被找到之后页面变换了。 这就说明，当当前页面发生跳转之后，存在cache中的关于这个页面的元素也被清空了。</p>\n<pre>\n    length = len(driver.find_elements_by_tag_name(\"a\")\n    for i in range(0,length):\n        links = driver.find_elements_by_tag_name(\"a\")\n        link = links[i]\n        link.click()\n        driver.back()\n</pre>\n\n<p>嗯，这个异常处理大概就这样样子了，具体情况具体对待，主要就是看是否页面结构改变了，或者元素被js动态删除了</p>','最近一直在帮瑞数公司做RSA动态防护系统反爬虫测试。遇到很多知识点，无奈时间太紧迫，都没好好总结下来放到博客上。明天要做专题汇报了，手头的工作暂时松了，可以做些自己喜欢的事了！\n\n回到正题上来，今天我用*selenium*驱动*geckodriver*打开*firefox*抓取[瑞数测试网址](http://119.254.209.77/) 的左边各个url链接的地址的时候(我的目的是测试是否能够通过程序采集到左边url点击后呈现的数据)，出现了**selenium.common.exceptions.StaleElementReferenceException**这个异常。先说说为何不用*firefox*自带的*webdriver*?因为如果是自带的webdriver，那么在调用click()函数触发点击事件后会得到空白页，这也就达到了它防护的目的。而通过人手动打开firefox点击页面却可以得到正确的结果。它能检测出我们是否用程序进行点击url的原理在于它可以检测到浏览器是否加载了webdriver插件，如果加载了，就不返回任何数据。所以我猜它是把一些常见的webdriver的**特征指纹**收集起来了，然后用于对比。而[geckodriver](https://github.com/mozilla/geckodriver)是最新的webdriver，它可用于驱动**firefox nightly和firefox48及以上版本**，目前的稳定版（47）尚不支持。目标网站肯定还没有提取该webdriver的特征指纹。额，怎么说到反爬虫的一些东西了，走题了！背景大概就这么多，以后有空我会总结这段时间做微博和瑞数反爬虫的一系列经验。下面看看这个异常。\n\n**StaleElementReferenceException**这个异常出现的原因有两个：\n1. *The element has been deleted entirely.* ,即该元素被删除了\n2. *The element is no longer attached to the DOM.*， 即在元素被找到之后页面变换了，和当前的页面不匹配\n如果想查看更详细的解释请看[官网对此的解释](http://docs.seleniumhq.org/exceptions/stale_element_reference.jsp)\n\n比如我们要将页面提取的url都通过click()函数触发点击事件得到网页源码，代码大概是这样的：\n\n<pre>\n	links = driver.find_elements_by_tag_name(\"a\")\n	for link in links:\n		link.click()\n		driver.back()\n</pre>\n\n>selenium.common.exceptions.StaleElementReferenceException: Message: u\'Element not found in the cache - perhaps the page has changed since it was looked up\'\n\n异常说明在cache中找不到元素，在元素被找到之后页面变换了。 这就说明，当当前页面发生跳转之后，存在cache中的关于这个页面的元素也被清空了。\n\n<pre>\n	length = len(driver.find_elements_by_tag_name(\"a\")\n	for i in range(0,length):\n		links = driver.find_elements_by_tag_name(\"a\")\n		link = links[i]\n		link.click()\n		driver.back()\n</pre>\n\n嗯，这个异常处理大概就这样样子了，具体情况具体对待，主要就是看是否页面结构改变了，或者元素被js动态删除了',1,'selnium',1468585366,0,51,0,1,1),(57,'Python爬虫系列：(一)预备知识','&lt;p&gt;编者按&lt;/p&gt;\n&lt;p&gt;<strong>本文针对的读者是没有爬虫编写经验的同学，因为本文讲的是基础知识</strong>\n&lt;hr&gt;&lt;/p&gt;\n&lt;p&gt;概念&lt;/p&gt;\n&lt;p&gt;网络爬虫是什么？它能干什么？&lt;/p&gt;\n&lt;p&gt;简单说网络爬虫就是采集网站数据的一种工具，最著名的就是google搜索引擎了；它主要的工作就是采集我们想要的数据，如今是数据的时代，有了一定规模的数据是可以做很多有趣或者有意义的事情的。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;理论知识&lt;/p&gt;\n&lt;p&gt;1.Http协议：需要理解<strong>Http协议的请求方法</strong>,<strong>Http协议状态码</strong>,<strong>Http协议的头部</strong>。下面做具体说明：&lt;/p&gt;\n&lt;p&gt;a)<strong>请求方法</strong>。Http协议中文名为超文本传输协议，现在大多数web应用都遵守该协议，当然现在更安全的还有Https协议。我们编写爬虫时，会对目标站点发送Http请求（<strong>Get/Post</strong>等）,然后等待服务器响应请求后就能获取到我们需要的内容了。Http请求的作用就是让服务器知道你想获取它的资源，如果是权限范围之内的，它就会返回给你。Get请求一般是用于请求一个页面，而Post请求常用于提交表单，当然两者还有其它区别，比如Get请求有字符长度限制，比起Post请求更不安全，Get请求可以带Cookie以应对用户禁用cookie的情况。&lt;/p&gt;\n&lt;p&gt;b)<strong>状态码</strong>。状态码是服务器返回给浏览器的一串数字，比如返回正常，那么状态码就是<strong>2xx</strong>,常见的是200，还有<strong>4xx</strong>表示用户请求不合法，比如404，就是用户请求的资源已经不在服务器上了，<strong>5xx</strong>表示服务器内部错误，如果你的网站数据库宕机了，就可能会出现500的错误，<strong>3xx</strong>表示资源重定向，比如你请求的是\"http://www.baidu.com\", 它会把你定向到\"https://www.baidu.com\"&lt;/p&gt;\n&lt;p&gt;c)<strong>协议头部</strong>。协议头部也是一个比较重要的知识。我们用手机浏览器或者PC浏览器访问微博的时候，访问的页面为何不同？因为我们在请求的时候就带了<strong>User-Agent</strong>这个标识，比如：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.112 Safari/537.36&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这个就是我电脑的chrome浏览器的信息，在发送Http请求的时候，Http头部就会带上它。下图就是一个具体的Http头部：&lt;/p&gt;\n&lt;p&gt;&lt;img width=\"600px;\" height=\"400px;\" src=\"http://o948iqcf0.bkt.clouddn.com/httpheader.jpg\"&gt;&lt;/p&gt;\n&lt;p&gt;我们主要关心的是<strong>User-Agent</strong>,<strong>\"Referer\"</strong>和<strong>\"Cookie\"</strong>。User-Agent(以后都简称UA)和Referer主要用于避开服务器的<strong>反爬虫机制</strong>(关于反爬虫机制，以后我会专门来讲一下)，比如说当你直接用<strong>Requests</strong>库(python的http库，以后我们会用到)请求，可能User-Agent就是‘requests...’/\'httpclient\'等Http库的UA,有的Web站点直接就不给你返回数据了；referer用在<strong>反盗链</strong>，意思就是目标站点会判断你是否是它自己指定的某个连接跳转过来的，如果不是就不给你返回正确数据，比如上图的referer表示我们是从“http://www.rookiefly.me” 跳转过来的。<strong>Cookie</strong>，则是验证用户身份信息的重要标识，这个在涉及到需要<strong>登陆</strong>或<strong>其它权限</strong>的时候非常重要，所以下文会有详细介绍。&lt;/p&gt;\n&lt;p&gt;至于Http的相关知识我就写到这里了，编写爬虫已经够用了，如果想深入了解，推荐阅读<em>《图解Http协议》</em>,百度云链接点<a href=\"\" title=\"http://pan.baidu.com/s/1i4Bwa7V\">这里</a>,密码是:azv2.这本书是mobi格式，可以用kindle看，如果没有kindle,可以安装<a href=\"http://download.cnet.com/s/education-ebooks/windows/\">E-book viewer</a>查看。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;2.Python和它的Requests库。&lt;/p&gt;\n&lt;p&gt;Python大家都应该知道吧，是一门编程语言。而<strong>Requests</strong>是Python的第三方库，号称是\"HTTP for Humans\",很好用的Http库。比如我们需要抓取百度首页，只需要一行代码就可以搞定了：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;requests.get(\'http://www.baidu.com\').text&lt;/p&gt;\n</blockquote>\n&lt;p&gt;是不是很简单很强大呢！至于更详细的用法，我会在具体的代码中进行讲解，大家也可以查看Requests的官方文档来进行了解和学习：<a href=\"http://docs.python-requests.org/zh_CN/latest/\">Requests中文官方网站</a>.这里就不加赘述了。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;3.Cookie和Session&lt;/p&gt;\n&lt;p&gt;关于Cookie和Session的知识点，也是需要了解的，我在这里讲一下，重点讲解Cookie。Cookie是存储在客户端的用来<strong>标识用户身份</strong>的字符串，Cookies由一系列的<strong>键值对</strong>组成。比如前面图上的各个键值对。之所以网站可以在你关闭浏览器之后，下次打开<strong>免登陆</strong>，就是Cookie在起作用。所以如果别人拿到你的微博Cookie，即便是不知道你的密码，也可以进入你的账号，因此不要随便把Cookie泄露了。Cookie有一个过期时间，比如常见的7天内免登陆，说明它的Cookie过期时间为7天。同一站点不同键名的Cookie过期时间可能不同，如果是使用的chrome浏览器，可以添加editthiscookie这个插件查看各个Cookie的过期时间，firebug也是可以查看的。Cookie的相关知识现在就讲到这里，以后会讲到用它来进行模拟登陆，甚至有的网站会将Cookies中的部分键的值加密，然后获取某些信息。以后分析QQ空间的用户资料采集就会用到这个。由此可见，掌握Cookie的相关知识，对于编写网络爬虫来说是非常重要的。Session中文名是会话,是存储在服务器的相关凭证。关于Session的详细知识，我这里就不多讲了，在web编程中会用得比较多，但是web爬虫用得较少。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;4.抓包工具Fidder或者HttpAnalyzer7&lt;/p&gt;\n&lt;p&gt;抓包工具用于抓取HTTP请求，用于分清楚用户和服务器交互的具体过程，便于模拟我们编写爬虫。我这里推荐两款windows下的http抓包工具:fidder和httpanalyzer7,至于选哪款，完全是看个人习惯，我个人比较喜欢使用httpanalyzer7，因为fidder抓的包比较杂，而httpanalyzer7本来就将各个http请求按浏览器的不同而分类。下面是两款抓包工具的下载链接:&lt;/p&gt;\n&lt;p&gt;1.<a href=\"http://www.telerik.com/fiddler\">fidder</a>&lt;/p&gt;\n&lt;p&gt;2.<a href=\"http://pan.baidu.com/s/1jH7qnNC\">httpanalyzer7</a> ，密码:ov9b&lt;/p&gt;\n&lt;p&gt;磨刀不误砍柴工，基本关于网络爬虫的预备知识都涉及到了，下一篇文章将进行实站:<strong>模拟登陆慕课网</strong>。&lt;/p&gt;','编者按\n\n**本文针对的读者是没有爬虫编写经验的同学，因为本文讲的是基础知识**\n<hr>\n\n概念\n\n网络爬虫是什么？它能干什么？\n\n简单说网络爬虫就是采集网站数据的一种工具，最著名的就是google搜索引擎了；它主要的工作就是采集我们想要的数据，如今是数据的时代，有了一定规模的数据是可以做很多有趣或者有意义的事情的。\n\n<hr>\n\n理论知识\n\n1.Http协议：需要理解**Http协议的请求方法**,**Http协议状态码**,**Http协议的头部**。下面做具体说明：\n\na)**请求方法**。Http协议中文名为超文本传输协议，现在大多数web应用都遵守该协议，当然现在更安全的还有Https协议。我们编写爬虫时，会对目标站点发送Http请求（**Get/Post**等）,然后等待服务器响应请求后就能获取到我们需要的内容了。Http请求的作用就是让服务器知道你想获取它的资源，如果是权限范围之内的，它就会返回给你。Get请求一般是用于请求一个页面，而Post请求常用于提交表单，当然两者还有其它区别，比如Get请求有字符长度限制，比起Post请求更不安全，Get请求可以带Cookie以应对用户禁用cookie的情况。\n\nb)**状态码**。状态码是服务器返回给浏览器的一串数字，比如返回正常，那么状态码就是**2xx**,常见的是200，还有**4xx**表示用户请求不合法，比如404，就是用户请求的资源已经不在服务器上了，**5xx**表示服务器内部错误，如果你的网站数据库宕机了，就可能会出现500的错误，**3xx**表示资源重定向，比如你请求的是\"http://www.baidu.com\", 它会把你定向到\"https://www.baidu.com\"\n\nc)**协议头部**。协议头部也是一个比较重要的知识。我们用手机浏览器或者PC浏览器访问微博的时候，访问的页面为何不同？因为我们在请求的时候就带了**User-Agent**这个标识，比如：\n\n>Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.112 Safari/537.36\n\n这个就是我电脑的chrome浏览器的信息，在发送Http请求的时候，Http头部就会带上它。下图就是一个具体的Http头部：\n\n<img width=\'600px;\' height=\'400px;\' src=\'http://o948iqcf0.bkt.clouddn.com/httpheader.jpg\'>\n\n我们主要关心的是**User-Agent**,**\"Referer\"**和**\"Cookie\"**。User-Agent(以后都简称UA)和Referer主要用于避开服务器的**反爬虫机制**(关于反爬虫机制，以后我会专门来讲一下)，比如说当你直接用**Requests**库(python的http库，以后我们会用到)请求，可能User-Agent就是‘requests...’/\'httpclient\'等Http库的UA,有的Web站点直接就不给你返回数据了；referer用在**反盗链**，意思就是目标站点会判断你是否是它自己指定的某个连接跳转过来的，如果不是就不给你返回正确数据，比如上图的referer表示我们是从“http://www.rookiefly.me” 跳转过来的。**Cookie**，则是验证用户身份信息的重要标识，这个在涉及到需要**登陆**或**其它权限**的时候非常重要，所以下文会有详细介绍。\n\n至于Http的相关知识我就写到这里了，编写爬虫已经够用了，如果想深入了解，推荐阅读*《图解Http协议》*,百度云链接点[这里](\'http://pan.baidu.com/s/1i4Bwa7V\'),密码是:azv2.这本书是mobi格式，可以用kindle看，如果没有kindle,可以安装[E-book viewer](http://download.cnet.com/s/education-ebooks/windows/)查看。\n\n<hr>\n\n2.Python和它的Requests库。\n\nPython大家都应该知道吧，是一门编程语言。而**Requests**是Python的第三方库，号称是\"HTTP for Humans\",很好用的Http库。比如我们需要抓取百度首页，只需要一行代码就可以搞定了：\n>requests.get(\'http://www.baidu.com\').text\n\n是不是很简单很强大呢！至于更详细的用法，我会在具体的代码中进行讲解，大家也可以查看Requests的官方文档来进行了解和学习：[Requests中文官方网站](http://docs.python-requests.org/zh_CN/latest/).这里就不加赘述了。\n\n<hr>\n\n3.Cookie和Session\n\n关于Cookie和Session的知识点，也是需要了解的，我在这里讲一下，重点讲解Cookie。Cookie是存储在客户端的用来**标识用户身份**的字符串，Cookies由一系列的**键值对**组成。比如前面图上的各个键值对。之所以网站可以在你关闭浏览器之后，下次打开**免登陆**，就是Cookie在起作用。所以如果别人拿到你的微博Cookie，即便是不知道你的密码，也可以进入你的账号，因此不要随便把Cookie泄露了。Cookie有一个过期时间，比如常见的7天内免登陆，说明它的Cookie过期时间为7天。同一站点不同键名的Cookie过期时间可能不同，如果是使用的chrome浏览器，可以添加editthiscookie这个插件查看各个Cookie的过期时间，firebug也是可以查看的。Cookie的相关知识现在就讲到这里，以后会讲到用它来进行模拟登陆，甚至有的网站会将Cookies中的部分键的值加密，然后获取某些信息。以后分析QQ空间的用户资料采集就会用到这个。由此可见，掌握Cookie的相关知识，对于编写网络爬虫来说是非常重要的。Session中文名是会话,是存储在服务器的相关凭证。关于Session的详细知识，我这里就不多讲了，在web编程中会用得比较多，但是web爬虫用得较少。\n\n<hr>\n\n4.抓包工具Fidder或者HttpAnalyzer7\n\n抓包工具用于抓取HTTP请求，用于分清楚用户和服务器交互的具体过程，便于模拟我们编写爬虫。我这里推荐两款windows下的http抓包工具:fidder和httpanalyzer7,至于选哪款，完全是看个人习惯，我个人比较喜欢使用httpanalyzer7，因为fidder抓的包比较杂，而httpanalyzer7本来就将各个http请求按浏览器的不同而分类。下面是两款抓包工具的下载链接:\n\n1.[fidder](http://www.telerik.com/fiddler)\n\n2.[httpanalyzer7](http://pan.baidu.com/s/1jH7qnNC) ，密码:ov9b\n\n磨刀不误砍柴工，基本关于网络爬虫的预备知识都涉及到了，下一篇文章将进行实站:**模拟登陆慕课网**。',1,'Python,爬虫',1468591095,0,64,0,1,1),(65,'Python爬虫系列:(二)模拟登陆CSDN','&lt;p&gt;很多网站都必须要<strong>登陆权限</strong>，爬虫如果想获取有用的信息就必须带有登陆后的cookie。所以就有了<strong>模拟登陆</strong>的需求。一般我们写爬虫的顺序就是 <strong>模拟登陆</strong>-&gt;<strong>页面抓取</strong>-&gt;<strong>页面解析和数据清理</strong>-&gt;<strong>数据入库</strong>，有的页面信息并不需要登陆权限就可以抓取数据，模拟登陆这一步就可以省略了。另外，如果涉及到<strong>数据分析</strong>，那么我们还需要将数据用<strong>可视化</strong>的方法展示出来。这些东西在以后都会讲到。&lt;/p&gt;\n&lt;p&gt;原计划先写<strong>慕课网的模拟登陆</strong>，因为比较简单。但刚上慕课网看了一下，它的登陆流程已经改了，和目前主流网站的登陆流程是类似的，那个属于比较复杂的登陆了，留在后面再讲吧。我在这里选择<a href=\"https://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn\">csdn</a>作为<strong>初级模拟登陆</strong>的范例。下面讲它的流程。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;h3&gt;通过抓包分析登陆流程&lt;/h3&gt;\n&lt;p&gt;使用正常用户<strong>手动</strong>登陆目标网站，这里就是csdn。在打开目标网站之前需要打开抓包工具，我使用httpanalyzer的时候不知道是不是它抽风了，始终抓不到包，于是临时换为fiddler进行演示。注意要在<strong>打开目标网站登陆界面之前</strong>就要打开抓包工具，因为一般<strong>加密登陆用户名和密码的js代码在用户登陆之前就被请求</strong>了。如果在手动登陆的过程再打开，那么可能就找不到它的JS加密文件了。这种情况一般用于加密提交用户名和密码的时候，具体我会在分析微博模拟登陆的时候讲到。而csdn的登陆没那么复杂，用户名和密码都是用的明文传输。在手动登陆的时候有个<strong>小技巧</strong>，那就是<strong>故意把密码填错</strong>，这样可以很容易看到用户名和密码正确的提交路径和提交方式。下面是我手动登陆csdn填错用户名和密码抓包截图：&lt;/p&gt;\n&lt;p&gt;&lt;img width=\"750px\" height=\"400px\" src=\"http://o948iqcf0.bkt.clouddn.com/csdn1.png\"&gt;&lt;/p&gt;\n&lt;p&gt;我们从Fillder的<strong>webforms</strong>一项中可以看到提交的具体参数。其中<strong>username</strong>、<strong>password</strong>、<strong>_enventId</strong>一看就很明了，表示用户名、密码和提交的动作，而且它的密码还是<strong>明文传输</strong>的(目前大多数的做法是采用js加密再进行传输)。对于enventId一项，我们只是猜测它是\'submit\'这个不变的值，还需要验证。而\"lt\"和\"execution\"看起来比较没有规律，尤其是\"lt\".于是我们再次进行手动登陆，发现<strong>lt</strong>和<strong>execution</strong>在发生变化，<strong>lt</strong>毫无规律可言，而<strong>execution</strong>却是每次我们错误登陆的时候，就会在<strong>s</strong>后面的数字加1。说明这个是记录我们登陆次数信息的，那么我们就取照片中的第一次的值即可。现在的问题就是分析<strong>lt</strong>是怎么来的。&lt;/p&gt;\n&lt;p&gt;<strong>lt</strong>不可能是平白无故自己生成的撒，只有三种情况，<strong>1是藏在页面中的 2是通过服务器返回的 3是通过运行js生成的</strong> 。第一种情况需要我们查看网页源代码，进行分析。第二种情况需要我们抓包，看是否返回相应信息，第三种情况也需要我们抓包，获取js代码。然后通过在js代码中寻找关键字，这里是\'lt\'，然后进行分析得到结果。我们先来验证第一种情况。在登陆页面，点击鼠标右键，查看网页源代码(<strong>注意我们查看的是登陆表单的源代码，所以需要光标定位在登陆表单范围内，表单外可能是别的一个页面</strong>)。然后点击<strong>CTRL+F</strong>进行全文搜索，可以发现以下内容：&lt;/p&gt;\n&lt;p&gt;&lt;img width=\"1000px\" src=\"http://o948iqcf0.bkt.clouddn.com/csdn2.png\"&gt;&lt;/p&gt;\n&lt;p&gt;看来不光是lt的值可以得到，就连我们多次抓包得到的_enventId和execution的值都可以得到。所以可见<strong>查看登陆网页源代码的重要性</strong>！&lt;/p&gt;\n&lt;p&gt;在分析出我们需要提交的值过后，就是对参数的提取。考虑到有的朋友可能没有爬虫编写经验，我这里用最通用的<strong>正则表达式</strong>进行提取(以后我会讲更加简单的提取方式，那一块会放在<strong>页面解析部分讲解</strong>)。&lt;/p&gt;\n&lt;h3&gt;分析页面以获取登陆需要参数&lt;/h3&gt;\n&lt;p&gt;我们这里使用requests库进行http请求，requests库的API对用户非常友好，因此我们可以把精力专注放在业务逻辑分析上。要使用requests库，那么我们首先需要引入：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;import requests&lt;/p&gt;\n</blockquote>\n&lt;p&gt;通过上一步的抓包分析我们可以知道登陆页面是通过get进行获取的，并且请求的URL地址为&lt;/p&gt;\n<blockquote>\n&lt;p&gt;login_url = \'https://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn\'&lt;/p&gt;\n</blockquote>\n&lt;p&gt;那么请求代码如下\n&lt;pre&gt;\nheader = {\n    \'Host\': \'passport.csdn.net\',\n    \'User-Agent\': \'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:47.0) Gecko/20100101 Firefox/47.0\',\n    \'Accept-Encoding\': \'gzip, deflate, br\',\n    \'Accept-Language\': \'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3\',\n    \'Accept\': \'text/html,application/xhtml+xml,application/xml;q=0.9,<em>/</em>;q=0.8\',\n    \'Connection\': \'keep-alive\',\n    \'Referer\': \'http://www.csdn.net/\'\n}\nsession = requests.session()\nr = session.get(login_url, verify=False, headers=header)\nlogin_page = r.text\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;这里我们先看<strong>header</strong>吧。header是http请求头部的信息，为了<strong>让目标服务器相信我们是正常用户而不是爬虫</strong>在进行请求，我们需要<strong>伪造请求头信息</strong>，header的信息由<strong>dict</strong>进行封装。我们如何知道该在header里面设置些什么呢？这个问题的答案在上一步（手动分析登陆流程）就给出了，以获取请求页面为例：我们在手动登陆的时候通过抓包工具(这里我使用的是fidder)可以查看到请求的头信息。通过浏览器的F12也可以看到。下图是我的请求header信息：&lt;/p&gt;\n&lt;p&gt;&lt;img width=\"750px\" height=\"400px\" src=\"http://o948iqcf0.bkt.clouddn.com/csdn3.png\"&gt;&lt;/p&gt;\n&lt;p&gt;所以就有了上面代码中header的由来。\n<strong>session=requests.session()</strong>是什么意思呢？在requests中，我们不必关心cookie的相关操作，requests库可以自动给我们维护，我们只需要通过调用它的session()方法，返回的变量(这里是session)就包括了所有通过该变量进行http请求的cookie。当然，如果有特殊需求，比如需要把<strong>cookie持久化</strong>（即存入数据库或者文本中），那么requests也是支持的，我在后面的新浪微博模拟登陆会讲到。&lt;/p&gt;\n&lt;p&gt;设置好之后就可以进行Http请求了，比如这里是用的get请求，<strong>verify=False</strong>这个参数是为了解决requests不信任目标网站https证书的问题。如果我们不设置verify=False,那么可能直接抛一个“<strong>ssl相关error</strong>”。&lt;/p&gt;\n&lt;p&gt;通过get请求会返回一个Http Response，就是这里的“r”,这个变量中封装了一些很有用的属性，常见的有<strong>text(网页源代码)、cookie(网页cookie)和status code(响应状态码)</strong>。这里我再说一下status_code,如果我们不设置header，那么我们在模拟登陆成功后访问自己的主页，是会出现<strong>403</strong>的，下面会讲到。所以说可见设置<strong>header的重要性</strong>&lt;/p&gt;\n&lt;p&gt;程序运行到这里，我们已经拿到了登陆的页面了，下一步就是通过<strong>正则表达式</strong>提取需要的参数。正则表达式作为解析页面最常用也是最通用的方法，是我们需要掌握的。后面我会讲更加简单的方法解析页面。关于正则表达式的教程，推荐大家查看<a href=\"http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/00143193331387014ccd1040c814dee8b2164bb4f064cff000\">廖雪峰老师的博客</a>.廖老师的博客写得深入浅出，值得一看。以前我自己读廖老师的博客，为了离线阅读，做了个爬虫把他的Git、Python和Js教程全部抓取下来了，该项目的代码放在github上:<a href=\"https://github.com/ResolveWang/liaospider\">廖雪峰的教程</a>。下面是提取参数的正则表达式相关代码：&lt;/p&gt;\n&lt;pre&gt;\nlt_pattern = r\'name=\"lt\" value=\"(.*)\"\'\nm = re.search(lt_pattern, html)\nlt = m.group(1)\nexec_pattern = r\'name=\"execution\" value=\"(.*)\"\'\nm2 = re.search(exec_pattern, html)\nexecution = m2.group(1)\nsubmit_pattern = r\'name=\"_eventId\" value=\"(.*)\"\'\nm3 = re.search(submit_pattern, html)\nsubmit = m3.group(1)\n&lt;/pre&gt;\n\n&lt;p&gt;这里我强调一点，就是关于search()和match()的区别，因为如果你点开看了廖雪峰老师的教程，那么他基本都用的match（），但是这里用match（）是匹配不到任何结果的，原因就在于<strong>match()只从字符串的开始与正则表达式匹配，而search()将字符串的所有字串尝试与正则表达式匹配</strong>&lt;/p&gt;\n&lt;h3&gt;提交登陆需要的参数&lt;/h3&gt;\n&lt;p&gt;通过抓包手动分析登陆流程可以看到提交登陆参数是通过Post方式的，那么怎么通过post构造提交参数呢？requetst库采用的是dict对其进行封装，下面是登陆参数提交代码：&lt;/p&gt;\n&lt;pre&gt;\npost_data = {\n                \'username\': username,\n                \'password\': password,\n                \'lt\': lt,\n                \'execution\': execution,\n                \'_eventId\': submit\n             }\n\nsession.post(login_url, data=post_data, headers=header)\n&lt;/pre&gt;\n\n&lt;p&gt;通过前面的讲解，这一段代码应该不用细讲了吧，调用的是post方法，post中的data参数就是需要提交的内容。&lt;/p&gt;\n&lt;p&gt;然后我们再通过访问自己主页验证是否已经登陆：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;home_page = \'http://my.csdn.net/my/mycsdn\'&lt;/p&gt;\n&lt;p&gt;r = session.get(home_page, headers=header).text&lt;/p&gt;\n</blockquote>\n&lt;p&gt;经过查看，确实是已经得到我们想要的结果了，至此，整个CSDN的模拟登陆流程和编码工作就讲完了。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;<strong>概括起来就以下几点</strong>&lt;/p&gt;\n&lt;p&gt;1.手动登陆，抓包分析登陆流程&lt;/p&gt;\n&lt;p&gt;2.请求登陆页面以获取登陆提交需要参数&lt;/p&gt;\n&lt;p&gt;3.提交登陆参数&lt;/p&gt;\n&lt;p&gt;4.登陆完成，验证是否正常&lt;/p&gt;\n&lt;p&gt;PS：整篇文章中需要大家注意以下几点:\n- 请求的时候注意构造header信息，有兴趣的同学可以<strong>不带header访问自己主页</strong>，看是否会出现<strong>403</strong>&lt;/p&gt;\n<ul>\n<li>\n&lt;p&gt;正则表达式中的match()和search()的区别&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;对于需要通过cookie才能访问需要登陆权限的网站，requests通过requests.session()就可以自动维护cookie了，并不需要我们手动去维护&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;别频繁登陆，因为CSDN登陆页面可能返回验证码。关于图片验证码的识别，则是比较难的部分了，从本质上说并不属于爬虫的核心技术。&lt;/p&gt;\n</li>\n</ul>\n&lt;p&gt;这里是它的源代码:<a href=\"https://github.com/ResolveWang/smart_login/blob/master/csdn_login.py\">csdn模拟登陆</a>，前段时间比较忙没有更新，不过我会一直保持更新的。&lt;/p&gt;','很多网站都必须要**登陆权限**，爬虫如果想获取有用的信息就必须带有登陆后的cookie。所以就有了**模拟登陆**的需求。一般我们写爬虫的顺序就是 **模拟登陆**->**页面抓取**->**页面解析和数据清理**->**数据入库**，有的页面信息并不需要登陆权限就可以抓取数据，模拟登陆这一步就可以省略了。另外，如果涉及到**数据分析**，那么我们还需要将数据用**可视化**的方法展示出来。这些东西在以后都会讲到。\n\n原计划先写**慕课网的模拟登陆**，因为比较简单。但刚上慕课网看了一下，它的登陆流程已经改了，和目前主流网站的登陆流程是类似的，那个属于比较复杂的登陆了，留在后面再讲吧。我在这里选择[csdn](https://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn)作为**初级模拟登陆**的范例。下面讲它的流程。\n\n<hr>\n\n### 通过抓包分析登陆流程\n使用正常用户**手动**登陆目标网站，这里就是csdn。在打开目标网站之前需要打开抓包工具，我使用httpanalyzer的时候不知道是不是它抽风了，始终抓不到包，于是临时换为fiddler进行演示。注意要在**打开目标网站登陆界面之前**就要打开抓包工具，因为一般**加密登陆用户名和密码的js代码在用户登陆之前就被请求**了。如果在手动登陆的过程再打开，那么可能就找不到它的JS加密文件了。这种情况一般用于加密提交用户名和密码的时候，具体我会在分析微博模拟登陆的时候讲到。而csdn的登陆没那么复杂，用户名和密码都是用的明文传输。在手动登陆的时候有个**小技巧**，那就是**故意把密码填错**，这样可以很容易看到用户名和密码正确的提交路径和提交方式。下面是我手动登陆csdn填错用户名和密码抓包截图：\n\n<img width=\'750px\' height=\'400px\' src=\'http://o948iqcf0.bkt.clouddn.com/csdn1.png\'>\n\n我们从Fillder的**webforms**一项中可以看到提交的具体参数。其中**username**、**password**、**_enventId**一看就很明了，表示用户名、密码和提交的动作，而且它的密码还是**明文传输**的(目前大多数的做法是采用js加密再进行传输)。对于enventId一项，我们只是猜测它是\'submit\'这个不变的值，还需要验证。而\"lt\"和\"execution\"看起来比较没有规律，尤其是\"lt\".于是我们再次进行手动登陆，发现**lt**和**execution**在发生变化，**lt**毫无规律可言，而**execution**却是每次我们错误登陆的时候，就会在**s**后面的数字加1。说明这个是记录我们登陆次数信息的，那么我们就取照片中的第一次的值即可。现在的问题就是分析**lt**是怎么来的。\n\n**lt**不可能是平白无故自己生成的撒，只有三种情况，**1是藏在页面中的 2是通过服务器返回的 3是通过运行js生成的** 。第一种情况需要我们查看网页源代码，进行分析。第二种情况需要我们抓包，看是否返回相应信息，第三种情况也需要我们抓包，获取js代码。然后通过在js代码中寻找关键字，这里是\'lt\'，然后进行分析得到结果。我们先来验证第一种情况。在登陆页面，点击鼠标右键，查看网页源代码(**注意我们查看的是登陆表单的源代码，所以需要光标定位在登陆表单范围内，表单外可能是别的一个页面**)。然后点击**CTRL+F**进行全文搜索，可以发现以下内容：\n\n<img width=\'1000px\'\nsrc=\'http://o948iqcf0.bkt.clouddn.com/csdn2.png\'>\n\n\n看来不光是lt的值可以得到，就连我们多次抓包得到的_enventId和execution的值都可以得到。所以可见**查看登陆网页源代码的重要性**！\n\n在分析出我们需要提交的值过后，就是对参数的提取。考虑到有的朋友可能没有爬虫编写经验，我这里用最通用的**正则表达式**进行提取(以后我会讲更加简单的提取方式，那一块会放在**页面解析部分讲解**)。\n\n### 分析页面以获取登陆需要参数\n\n我们这里使用requests库进行http请求，requests库的API对用户非常友好，因此我们可以把精力专注放在业务逻辑分析上。要使用requests库，那么我们首先需要引入：\n> import requests\n\n通过上一步的抓包分析我们可以知道登陆页面是通过get进行获取的，并且请求的URL地址为\n> login_url = \'https://passport.csdn.net/account/login?from=http://my.csdn.net/my/mycsdn\'\n\n那么请求代码如下\n<pre>\nheader = {\n    \'Host\': \'passport.csdn.net\',\n    \'User-Agent\': \'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:47.0) Gecko/20100101 Firefox/47.0\',\n    \'Accept-Encoding\': \'gzip, deflate, br\',\n    \'Accept-Language\': \'zh-CN,zh;q=0.8,en-US;q=0.5,en;q=0.3\',\n    \'Accept\': \'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\',\n    \'Connection\': \'keep-alive\',\n    \'Referer\': \'http://www.csdn.net/\'\n}\nsession = requests.session()\nr = session.get(login_url, verify=False, headers=header)\nlogin_page = r.text\n</pre>\n\n这里我们先看**header**吧。header是http请求头部的信息，为了**让目标服务器相信我们是正常用户而不是爬虫**在进行请求，我们需要**伪造请求头信息**，header的信息由**dict**进行封装。我们如何知道该在header里面设置些什么呢？这个问题的答案在上一步（手动分析登陆流程）就给出了，以获取请求页面为例：我们在手动登陆的时候通过抓包工具(这里我使用的是fidder)可以查看到请求的头信息。通过浏览器的F12也可以看到。下图是我的请求header信息：\n\n<img width=\'750px\' height=\'400px\' src=\'http://o948iqcf0.bkt.clouddn.com/csdn3.png\'>\n\n\n所以就有了上面代码中header的由来。\n**session=requests.session()**是什么意思呢？在requests中，我们不必关心cookie的相关操作，requests库可以自动给我们维护，我们只需要通过调用它的session()方法，返回的变量(这里是session)就包括了所有通过该变量进行http请求的cookie。当然，如果有特殊需求，比如需要把**cookie持久化**（即存入数据库或者文本中），那么requests也是支持的，我在后面的新浪微博模拟登陆会讲到。\n\n设置好之后就可以进行Http请求了，比如这里是用的get请求，**verify=False**这个参数是为了解决requests不信任目标网站https证书的问题。如果我们不设置verify=False,那么可能直接抛一个“**ssl相关error**”。\n\n通过get请求会返回一个Http Response，就是这里的“r”,这个变量中封装了一些很有用的属性，常见的有**text(网页源代码)、cookie(网页cookie)和status code(响应状态码)**。这里我再说一下status_code,如果我们不设置header，那么我们在模拟登陆成功后访问自己的主页，是会出现**403**的，下面会讲到。所以说可见设置**header的重要性**\n\n程序运行到这里，我们已经拿到了登陆的页面了，下一步就是通过**正则表达式**提取需要的参数。正则表达式作为解析页面最常用也是最通用的方法，是我们需要掌握的。后面我会讲更加简单的方法解析页面。关于正则表达式的教程，推荐大家查看[廖雪峰老师的博客](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/00143193331387014ccd1040c814dee8b2164bb4f064cff000).廖老师的博客写得深入浅出，值得一看。以前我自己读廖老师的博客，为了离线阅读，做了个爬虫把他的Git、Python和Js教程全部抓取下来了，该项目的代码放在github上:[廖雪峰的教程](https://github.com/ResolveWang/liaospider)。下面是提取参数的正则表达式相关代码：\n\n<pre>\nlt_pattern = r\'name=\"lt\" value=\"(.*)\"\'\nm = re.search(lt_pattern, html)\nlt = m.group(1)\nexec_pattern = r\'name=\"execution\" value=\"(.*)\"\'\nm2 = re.search(exec_pattern, html)\nexecution = m2.group(1)\nsubmit_pattern = r\'name=\"_eventId\" value=\"(.*)\"\'\nm3 = re.search(submit_pattern, html)\nsubmit = m3.group(1)\n</pre>\n\n这里我强调一点，就是关于search()和match()的区别，因为如果你点开看了廖雪峰老师的教程，那么他基本都用的match（），但是这里用match（）是匹配不到任何结果的，原因就在于**match()只从字符串的开始与正则表达式匹配，而search()将字符串的所有字串尝试与正则表达式匹配**\n\n\n### 提交登陆需要的参数\n\n通过抓包手动分析登陆流程可以看到提交登陆参数是通过Post方式的，那么怎么通过post构造提交参数呢？requetst库采用的是dict对其进行封装，下面是登陆参数提交代码：\n\n<pre>\npost_data = {\n                \'username\': username,\n                \'password\': password,\n                \'lt\': lt,\n                \'execution\': execution,\n                \'_eventId\': submit\n             }\n\nsession.post(login_url, data=post_data, headers=header)\n</pre>\n\n通过前面的讲解，这一段代码应该不用细讲了吧，调用的是post方法，post中的data参数就是需要提交的内容。\n\n然后我们再通过访问自己主页验证是否已经登陆：\n\n>home_page = \'http://my.csdn.net/my/mycsdn\'\n\n>r = session.get(home_page, headers=header).text\n\n经过查看，确实是已经得到我们想要的结果了，至此，整个CSDN的模拟登陆流程和编码工作就讲完了。\n\n<hr>\n\n**概括起来就以下几点**\n\n1.手动登陆，抓包分析登陆流程\n\n2.请求登陆页面以获取登陆提交需要参数\n\n3.提交登陆参数\n\n4.登陆完成，验证是否正常\n\n\nPS：整篇文章中需要大家注意以下几点:\n- 请求的时候注意构造header信息，有兴趣的同学可以**不带header访问自己主页**，看是否会出现**403**\n\n- 正则表达式中的match()和search()的区别\n\n- 对于需要通过cookie才能访问需要登陆权限的网站，requests通过requests.session()就可以自动维护cookie了，并不需要我们手动去维护\n\n- 别频繁登陆，因为CSDN登陆页面可能返回验证码。关于图片验证码的识别，则是比较难的部分了，从本质上说并不属于爬虫的核心技术。\n\n这里是它的源代码:[csdn模拟登陆](https://github.com/ResolveWang/smart_login/blob/master/csdn_login.py)，前段时间比较忙没有更新，不过我会一直保持更新的。',1,'requests,模拟登陆',1468985967,0,136,0,1,1),(69,'windows安装cx_Oracle踩过的那些坑','&lt;p&gt;作死小能手这两天闲着没事，把自己电脑重装了，然而重装过后配置开发环境踩了一些坑，这里把安装<strong>cx_oracle</strong>遇到的坑记录下来，方便以后查看。&lt;/p&gt;\n&lt;h4&gt;使用pip安装出现的问题&lt;/h4&gt;\n&lt;p&gt;命令：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;pip install cx_oracle&lt;/p&gt;\n</blockquote>\n&lt;p&gt;错误：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Unable to find vcvarsall.bat&lt;/p&gt;\n</blockquote>\n&lt;p&gt;我用了最简单粗暴的方法:由于我的操作系统是<strong>win10 64</strong>位，所以我安装了<strong><a href=\"http://itellyou.cn/\">vs2015</a></strong>，很遗憾报的错误更多了！由于以前我没用pip安装都可以成功安装，所以我舍弃了这种安装方式&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;h3&gt;到官网下载相应版本的驱动进行安装&lt;/h3&gt;\n&lt;p&gt;我的操作系统为<strong>64</strong>位,Python版本为<strong>3.5.2</strong>，所以我到https://pypi.python.org/pypi/cx_Oracle/5.2.1 下载了对应的版本：<strong>cx_Oracle-5.2.1-12c.win-amd64-py3.5</strong>&lt;/p&gt;\n&lt;p&gt;1.安装过程中的错误：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Python version 3.5 required, which was not found in the registry&lt;/p&gt;\n</blockquote>\n&lt;p&gt;解决方法：\n网上看了很多种解决方法，很多是说的修改注册表，这种方式我试了，但是没成功，最后找到这个方法，成功了。运行下面这个脚本，不管是Python3.x还是2.x都可以加入注册表中：\n&lt;pre&gt;&lt;/p&gt;\n&lt;p&gt;# 解决windows平台下找不到python的注册信息问题 （安装oracle驱动会用）\nfrom winreg import *\nimport sys&lt;/p&gt;\n&lt;p&gt;# tweak as necessary\nversion = sys.version[:3]\ninstallpath = sys.prefix&lt;/p&gt;\n&lt;p&gt;regpath = \"SOFTWARE\\Python\\Pythoncore\\{0}\\\".format(version)\ninstallkey = \"InstallPath\"\npythonkey = \"PythonPath\"\npythonpath = \"{0};{1}\\Lib\\;{2}\\DLLs\\\".format(\n    installpath, installpath, installpath)&lt;/p&gt;\n&lt;p&gt;def RegisterPy():\n    try:\n        reg = OpenKey(HKEY_CURRENT_USER, regpath)\n    except EnvironmentError as e:\n        try:\n            reg = CreateKey(HKEY_CURRENT_USER, regpath)\n            SetValue(reg, installkey, REG_SZ, installpath)\n            SetValue(reg, pythonkey, REG_SZ, pythonpath)\n            CloseKey(reg)\n        except:\n            print(\"<strong><em> Unable to register!\")\n            return\n        print(\"--- Python\", version, \"is now registered!\")\n        return\n    if (QueryValue(reg, installkey) == installpath and\n        QueryValue(reg, pythonkey) == pythonpath):\n        CloseKey(reg)\n        print(\"=== Python\", version, \"is already registered!\")\n        return\n    CloseKey(reg)\n    print(\"</em></strong> Unable to register!\")\n    print(\"*** You probably have another Python installation!\")&lt;/p&gt;\n&lt;p&gt;if <strong>name</strong> == \"<strong>main</strong>\":\n    RegisterPy()\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;为了防止直接从网页复制运行失败的情况，我把它放到了github上，可以直接下载运行:<a href=\"https://github.com/ResolveWang/snippets/blob/master/register.py\">register.py</a>&lt;/p&gt;\n&lt;p&gt;2.命令行中运行提示找不到指定的模块&lt;/p&gt;\n<blockquote>\n&lt;p&gt;import cx_Oracle&lt;/p&gt;\n&lt;p&gt;ImportError: DLL load failed: 找不到指定的模块。&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这个问题的解决方法网上也说了很多，就是下载<strong><a href=\"http://www.oracle.com/technetwork/cn/database/features/instant-client/index-092699-zhs.html\">instantclient</a></strong>，然后解压将其中的<strong>oci.dll</strong>拷贝到$Python_Home 或者 $Python_Home\\Lib\\site-packages 目录下。运气好了，就成功了，运气不好的话可能<strong>还会出现找不到指定的模块</strong>这个问题，原因是<strong>instantclient的版本和cx_Oracle的版本不一致</strong>，拿我安装的来举例，我先下载了instantclient11,而我的\ncx_Oracle安装的是cx_Oracle-5.2.1-12c.win-amd64-py3.5，一个是11,一个是12c，这样还是出现了这个找不到指定的模块这个问题。正确做法是下载<strong>instantclient12和cx_Oracle-5.2.1-12c.win-amd64-py3.5</strong>。注意一点是<strong>cx_oracle和instantclient的版本不必和Oracle数据库版本一致，只需要cx_Oracle和instantclient版本一致</strong>即可。这样这个问题解决了，但是还有坑等着你！&lt;/p&gt;\n&lt;p&gt;3.命令行中运行提示不是有效的win32模块&lt;/p&gt;\n<blockquote>\n&lt;p&gt;import cx_Oracle&lt;/p&gt;\n&lt;p&gt;DLL load failed: %1 不是有效的 Win32 应用程序&lt;/p&gt;\n</blockquote>\n&lt;p&gt;解决方法:上一步我们讨论了版本问题，这一步该说说操作系统位数的问题了，出现这个问题的原因是<strong>操作系统、cx_Oracle和instantclient的位数不同</strong>,比如我先就是用的win10 64、cx_Oracle-5.2.1-12c.win-amd64-py3.5和instantclient12c(32位),就报了这个错误。正确做法是<strong>三者都用64或者三者都用32位系统</strong>,将instantclient的<strong>oci.dll</strong>文件放到$Python_Home\\Lib\\site-packages 目录下即可。&lt;/p&gt;\n&lt;p&gt;到此，应该可以解决cx_oracle安装过程的所有问题了，祝大家好运！&lt;/p&gt;\n&lt;p&gt;补充：虽然这样是可以使用cx_Oracle了，但是实际操作数据库的时候可能会出现<strong>unable to acquire oracle environment handle</strong>这个错误，解决方法是拷贝<strong>oci.dll, oraociei12.dll, oraocci12.dll</strong>到site-package中。另外一种方法是为instantclient12c设置环境变量，这样就不用拷贝dll文件了&lt;/p&gt;','作死小能手这两天闲着没事，把自己电脑重装了，然而重装过后配置开发环境踩了一些坑，这里把安装**cx_oracle**遇到的坑记录下来，方便以后查看。\n\n#### 使用pip安装出现的问题\n命令：\n> pip install cx_oracle\n\n错误：\n> Unable to find vcvarsall.bat\n\n我用了最简单粗暴的方法:由于我的操作系统是**win10 64**位，所以我安装了**[vs2015](http://itellyou.cn/)**，很遗憾报的错误更多了！由于以前我没用pip安装都可以成功安装，所以我舍弃了这种安装方式\n\n<hr>\n\n### 到官网下载相应版本的驱动进行安装\n我的操作系统为**64**位,Python版本为**3.5.2**，所以我到https://pypi.python.org/pypi/cx_Oracle/5.2.1 下载了对应的版本：**cx_Oracle-5.2.1-12c.win-amd64-py3.5**\n\n1.安装过程中的错误：\n> Python version 3.5 required, which was not found in the registry\n\n解决方法：\n网上看了很多种解决方法，很多是说的修改注册表，这种方式我试了，但是没成功，最后找到这个方法，成功了。运行下面这个脚本，不管是Python3.x还是2.x都可以加入注册表中：\n<pre>\n\n\\# 解决windows平台下找不到python的注册信息问题 （安装oracle驱动会用）\nfrom winreg import *\nimport sys\n\n\\# tweak as necessary\nversion = sys.version[:3]\ninstallpath = sys.prefix\n\nregpath = \"SOFTWARE\\\\Python\\\\Pythoncore\\\\{0}\\\\\".format(version)\ninstallkey = \"InstallPath\"\npythonkey = \"PythonPath\"\npythonpath = \"{0};{1}\\\\Lib\\\\;{2}\\\\DLLs\\\\\".format(\n    installpath, installpath, installpath)\n\n\ndef RegisterPy():\n    try:\n        reg = OpenKey(HKEY_CURRENT_USER, regpath)\n    except EnvironmentError as e:\n        try:\n            reg = CreateKey(HKEY_CURRENT_USER, regpath)\n            SetValue(reg, installkey, REG_SZ, installpath)\n            SetValue(reg, pythonkey, REG_SZ, pythonpath)\n            CloseKey(reg)\n        except:\n            print(\"*** Unable to register!\")\n            return\n        print(\"--- Python\", version, \"is now registered!\")\n        return\n    if (QueryValue(reg, installkey) == installpath and\n        QueryValue(reg, pythonkey) == pythonpath):\n        CloseKey(reg)\n        print(\"=== Python\", version, \"is already registered!\")\n        return\n    CloseKey(reg)\n    print(\"*** Unable to register!\")\n    print(\"*** You probably have another Python installation!\")\n\nif __name__ == \"__main__\":\n    RegisterPy()\n</pre>\n\n为了防止直接从网页复制运行失败的情况，我把它放到了github上，可以直接下载运行:[register.py](https://github.com/ResolveWang/snippets/blob/master/register.py)\n\n2.命令行中运行提示找不到指定的模块\n>import cx_Oracle\n\n>ImportError: DLL load failed: 找不到指定的模块。\n\n这个问题的解决方法网上也说了很多，就是下载**[instantclient](http://www.oracle.com/technetwork/cn/database/features/instant-client/index-092699-zhs.html)**，然后解压将其中的**oci.dll**拷贝到$Python_Home 或者 $Python_Home\\Lib\\site-packages 目录下。运气好了，就成功了，运气不好的话可能**还会出现找不到指定的模块**这个问题，原因是**instantclient的版本和cx_Oracle的版本不一致**，拿我安装的来举例，我先下载了instantclient11,而我的\ncx_Oracle安装的是cx_Oracle-5.2.1-12c.win-amd64-py3.5，一个是11,一个是12c，这样还是出现了这个找不到指定的模块这个问题。正确做法是下载**instantclient12和cx_Oracle-5.2.1-12c.win-amd64-py3.5**。注意一点是**cx_oracle和instantclient的版本不必和Oracle数据库版本一致，只需要cx_Oracle和instantclient版本一致**即可。这样这个问题解决了，但是还有坑等着你！\n\n\n3.命令行中运行提示不是有效的win32模块\n> import cx_Oracle\n\n> DLL load failed: %1 不是有效的 Win32 应用程序\n\n解决方法:上一步我们讨论了版本问题，这一步该说说操作系统位数的问题了，出现这个问题的原因是**操作系统、cx_Oracle和instantclient的位数不同**,比如我先就是用的win10 64、cx_Oracle-5.2.1-12c.win-amd64-py3.5和instantclient12c(32位),就报了这个错误。正确做法是**三者都用64或者三者都用32位系统**,将instantclient的**oci.dll**文件放到$Python_Home\\Lib\\site-packages 目录下即可。\n\n到此，应该可以解决cx_oracle安装过程的所有问题了，祝大家好运！\n\n补充：虽然这样是可以使用cx_Oracle了，但是实际操作数据库的时候可能会出现**unable to acquire oracle environment handle**这个错误，解决方法是拷贝**oci.dll, oraociei12.dll, oraocci12.dll**到site-package中。另外一种方法是为instantclient12c设置环境变量，这样就不用拷贝dll文件了',1,'python,oracle',1469368915,0,182,0,1,1),(70,'Pycharm:cannot run program \"git.exe\":CreateProcess error=2','&lt;p&gt;今天安装完了<strong>Pycharm</strong>，在使用它从github上拉项目下来的时候，出现了这个问题：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;cannot run program \"git.exe\":CreateProcess error=2&lt;/p&gt;\n</blockquote>\n&lt;p&gt;我使用的是<strong>win10 64位</strong>，在网上查了一下这个问题的原因，说是<strong>没有为git设置环境变量</strong>。引起问题的原因找到了，那么就有解决的办法了。&lt;/p&gt;\n&lt;p&gt;我们需要把windows版的github的安装路径找出来，但是到目前，github是直接从网上下载下来直接就安装了，根本就没机会让我们自定义安装路径。我在<strong>C盘</strong>搜索<strong>git</strong>关键字，发现<strong>C:\\Users\\Administrator\\AppData\\Local\\GitHub</strong>这个路径很像该设置环境变量的路径。为了验证，我使用命令行进入该目录，使用<strong>git</strong>关键字，结果报错了。后来突然想到了，<strong>github客户端是否有安装路径的相关信息</strong>呢？于是我点开github客户端右上角的<strong>about github desktop</strong>,发现有一个<strong>open debug log</strong>选项，我打开一看，有一行信息特别重要：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;PATH is C:\\Users\\Administrator\\AppData\\Local\\GitHub\\\nPortableGit_d76a6a98c9315931ec4927243517bc09e9b731a0\\cmd...&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这个不就是github该设置的环境路径吗？我再次使用命令行，切换到这个cmd目录下使用<strong>git</strong>命令，果然可以了！然后我再把它设置为环境变量，关闭pycharm再次打开，就不会报<strong>cannot run program \"git.exe\":CreateProcess error=2</strong>这个错误了，<strong>github</strong>和<strong>git</strong>都能正常使用了&lt;/p&gt;','今天安装完了**Pycharm**，在使用它从github上拉项目下来的时候，出现了这个问题：\n > cannot run program \"git.exe\":CreateProcess error=2\n\n我使用的是**win10 64位**，在网上查了一下这个问题的原因，说是**没有为git设置环境变量**。引起问题的原因找到了，那么就有解决的办法了。\n\n我们需要把windows版的github的安装路径找出来，但是到目前，github是直接从网上下载下来直接就安装了，根本就没机会让我们自定义安装路径。我在**C盘**搜索**git**关键字，发现**C:\\Users\\Administrator\\AppData\\Local\\GitHub**这个路径很像该设置环境变量的路径。为了验证，我使用命令行进入该目录，使用**git**关键字，结果报错了。后来突然想到了，**github客户端是否有安装路径的相关信息**呢？于是我点开github客户端右上角的**about github desktop**,发现有一个**open debug log**选项，我打开一看，有一行信息特别重要：\n> PATH is C:\\Users\\Administrator\\AppData\\Local\\GitHub\\\n>PortableGit_d76a6a98c9315931ec4927243517bc09e9b731a0\\cmd...\n\n这个不就是github该设置的环境路径吗？我再次使用命令行，切换到这个cmd目录下使用**git**命令，果然可以了！然后我再把它设置为环境变量，关闭pycharm再次打开，就不会报**cannot run program \"git.exe\":CreateProcess error=2**这个错误了，**github**和**git**都能正常使用了',1,'github',1469375285,0,97,0,1,1),(71,'sqlalchemy.exc.DatabaseError: raised as a result of Query-invoked autoflush的解决方法','<p>最近稍微空闲了一些，便在迁移博客。数据库从<strong>Mysql</strong>改为<strong>Mariadb</strong>，先在本地测试，发现出了一个问题：</p>\n<blockquote>\n<p>sqlalchemy.exc.DataError: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely) (_mysql_exceptions.DataError) (1265, \"Data truncated for column \'post_time\' at row 1\")</p>\n</blockquote>\n<p>以前在Mysql上运行只是出现警告，并不影响使用，而现在直接报错了，连网站页面都打不开。查询原因，才知道<strong>flasksqlalchemy</strong>中<em>autoflush</em>默认为开的,而上面的提示也很明显了，需要关闭<em>autoflush</em>。通过查看<a href=\"http://flask-sqlalchemy.pocoo.org/2.1/api/\">flasksqlalchemy文档</a>,得知需要修改<strong>SignallingSession</strong>类中的init方法，使用IDE找到flasksqlalchemy的SignallingSeision这个类，它的说明文档如下：</p>\n<blockquote>\n<p>If you want to use a different session you can override the\n    :meth:<code>SQLAlchemy.create_session</code> function.</p>\n</blockquote>\n<p>意思就是说我们需要修改<strong>SQLAlchemy</strong>这个类中的<strong>create_session</strong>方法,代码如下:</p>\n<pre>\n    def create_session(self, options):\n        \"\"\"Creates the session.  The default implementation returns a\n        :class:`SignallingSession`.\n        .. versionadded:: 2.0\n        \"\"\"\n        return SignallingSession(self, **options)\n</pre>\n\n<p>那么怎么修改第三方库或者内置库中的方法呢，一种比较好的方法是使用<strong>monkey_patch</strong>,另外一种方法是使用一个新的类来继承SQLALchemy,然后再重写create_session这个方法，我采用的后者:</p>\n<pre>\nclass MySQLAlchemy(SQLAlchemy):\n    def create_session(self, options):\n        options[\'autoflush\'] = False\n        return SignallingSession(self, **options)\n</pre>\n\n<p>然后，我们使用这个新类初始化db即可：</p>\n<blockquote>\n<p>db = MySQLAlchemy(app)</p>\n</blockquote>','最近稍微空闲了一些，便在迁移博客。数据库从**Mysql**改为**Mariadb**，先在本地测试，发现出了一个问题：\n\n>sqlalchemy.exc.DataError: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely) (_mysql_exceptions.DataError) (1265, \"Data truncated for column \'post_time\' at row 1\")\n\n以前在Mysql上运行只是出现警告，并不影响使用，而现在直接报错了，连网站页面都打不开。查询原因，才知道**flasksqlalchemy**中*autoflush*默认为开的,而上面的提示也很明显了，需要关闭*autoflush*。通过查看[flasksqlalchemy文档](http://flask-sqlalchemy.pocoo.org/2.1/api/),得知需要修改**SignallingSession**类中的init方法，使用IDE找到flasksqlalchemy的SignallingSeision这个类，它的说明文档如下：\n\n>If you want to use a different session you can override the\n    :meth:`SQLAlchemy.create_session` function.\n\n意思就是说我们需要修改**SQLAlchemy**这个类中的**create_session**方法,代码如下:\n\n<pre>\n	def create_session(self, options):\n		\"\"\"Creates the session.  The default implementation returns a\n		:class:`SignallingSession`.\n		.. versionadded:: 2.0\n		\"\"\"\n		return SignallingSession(self, **options)\n</pre>\n\n那么怎么修改第三方库或者内置库中的方法呢，一种比较好的方法是使用**monkey_patch**,另外一种方法是使用一个新的类来继承SQLALchemy,然后再重写create_session这个方法，我采用的后者:\n\n<pre>\nclass MySQLAlchemy(SQLAlchemy):\n	def create_session(self, options):\n		options[\'autoflush\'] = False\n		return SignallingSession(self, **options)\n</pre>\n\n然后，我们使用这个新类初始化db即可：\n> db = MySQLAlchemy(app)\n',1,'flask',1471400593,0,124,0,1,1),(72,'ubuntu下使用python3提示 ImportError: No module named \'ConfigParser\'','<p>1.出现这个问题的原因是python3中并<strong>没有ConfigParser</strong>这个模块，为了遵循<strong>pep 8</strong>的标准，已经改名为<strong>configparser</strong>了。</p>\n<p>2.通过报错可以看到出问题的文件在哪里，我们切换到该文件所在文件夹，我的是<strong>/usr/bin/</strong>。如果通过一般的思维，即<strong>把该文件中的语法转化为python3，那么可以解决这个问题，但是又会报出其它错误，可以照错误提示一直把全部相关文件和模块改为python3的语法</strong>，但是工作量很繁琐。</p>\n<p>3.另外一种方法:通过<strong>ls</strong>我们可以看到有个文件叫做<strong>pycompile</strong>,还有个文件叫做<strong>py3compile</strong>，前者遵循的是python2的语法，而我们使用pip的时候使用的就是pycompile,我们只需要用py3compile中的内容覆盖pycompile中的内容，这样的话就解决这个问题了</p>\n<p>备注:以上是我在使用ubuntu16.04安装和使用pip发现的问题，ubuntu16.04测试成功</p>','1.出现这个问题的原因是python3中并**没有ConfigParser**这个模块，为了遵循**pep 8**的标准，已经改名为**configparser**了。\n\n\n\n2.通过报错可以看到出问题的文件在哪里，我们切换到该文件所在文件夹，我的是**/usr/bin/**。如果通过一般的思维，即**把该文件中的语法转化为python3，那么可以解决这个问题，但是又会报出其它错误，可以照错误提示一直把全部相关文件和模块改为python3的语法**，但是工作量很繁琐。\n\n\n\n3.另外一种方法:通过**ls**我们可以看到有个文件叫做**pycompile**,还有个文件叫做**py3compile**，前者遵循的是python2的语法，而我们使用pip的时候使用的就是pycompile,我们只需要用py3compile中的内容覆盖pycompile中的内容，这样的话就解决这个问题了\n\n备注:以上是我在使用ubuntu16.04安装和使用pip发现的问题，ubuntu16.04测试成功',1,'ubuntu,python',1471403013,0,72,0,1,1),(73,'navicat linux 的破解方法','<p>1.安装：解压后即可用。目录下的<strong>start_navicat文件</strong>为可执行文件,执行:</p>\n<blockquote>\n<p>./start_navicat.sh </p>\n</blockquote>\n<p>2.破解：linux平台下无<strong>注册机</strong>可用,所以弃用这种方法。下面是<strong>正确方法</strong>:</p>\n<p>第一次执行start_navicat时，会在用户<strong>主目录</strong>下生成一个名为<strong>.navicat64</strong>的隐藏文件夹。 ----此文件夹下有一个system.reg文件 ----把此文件删除后，下次启动navicat 会重新生成此文件，30天试用期会按新的时间开始计算。 如果嫌麻烦，可以写一个sh脚本每次开机（或者写成定时任务）自动删除.navicat64文件夹(或者里面的system.reg文件)，这样就能无限试用了。主要步骤的代码表示:</p>\n<p>新建脚本:</p>\n<blockquote>\n<p>vi /usr/bin/navicat_active.sh</p>\n</blockquote>\n<p>脚本内容:</p>\n<blockquote>\n<p>rm -rf ~/.navicat64</p>\n</blockquote>\n<p>给脚本添加可执行权限:</p>\n<blockquote>\n<p>sudo chmod +x navicat_active.sh</p>\n</blockquote>\n<p>打开开机启动设置文本:</p>\n<blockquote>\n<p>sudo vi /etc/rc.local</p>\n</blockquote>\n<p>在文本末尾新加一行，设置脚本开机启动:</p>\n<blockquote>\n<p>/usr/bin/navicat_active.sh</p>\n</blockquote>','1.安装：解压后即可用。目录下的**start_navicat文件**为可执行文件,执行:\n\n> ./start_navicat.sh \n\n\n\n2.破解：linux平台下无**注册机**可用,所以弃用这种方法。下面是**正确方法**:\n\n第一次执行start_navicat时，会在用户**主目录**下生成一个名为**.navicat64**的隐藏文件夹。 ----此文件夹下有一个system.reg文件 ----把此文件删除后，下次启动navicat 会重新生成此文件，30天试用期会按新的时间开始计算。 如果嫌麻烦，可以写一个sh脚本每次开机（或者写成定时任务）自动删除.navicat64文件夹(或者里面的system.reg文件)，这样就能无限试用了。主要步骤的代码表示:\n\n新建脚本:\n\n> vi /usr/bin/navicat_active.sh\n\n\n\n脚本内容:\n\n> rm -rf ~/.navicat64\n\n\n\n给脚本添加可执行权限:\n\n> sudo chmod +x navicat_active.sh\n\n\n\n打开开机启动设置文本:\n\n> sudo vi /etc/rc.local\n\n\n\n在文本末尾新加一行，设置脚本开机启动:\n\n> /usr/bin/navicat_active.sh\n\n',1,'navicat,linux',1471403153,0,43,0,1,1),(74,'oracle数据导入和导出(转)','&lt;p&gt;下面介绍的是导入导出的实例。&lt;/p&gt;\n&lt;p&gt;数据导出&lt;/p&gt;\n&lt;p&gt;1.将数据库TEST完全导出,用户名system 密码manager 导出到D:\\daochu.dmp中&lt;/p&gt;\n<blockquote>\n&lt;p&gt;exp system/manager@TEST file=d:\\daochu.dmp full=y&lt;/p&gt;\n</blockquote>\n&lt;p&gt;2.将数据库中system用户与sys用户的表导出&lt;/p&gt;\n<blockquote>\n&lt;p&gt;exp system/manager@TEST file=d:\\daochu.dmp owner=(system,sys)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;3.将数据库中的表inner_notify、notify_staff_relat导出&lt;/p&gt;\n<blockquote>\n&lt;p&gt;exp aichannel/aichannel@TESTDB2 file= d:\\datanewsmgnt.dmp tables=(inner_notify,notify_staff_relat)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;4.将数据库中的表table1中的字段filed1以\"00\"打头的数据导出&lt;/p&gt;\n<blockquote>\n&lt;p&gt;exp system/manager@TEST file=d:\\daochu.dmp tables=(table1) query=\" where filed1 like \'00%\'\"&lt;/p&gt;\n</blockquote>\n&lt;p&gt;上面是常用的导出，对于压缩，既用winzip把dmp文件可以很好的压缩。也可以在上面命令后面 加上 compress=y 来实现。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;数据导入&lt;/p&gt;\n&lt;p&gt;1.将D:\\daochu.dmp 中的数据导入 TEST数据库中。&lt;/p&gt;\n<blockquote>\n&lt;p&gt;imp system/manager@TEST  file=d:\\daochu.dmp&lt;/p&gt;\n&lt;p&gt;imp aichannel/aichannel@TEST  full=y  file=d:\\datanewsmgnt.dmp ignore=y&lt;/p&gt;\n</blockquote>\n&lt;p&gt;上面可能有点问题，因为有的表已经存在，然后它就报错，对该表就不进行导入。在后面加上 ignore=y 就可以了。&lt;/p&gt;\n&lt;p&gt;2.将d:daochu.dmp中的表table1 导入&lt;/p&gt;\n<blockquote>\n&lt;p&gt;imp system/manager@TEST  file=d:\\daochu.dmp  tables=(table1)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;基本上上面的导入导出够用了。不少情况要先是将表彻底删除，然后导入。&lt;/p&gt;\n&lt;p&gt;注意：操作者要有足够的权限，权限不够它会提示。&lt;/p&gt;\n&lt;p&gt;原文： http://www.cnblogs.com/jason_lb/archive/2007/02/09/645586.html&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;由于项目需求，需要远程导入导出，远程导入导出的命令和上面的类似：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;imp/exp [username[/password[@hostIp：1521/DBsid]]]  DBsid是数据库sid&lt;/p&gt;\n</blockquote>\n&lt;p&gt;远程导出例子:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;exp admin/123@192.168.3.186/orcl(这里没有写端口号，因为默认的是1521)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;远程导入例子：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;imp c##cadb/ntci#8540@202.115.44.185/cloudsecurity file=g:/daochu.dmp  full=y ignore=y&lt;/p&gt;\n</blockquote>\n&lt;p&gt;导入导出都是连同表结构一起导入导出的，所以不需要提前建表&lt;/p&gt;','下面介绍的是导入导出的实例。\n\n数据导出\n\n1.将数据库TEST完全导出,用户名system 密码manager 导出到D:\\daochu.dmp中\n>exp system/manager@TEST file=d:\\daochu.dmp full=y\n\n2.将数据库中system用户与sys用户的表导出\n>exp system/manager@TEST file=d:\\daochu.dmp owner=(system,sys)\n\n3.将数据库中的表inner_notify、notify_staff_relat导出\n>exp aichannel/aichannel@TESTDB2 file= d:\\datanewsmgnt.dmp tables=(inner_notify,notify_staff_relat)\n\n4.将数据库中的表table1中的字段filed1以\"00\"打头的数据导出\n>exp system/manager@TEST file=d:\\daochu.dmp tables=(table1) query=\" where filed1 like \'00%\'\"\n\n上面是常用的导出，对于压缩，既用winzip把dmp文件可以很好的压缩。也可以在上面命令后面 加上 compress=y 来实现。\n\n<hr>\n\n数据导入\n\n1.将D:\\daochu.dmp 中的数据导入 TEST数据库中。\n>imp system/manager@TEST  file=d:\\daochu.dmp\n\n>imp aichannel/aichannel@TEST  full=y  file=d:\\datanewsmgnt.dmp ignore=y\n\n上面可能有点问题，因为有的表已经存在，然后它就报错，对该表就不进行导入。在后面加上 ignore=y 就可以了。\n\n2.将d:daochu.dmp中的表table1 导入\n>imp system/manager@TEST  file=d:\\daochu.dmp  tables=(table1)\n\n基本上上面的导入导出够用了。不少情况要先是将表彻底删除，然后导入。\n\n注意：操作者要有足够的权限，权限不够它会提示。\n\n原文： http://www.cnblogs.com/jason_lb/archive/2007/02/09/645586.html\n\n<hr>\n\n由于项目需求，需要远程导入导出，远程导入导出的命令和上面的类似：\n> imp/exp [username[/password[@hostIp：1521/DBsid]]]  DBsid是数据库sid\n\n远程导出例子:\n> exp admin/123@192.168.3.186/orcl(这里没有写端口号，因为默认的是1521)\n\n远程导入例子：\n> imp c##cadb/ntci#8540@202.115.44.185/cloudsecurity file=g:/daochu.dmp  full=y ignore=y\n\n导入导出都是连同表结构一起导入导出的，所以不需要提前建表',1,'oracle',1471403635,0,46,0,1,1),(75,'oracle数据导入导出遇到的问题及解决方法','&lt;p&gt;前一篇文章我们总结了oracle中数据导入和导出的方法，导入导出的时候还可能遇到如下问题。&lt;/p&gt;\n&lt;p&gt;通过imp命令导入数据，遇到了Oracle错误1691(ORA-01691),1658(ORA-01658),1659(ORA-01659).&lt;/p&gt;\n&lt;p&gt;究其原因，还是表空间的问题。&lt;/p&gt;\n&lt;p&gt;解决步骤：&lt;/p&gt;\n&lt;p&gt;查询表空间数据文件路径&lt;/p&gt;\n<blockquote>\n&lt;p&gt;select tablespace_name,file_name,autoextensible from dba_data_files&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这条语句的作用是查询表空间名字、数据文件所在位置、是否设置自动扩展,注意执行这条语句需要管理员权限(我使用的是sys账号)。&lt;/p&gt;\n&lt;p&gt;查询结果如下：&lt;/p&gt;\n&lt;p&gt;&lt;img alt=\"查询结果\" src=\"http://o948iqcf0.bkt.clouddn.com/oracle1.png\"/&gt;&lt;/p&gt;\n&lt;p&gt;如果autoextensible为NO，那么执行下面的语句：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;ALTER DATABASE  DATAFILE \'F:\\ORACLE\\ORACLEDATA\\CLOUDSECURITY\\SYSTEM01.DBF\'（表空间存储路径） AUTOEXTEND ON NEXT 100M MAXSIZE UNLIMITED;&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这样就把表空间设置为自动扩展了。&lt;/p&gt;\n&lt;p&gt;上图的SYSTEM02.DBF是我通过SYS账号执行sql添加的。因为好像一个.DBF文件最大为32G,我在把所有的表空间都改成自动扩展使用imp导入的时候仍然出了问题，我猜想原因就是SYSTEM01.DBF文件已达到最大了。添加.DBF文件语句如下：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;ALTER TABLESPACE MAXDATA ADD DATAFILE \'F:\\ORACLE\\ORACLEDATA\\CLOUDSECURITY\\SYSTEM02.DBF\' SIZE 1000M;&lt;/p&gt;\n</blockquote>\n&lt;p&gt;再用前面所讲的方法把新加的表空间设置为自动扩展，语句上面有，所以就不多说了&lt;/p&gt;\n&lt;p&gt;然后再使用imp语句，就能导入了。我导入的时候添加了这两个参数：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;imp rookiefly/ntci@cloudsecurity  full=y  file=d:\\datanewsmgnt.dmp ignore=y&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这样应该就不会报这三个错误了&lt;/p&gt;\n&lt;p&gt;ps:一定要看imp导入报错的提示，好确定是哪一个表空间的问题，比如我的实际情况：\n&lt;pre&gt;\n“\nIMP-00058: 遇到 ORACLE 错误 1658\nORA-01658: 无法为表空间 SYSTEM 中的段创建 INITIAL 区\n”\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;这个问题一看就是SYSTEM表空间出了问题，所以就针对这个表空间，检查是否<strong>自动扩展</strong>，还有就是<strong>添加表空间文件</strong>&lt;/p&gt;\n&lt;p&gt;&lt;hr&gt;\n添加于2016/08/26&lt;/p&gt;\n&lt;p&gt;在使用<strong>批处理</strong>挨个导入.dmp文件的时候，出现了如下错误：\n&lt;pre&gt;\nIMP-00058: 遇到 ORACLE 错误 1950\nORA-01950: 对表空间 \'SYSTEM\' 无权限\n成功终止导入, 但出现警告。\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;原因是该表的表空间是system所有，而普通用户并没有使用system表空间的权限，所以需要用dba赋权限给当前用户,赋权语句如下:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;alter user c##cadb quota unlimited on system&lt;/p&gt;\n</blockquote>','前一篇文章我们总结了oracle中数据导入和导出的方法，导入导出的时候还可能遇到如下问题。\n\n通过imp命令导入数据，遇到了Oracle错误1691(ORA-01691),1658(ORA-01658),1659(ORA-01659).\n\n究其原因，还是表空间的问题。\n\n解决步骤：\n\n查询表空间数据文件路径\n\n>select tablespace_name,file_name,autoextensible from dba_data_files\n\n这条语句的作用是查询表空间名字、数据文件所在位置、是否设置自动扩展,注意执行这条语句需要管理员权限(我使用的是sys账号)。\n\n查询结果如下：\n\n![查询结果](http://o948iqcf0.bkt.clouddn.com/oracle1.png)\n\n如果autoextensible为NO，那么执行下面的语句：\n>ALTER DATABASE  DATAFILE \'F:\\ORACLE\\ORACLEDATA\\CLOUDSECURITY\\SYSTEM01.DBF\'（表空间存储路径） AUTOEXTEND ON NEXT 100M MAXSIZE UNLIMITED;\n\n这样就把表空间设置为自动扩展了。\n\n上图的SYSTEM02.DBF是我通过SYS账号执行sql添加的。因为好像一个.DBF文件最大为32G,我在把所有的表空间都改成自动扩展使用imp导入的时候仍然出了问题，我猜想原因就是SYSTEM01.DBF文件已达到最大了。添加.DBF文件语句如下：\n>ALTER TABLESPACE MAXDATA ADD DATAFILE \'F:\\ORACLE\\ORACLEDATA\\CLOUDSECURITY\\SYSTEM02.DBF\' SIZE 1000M;\n\n再用前面所讲的方法把新加的表空间设置为自动扩展，语句上面有，所以就不多说了\n\n然后再使用imp语句，就能导入了。我导入的时候添加了这两个参数：\n>imp rookiefly/ntci@cloudsecurity  full=y  file=d:\\datanewsmgnt.dmp ignore=y\n\n这样应该就不会报这三个错误了\n\nps:一定要看imp导入报错的提示，好确定是哪一个表空间的问题，比如我的实际情况：\n<pre>\n“\nIMP-00058: 遇到 ORACLE 错误 1658\nORA-01658: 无法为表空间 SYSTEM 中的段创建 INITIAL 区\n”\n</pre>\n\n这个问题一看就是SYSTEM表空间出了问题，所以就针对这个表空间，检查是否**自动扩展**，还有就是**添加表空间文件**\n\n<hr>\n添加于2016/08/26\n\n在使用**批处理**挨个导入.dmp文件的时候，出现了如下错误：\n<pre>\nIMP-00058: 遇到 ORACLE 错误 1950\nORA-01950: 对表空间 \'SYSTEM\' 无权限\n成功终止导入, 但出现警告。\n</pre>\n\n原因是该表的表空间是system所有，而普通用户并没有使用system表空间的权限，所以需要用dba赋权限给当前用户,赋权语句如下:\n>alter user c##cadb quota unlimited on system\n',1,'oracle',1471404624,0,70,0,1,1),(76,'windows上使用pyvenv进行项目隔离','<p>最近在进行<a href=\"www.rookiefly.cn\">个人博客</a>迁移,因为阿里云服务和域名服务都到期了，得知腾讯云对于学生更优惠后，我选择了把博客迁移到腾讯云上,腾讯云的学生认证入口:<a href=\"https://www.qcloud.com/act/campus\">学生认证</a>。目前每天只有<strong>200</strong>个名额，需要的童鞋手要快。由于博客迁移一次，就要安装一次相应的库，有的时候并不知道自己项目中装了些啥三方库，所以只有边试错边部署，很费精力，所以便萌生了使用<strong>pyvenv</strong>构建虚拟目录进行部署项目。</p>\n<p>查阅了网上的一些资料发现，很多都是基于linux平台的，基于windows平台的特别少。所以我打算把过程记录下来。方便自己，也方便他人。</p>\n<p>从<strong>python3.4</strong>开始，就已经自带了<strong>pyvenv</strong>，我使用的是python3.5。如果版本低于3.4，可以使用<strong>pip</strong>安装<strong>virtualenv</strong>这个库，它们用法基本一致。</p>\n<p>先切换到你需要放置项目的目录，然后在命令行中使用pyvenv新建虚拟环境:</p>\n<blockquote>\n<p>python -m venv test</p>\n</blockquote>\n<p>这个命令执行完成之后，当前目录会新建一个名为<em>test</em>的目录，里面就是虚拟环境。</p>\n<p>激活虚拟环境,需要先切换到 test/Scripts/目录下，执行activate.bat这个批处理，这个就和linux有所区别:</p>\n<blockquote>\n<p>cd test/Scripts</p>\n<p>activate</p>\n</blockquote>\n<p>激活虚拟环境后的命令行，最前面会出现项目名称, 比如下面:</p>\n<blockquote>\n<p>(test) C:\\Users\\Administrator\\test\\Scripts&gt;</p>\n</blockquote>\n<p>虚拟环境中的python并没有安装扩展库(pip除外)，我们通过pip在虚拟环境中安装的任何扩展库都只对当前虚拟环境(<strong>test</strong>)有效，对真实的环境和别的虚拟环境都没有效。比如我们继续执行以下命令安装requests库：</p>\n<blockquote>\n<p>pip install requests</p>\n</blockquote>\n<p>然后导入它：</p>\n<blockquote>\n<p>import requests</p>\n</blockquote>\n<p>这个是可以运行的。如果我们的真实环境没装requests的话，我们使用这条命令就会报错。换句话说，就是虚拟环境和真实环境、还有别的虚拟环境都各不影响。</p>\n<p>激活虚拟环境后可以安装各种库，执行各种操作了，怎么退出虚拟环境呢？</p>\n<blockquote>\n<p>deactivate</p>\n</blockquote>\n<p>这个命令不必切换到 <em>test/Scripts</em>, 哪里都可以执行。</p>\n<p>这里说完了虚拟环境的激活和退出，下面说说从A环境迁移到B虚拟环境怎么<strong>重建依赖</strong>的问题,这也是我自己运用虚拟环境的一个很重要的原因。</p>\n<p>先在A环境中把所有依赖都保存到re.txt中,使用<strong>pip freeze</strong>:</p>\n<blockquote>\n<p>pip freeze &gt; re.txt</p>\n</blockquote>\n<p>这时会在当前目录生成re.txt,通过记事本可以直接打开:</p>\n<blockquote>\n<p>notepad re.txt</p>\n</blockquote>\n<p>可以看到类似内容:\n<pre>\nFlask==0.11.1\nFlask-Login==0.3.2\nFlask-SQLAlchemy==2.1\n</pre></p>\n<p>我们可以修改该文件来改变我们虚拟环境的相关依赖，比如我们不需要Flask,直接删除<em>Flask==0.11.1</em>即可。</p>\n<p>这个文件怎么用呢,我们先激活B虚拟环境，然后可以一条命令安装所有依赖:</p>\n<blockquote>\n<p>pip install -r re.txt</p>\n</blockquote>\n<p>到此，B虚拟环境和A环境的依赖就一样了。还有一点我需要说明，有的扩展库通过pip install的方式安装可能会出现问题(比如 lxml)，那么通过上面那条命令安装也会失败，这种扩展库我们只有去<a href=\"http://www.lfd.uci.edu/~gohlke/pythonlibs/#mysqlclient\">这里</a>下载编译好的.whl文件进行单独安装。先在虚拟环境中安装wheel(pip install wheel)，然后就可以直接用pip命令安装.whl文件了。</p>\n<p>关于python在win平台上的虚拟环境的知识大概就如此了。</p>','最近在进行[个人博客](www.rookiefly.cn)迁移,因为阿里云服务和域名服务都到期了，得知腾讯云对于学生更优惠后，我选择了把博客迁移到腾讯云上,腾讯云的学生认证入口:[学生认证](https://www.qcloud.com/act/campus)。目前每天只有**200**个名额，需要的童鞋手要快。由于博客迁移一次，就要安装一次相应的库，有的时候并不知道自己项目中装了些啥三方库，所以只有边试错边部署，很费精力，所以便萌生了使用**pyvenv**构建虚拟目录进行部署项目。\n\n查阅了网上的一些资料发现，很多都是基于linux平台的，基于windows平台的特别少。所以我打算把过程记录下来。方便自己，也方便他人。\n\n从**python3.4**开始，就已经自带了**pyvenv**，我使用的是python3.5。如果版本低于3.4，可以使用**pip**安装**virtualenv**这个库，它们用法基本一致。\n\n\n先切换到你需要放置项目的目录，然后在命令行中使用pyvenv新建虚拟环境:\n> python -m venv test\n\n这个命令执行完成之后，当前目录会新建一个名为*test*的目录，里面就是虚拟环境。\n\n激活虚拟环境,需要先切换到 test/Scripts/目录下，执行activate.bat这个批处理，这个就和linux有所区别:\n> cd test/Scripts\n\n> activate\n\n激活虚拟环境后的命令行，最前面会出现项目名称, 比如下面:\n> (test) C:\\Users\\Administrator\\test\\Scripts>\n\n虚拟环境中的python并没有安装扩展库(pip除外)，我们通过pip在虚拟环境中安装的任何扩展库都只对当前虚拟环境(**test**)有效，对真实的环境和别的虚拟环境都没有效。比如我们继续执行以下命令安装requests库：\n> pip install requests\n\n然后导入它：\n> import requests\n\n这个是可以运行的。如果我们的真实环境没装requests的话，我们使用这条命令就会报错。换句话说，就是虚拟环境和真实环境、还有别的虚拟环境都各不影响。\n\n激活虚拟环境后可以安装各种库，执行各种操作了，怎么退出虚拟环境呢？\n> deactivate\n\n这个命令不必切换到 *test/Scripts*, 哪里都可以执行。\n\n这里说完了虚拟环境的激活和退出，下面说说从A环境迁移到B虚拟环境怎么**重建依赖**的问题,这也是我自己运用虚拟环境的一个很重要的原因。\n\n先在A环境中把所有依赖都保存到re.txt中,使用**pip freeze**:\n> pip freeze > re.txt\n\n这时会在当前目录生成re.txt,通过记事本可以直接打开:\n> notepad re.txt\n\n可以看到类似内容:\n<pre>\nFlask==0.11.1\nFlask-Login==0.3.2\nFlask-SQLAlchemy==2.1\n</pre>\n\n我们可以修改该文件来改变我们虚拟环境的相关依赖，比如我们不需要Flask,直接删除*Flask==0.11.1*即可。\n\n这个文件怎么用呢,我们先激活B虚拟环境，然后可以一条命令安装所有依赖:\n> pip install -r re.txt\n\n到此，B虚拟环境和A环境的依赖就一样了。还有一点我需要说明，有的扩展库通过pip install的方式安装可能会出现问题(比如 lxml)，那么通过上面那条命令安装也会失败，这种扩展库我们只有去[这里](http://www.lfd.uci.edu/~gohlke/pythonlibs/#mysqlclient)下载编译好的.whl文件进行单独安装。先在虚拟环境中安装wheel(pip install wheel)，然后就可以直接用pip命令安装.whl文件了。\n\n关于python在win平台上的虚拟环境的知识大概就如此了。\n\n\n',1,'python,pyvenv',1471440054,0,82,0,1,1),(77,'pycharm、idea等使用ftp出现\"couldnot list the contents\"','<p>由于博客迁移，需要重新部署sftp服务器，在windows上使用<a href=\"http://www.freesshd.com/?ctt=download\">freesshd</a>部署的时候，idea的sftp客户端始终连不上，最后想换成ftp试试，抱着试一试的心态又下载了一个<a href=\"http://www.freesshd.com/?ctt=download\">freeftpd</a>.在完成了一系列配置过后，我通过pycharm连接ftp服务器，出现了如下错误:</p>\n<blockquote>\n<p>Could not list the contents of folder \"ftp://123.206.XX.XX\"</p>\n</blockquote>\n<p>通过查阅相关资料发现了解决方法:</p>\n<blockquote>\n<p>pycharm-&gt;Tools&gt;Deployment-&gt;Configuration</p>\n</blockquote>\n<p>在设置了tfp的相关连接信息过后，接着下一步操作:</p>\n<blockquote>\n<p>Advanced options-&gt;勾选Passive mode&gt;Test FTP connection</p>\n</blockquote>\n<p>第一次连接需要一些时间。</p>','由于博客迁移，需要重新部署sftp服务器，在windows上使用[freesshd](http://www.freesshd.com/?ctt=download)部署的时候，idea的sftp客户端始终连不上，最后想换成ftp试试，抱着试一试的心态又下载了一个[freeftpd](http://www.freesshd.com/?ctt=download).在完成了一系列配置过后，我通过pycharm连接ftp服务器，出现了如下错误:\n> Could not list the contents of folder \"ftp://123.206.XX.XX\"\n\n通过查阅相关资料发现了解决方法:\n>pycharm->Tools>Deployment->Configuration\n\n在设置了tfp的相关连接信息过后，接着下一步操作:\n> Advanced options->勾选Passive mode>Test FTP connection\n\n第一次连接需要一些时间。\n\n',1,'ftp',1471490282,0,42,0,1,1),(78,'Sublime Text3的插件安装(重点讲解Ctags)','<p>以前都是用的IDE进行开发，sublime一直安装着却没有用，如今想好好使用它。安装插件是基本功，这里我说说我安装<strong>packge control</strong>和<strong>ctags</strong>的一些坑。</p>\n<p>sublime中可以使用packge control进行插件管理，所以我们第一步是安装packge control。sublime text3有两种方法安装packge control，第一种方法是直接下载包，通过 sublime-&gt;preferencs-&gt;browse packges定位到插件目录，然后在<a href=\"https://packagecontrol.io/installation\">packge control官网</a>下载文件直接放置在插件根目录下的<strong>User</strong>目录即可。重启后就可以使用了，别的插件也可以使用这种方式安装。第二种是使用命令行进行安装。使用<strong>ctrl+`</strong> 调出命令行。如果电脑装有QQ输入法，那么需要先修改一个设置，因为它也是使用的这个快捷键。修改步骤：</p>\n<blockquote>\n<p>输入法属性设置-输入法管理-取消热键切换至QQ拼音</p>\n</blockquote>\n<p>在弹出的命令行中输入以下代码：\n<code>\nimport urllib.request,os,hashlib;\nh = \'2915d1851351e5ee549c20394736b442\' + \'8bc59f460fa1548d1514676163dafc88\'; pf = \'Package Control.sublime-package\';\nipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); \nby = urllib.request.urlopen( \'http://packagecontrol.io/\' + pf.replace(\' \', \'%20\')).read();\ndh = hashlib.sha256(by).hexdigest(); print(\'Error validating download (got %s instead of %s), please try manual install\' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), \'wb\' ).write(by)\n</code></p>\n<p>安装的时候sublime会有点卡，等安装完了就好了。</p>\n<p>然后重启Sublime Text 3，如果在Perferences-&gt;package settings中看到package control这一项，则安装成功。</p>\n<hr>\n\n<p>然后再使用Packge Control安装插件:</p>\n<p>1.按下<strong>Ctrl+Shift+P</strong>或者在preferences-&gt;packge control中调出命令面板</p>\n<p>2.输入<strong>install</strong>调出<strong>install packge</strong>并回车，选择要安装的插件。</p>\n<p>我们用这种方法安装<strong>Ctags</strong>,当我们在项目上点击<em>rebuild tags</em> 会出现一段乱码而导致rebuild失败，出现原因是因为sublime找不到ctags的可执行文件，解决方法如下：\n1.在<a href=\"https://sourceforge.net/projects/ctags/?source=directory\">该地址</a>下载ctags的相关文件</p>\n<p>2.sublime text 3：Preferences-&gt;Package settings-&gt;CTags-&gt;Settings-Default文档里的内容全部复制到 Settings-User里</p>\n<p>3.将下载后的ctags文件夹解压并放置到sublime的packge的user目录下，packge目录的位置可通过preferences-&gt;browese packge来查。</p>\n<p>4.添加ctags.exe到环境变量</p>\n<p>5.重启sublime，就可以使用了</p>','以前都是用的IDE进行开发，sublime一直安装着却没有用，如今想好好使用它。安装插件是基本功，这里我说说我安装**packge control**和**ctags**的一些坑。\n\nsublime中可以使用packge control进行插件管理，所以我们第一步是安装packge control。sublime text3有两种方法安装packge control，第一种方法是直接下载包，通过 sublime->preferencs->browse packges定位到插件目录，然后在[packge control官网](https://packagecontrol.io/installation)下载文件直接放置在插件根目录下的**User**目录即可。重启后就可以使用了，别的插件也可以使用这种方式安装。第二种是使用命令行进行安装。使用**ctrl+`** 调出命令行。如果电脑装有QQ输入法，那么需要先修改一个设置，因为它也是使用的这个快捷键。修改步骤：\n> 输入法属性设置-输入法管理-取消热键切换至QQ拼音\n\n在弹出的命令行中输入以下代码：\n<code>\nimport urllib.request,os,hashlib;\nh = \'2915d1851351e5ee549c20394736b442\' + \'8bc59f460fa1548d1514676163dafc88\'; pf = \'Package Control.sublime-package\';\nipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); \nby = urllib.request.urlopen( \'http://packagecontrol.io/\' + pf.replace(\' \', \'%20\')).read();\ndh = hashlib.sha256(by).hexdigest(); print(\'Error validating download (got %s instead of %s), please try manual install\' % (dh, h)) if dh != h else open(os.path.join( ipp, pf), \'wb\' ).write(by)\n</code>\n\n安装的时候sublime会有点卡，等安装完了就好了。\n\n然后重启Sublime Text 3，如果在Perferences->package settings中看到package control这一项，则安装成功。\n\n<hr>\n\n然后再使用Packge Control安装插件:\n\n1.按下**Ctrl+Shift+P**或者在preferences->packge control中调出命令面板\n\n2.输入**install**调出**install packge**并回车，选择要安装的插件。\n\n我们用这种方法安装**Ctags**,当我们在项目上点击*rebuild tags* 会出现一段乱码而导致rebuild失败，出现原因是因为sublime找不到ctags的可执行文件，解决方法如下：\n1.在[该地址](https://sourceforge.net/projects/ctags/?source=directory)下载ctags的相关文件\n\n2.sublime text 3：Preferences->Package settings->CTags->Settings-Default文档里的内容全部复制到 Settings-User里\n\n3.将下载后的ctags文件夹解压并放置到sublime的packge的user目录下，packge目录的位置可通过preferences->browese packge来查。\n\n4.添加ctags.exe到环境变量\n\n5.重启sublime，就可以使用了\n\n\n',1,'sublime',1471589307,0,35,0,1,1),(79,'ubuntu中安装cx_Oracle踩过的那些坑','<p>前面写过一篇<a href=\"http://www.rookiefly.cn/detail/69\">windows上安装oracle踩过的那些坑</a>,今天作死小能手又带来ubuntu安装cx_Oracle会遇到的一些坑和填坑方法。</p>\n<p>先直接通过pip安装cx_Oracle看看会遇到什么情况：</p>\n<blockquote>\n<p>pip install cx_Oracle</p>\n</blockquote>\n<p>出现如下错误：</p>\n<blockquote>\n<p>raise DistutilsSetupError(\"cannot locate an Oracle software \" distutils.errors.DistutilsSetupError: cannot locate an Oracle software installation</p>\n</blockquote>\n<p>这个是因为没有下载oracle的instantclient和设置环境变量所致。解决方法如下：</p>\n<p>到oracle官网下载对应版本的<strong>instantclient</strong>和对应的<strong>sdk</strong>:<a href=\"http://www.oracle.com/technetwork/topics/linuxx86-64soft-092277.html\">instantclient和sdk下载页面</a>.然后解压instantclient和sdk，把解压后的sdk文件夹放到instantclient目录下。然后将instantclient放到自己指定的某个目录，并设置环境变量，比如我解压放在了/home/program目录下：\n<pre>\n$vi /etc/profile\nexport ORACLE_HOME=/home/program/instantclient_12_1\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/program/instantclient_12_1\n$source /etc/profile\n</pre></p>\n<p>然后执行pip,发现又报错了。\n<pre>\n/usr/bin/ld: cannot find -lclntsh\ncollect2: error: ld returned 1 exit status\nerror: command \'gcc\' failed with exit status 1\n</pre></p>\n<p>解决方法：</p>\n<p>切换到instantclient目录下，执行下面命令</p>\n<blockquote>\n<p>ln-s libclntsh.so.12.1 libclntsh.so</p>\n</blockquote>\n<p>再用pip就可以安装cx_Oracle了。使用import导入cx_Oracle又出现了错误：\n<pre>\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: libaio.so.1: cannot open shared object file: No such file or directory\n</pre></p>\n<p>解决方法：</p>\n<blockquote>\n<p>sudo apt-get install sudo apt-get install libaio1</p>\n</blockquote>','前面写过一篇[windows上安装oracle踩过的那些坑](http://www.rookiefly.cn/detail/69),今天作死小能手又带来ubuntu安装cx_Oracle会遇到的一些坑和填坑方法。\n\n先直接通过pip安装cx_Oracle看看会遇到什么情况：\n> pip install cx_Oracle\n\n出现如下错误：\n>raise DistutilsSetupError(\"cannot locate an Oracle software \" distutils.errors.DistutilsSetupError: cannot locate an Oracle software installation\n\n这个是因为没有下载oracle的instantclient和设置环境变量所致。解决方法如下：\n\n到oracle官网下载对应版本的**instantclient**和对应的**sdk**:[instantclient和sdk下载页面](http://www.oracle.com/technetwork/topics/linuxx86-64soft-092277.html).然后解压instantclient和sdk，把解压后的sdk文件夹放到instantclient目录下。然后将instantclient放到自己指定的某个目录，并设置环境变量，比如我解压放在了/home/program目录下：\n<pre>\n$vi /etc/profile\nexport ORACLE_HOME=/home/program/instantclient_12_1\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/program/instantclient_12_1\n$source /etc/profile\n</pre>\n\n然后执行pip,发现又报错了。\n<pre>\n/usr/bin/ld: cannot find -lclntsh\ncollect2: error: ld returned 1 exit status\nerror: command \'gcc\' failed with exit status 1\n</pre>\n\n解决方法：\n\n切换到instantclient目录下，执行下面命令\n> ln-s libclntsh.so.12.1 libclntsh.so\n\n再用pip就可以安装cx_Oracle了。使用import导入cx_Oracle又出现了错误：\n<pre>\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: libaio.so.1: cannot open shared object file: No such file or directory\n</pre>\n\n解决方法：\n>sudo apt-get install sudo apt-get install libaio1\n\n',1,'环境配置',1471857389,0,56,0,1,1),(80,'使用IDEA打包jar文件','<p>最近，由于项目需要所以必须使用Java，对于java，最烦它的各种环境配置，这里我记录一下使用IDEA打包jar文件的过程，以便以后查看。</p>\n<blockquote>\n<p>File-&gt;Project Structure-&gt;Artifacts-&gt; + -&gt; JAR -&gt; From modules with dependences</p>\n</blockquote>\n<p>选择需要打包的项目和主类，然后选择</p>\n<blockquote>\n<p>extract to the target JAR</p>\n</blockquote>\n<p>点击“OK”,继续点击OK,如果出现<strong>出现manifest.mf already exists in vfs</strong>这个错误，原因是之前在IDEA中对这个module打过jar包了，所以module中会有一个MANIFEST.MF文件，提示的错误即时这个文件夹及其中的文件已经存在，所以把这个文件删除掉，这个文件位于<strong>src/META-INF/</strong>目录下。</p>\n<p>然后点击<strong>build-&gt;Build Artifacts-&gt;build</strong>即可。然后就会在根目录的<strong>out/artifacts/</strong>目录下生成打包好的jar文件。</p>\n<p>另外，我打包好了，使用java -jar运行，不报错但是也不执行，后来想起可能需要引入.properties配置文件，我把配置文件放到相应目录，运行就没问题了。</p>','最近，由于项目需要所以必须使用Java，对于java，最烦它的各种环境配置，这里我记录一下使用IDEA打包jar文件的过程，以便以后查看。\n\n> File->Project Structure->Artifacts-> + -> JAR -> From modules with dependences\n\n选择需要打包的项目和主类，然后选择\n> extract to the target JAR\n\n点击“OK”,继续点击OK,如果出现**出现manifest.mf already exists in vfs**这个错误，原因是之前在IDEA中对这个module打过jar包了，所以module中会有一个MANIFEST.MF文件，提示的错误即时这个文件夹及其中的文件已经存在，所以把这个文件删除掉，这个文件位于**src/META-INF/**目录下。\n\n然后点击**build->Build Artifacts->build**即可。然后就会在根目录的**out/artifacts/**目录下生成打包好的jar文件。\n\n另外，我打包好了，使用java -jar运行，不报错但是也不执行，后来想起可能需要引入.properties配置文件，我把配置文件放到相应目录，运行就没问题了。\n',1,'环境配置,java',1471920874,0,106,0,1,1),(81,'linux平台cx_Oracle:UnicodeEncodeError: \'ascii\' codec can\'t encode characters in position... ','<p>今天，把微博爬虫部署到linux服务器上了，在采集数据插入Oracle数据库的时候遇到了如下问题：</p>\n<blockquote>\n<p>UnicodeEncodeError: \'ascii\' codec can\'t encode characters in position 0-3: ordinal not in range(128)  </p>\n</blockquote>\n<p>爬虫程序直接就挂掉了。我就比较纳闷了，为啥在windows上面运行得好好的程序在linux下面就报编码错误，在命令行查询中文字符并不会报错，但是出现的是\"?\"。我的Oracle数据库编码采用的是GBK,用的是Python3，为什么还会这样呢？后来想明白了肯定是数据库客户端(即我们的程序)或者数据库连接编码是ascii，所以才会出现这个问题。知道了问题，就知道如何解决了，解决方法如下：</p>\n<p>在连接数据库的模块加入下面两行代码：\n<pre>\nimport os \nos.environ[\'NLS_LANG\'] = \'SIMPLIFIED CHINESE_CHINA.UTF8\' \n</pre></p>\n<p>这样，就可以正常的进行数据库操作了。</p>','今天，把微博爬虫部署到linux服务器上了，在采集数据插入Oracle数据库的时候遇到了如下问题：\n>UnicodeEncodeError: \'ascii\' codec can\'t encode characters in position 0-3: ordinal not in range(128)  \n\n爬虫程序直接就挂掉了。我就比较纳闷了，为啥在windows上面运行得好好的程序在linux下面就报编码错误，在命令行查询中文字符并不会报错，但是出现的是\"?\"。我的Oracle数据库编码采用的是GBK,用的是Python3，为什么还会这样呢？后来想明白了肯定是数据库客户端(即我们的程序)或者数据库连接编码是ascii，所以才会出现这个问题。知道了问题，就知道如何解决了，解决方法如下：\n\n在连接数据库的模块加入下面两行代码：\n<pre>\nimport os \nos.environ[\'NLS_LANG\'] = \'SIMPLIFIED CHINESE_CHINA.UTF8\' \n</pre>\n\n这样，就可以正常的进行数据库操作了。',1,'oracle',1472545475,0,42,0,1,1),(82,'cx_Oracle.DatabaseError: ORA-01745: 无效的主机/绑定变量名','<p>在改写数据库查询的时候，使用了这样一条语句：</p>\n<blockquote>\n<p>select_sql = \'select * from weibo_sina_users where su_id = :uid\'</p>\n</blockquote>\n<p>然后就出了问题了：</p>\n<blockquote>\n<p>cx_Oracle.DatabaseError: ORA-01745: 无效的主机/绑定变量名</p>\n</blockquote>\n<p>我起初认为是连接的问题，但我试了别的sql语句后，发现都可以执行，就这一条不可以执行。后来才得知<strong>uid</strong>为<strong>Oracle的关键字或者保留字</strong>，<strong>查询参数不可以是oracle的关键字</strong>，不然就会这个问题。</p>\n<p>把uid改为u_id果然可以执行了</p>','在改写数据库查询的时候，使用了这样一条语句：\n>select_sql = \'select * from weibo_sina_users where su_id = :uid\'\n\n然后就出了问题了：\n> cx_Oracle.DatabaseError: ORA-01745: 无效的主机/绑定变量名\n\n我起初认为是连接的问题，但我试了别的sql语句后，发现都可以执行，就这一条不可以执行。后来才得知**uid**为**Oracle的关键字或者保留字**，**查询参数不可以是oracle的关键字**，不然就会这个问题。\n\n把uid改为u_id果然可以执行了',1,'oracle,python',1472545799,0,85,0,1,1),(83,'Python爬虫系列:(三)模拟登陆新浪微博','&lt;p&gt;前面已经讲过了<a href=\"http://www.rookiefly.cn/detail/57\">Python爬虫的预备知识</a>和<a href=\"http://www.rookiefly.cn/detail/65\">使用python模拟登陆csdn</a>，今天我将谈谈使用Python登陆新浪微博。&lt;/p&gt;\n&lt;p&gt;该文章我在简书上写过，这里我把它引用过来，顺便进行一些修改和完善。&lt;/p&gt;\n&lt;p&gt;一直在研究微博的爬虫，第一步便是模拟登陆，从开始摸索到走通模拟登陆这条路其实还是挺艰难的，需要一定的经验，为了让朋友们以后少走点弯路，这里我把我的分析过程和代码都附上来。&lt;/p&gt;\n&lt;p&gt;首先，我们先用正常的账号登陆，具体看会有些什么请求。这里我用的是Http Analyzer抓包(Filders也是一个不错的选择)。下面是正常登陆流程的截图：&lt;/p&gt;\n&lt;p&gt;&lt;img width=\"600px\" src=\"http://upload-images.jianshu.io/upload_images/1514374-aa13818dfdbdd8f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"&gt;&lt;/p&gt;\n&lt;p&gt;接下来我会详细说明各个过程。&lt;/p&gt;\n&lt;p&gt;第一步：预登陆。&lt;/p&gt;\n&lt;p&gt;现在微博、空间等大型网站在输入用户名后基本都会做编码或者加密处理，这里在用户名输入框输入我的账号，通过抓包工具可以看到服务器会返回一段字符串：&lt;/p&gt;\n&lt;p&gt;&lt;img width=\"600px\" src=\"http://upload-images.jianshu.io/upload_images/1514374-affa0e2ac8848f62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"&gt;&lt;/p&gt;\n&lt;p&gt;这一步就是预登陆过程，同学们可以自己试试。登陆的时候我们需要用到其中的servertime、nonce、pubkey等字段。当然这个不是我自己猜想的，后面的步骤会做说明。&lt;/p&gt;\n&lt;p&gt;还有一点，就是预登陆的url:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;http://login.sina.com.cn/sso/prelogin.php?entry=weibo&amp;callback=sinaSSOController.preloginCallBack\n&amp;su=&amp;rsakt=mod&amp;checkpin=1&amp;client=ssologin.js(v1.4.18)\n&amp;_=1461819359582&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这里su的值是自己用户名经过base64编码的值。但可能你们会问我是如何知道的呢，待会儿我会讲到。经过实测，如果我们这里不给su传参数，其实也是可以的。为了最真实的模拟用户登录，我们最好还是带上它的值。&lt;/p&gt;\n&lt;p&gt;请看图一的第一条js请求<strong>http://i.sso.sina.com.cn/js/ssologin.js</strong>&lt;/p&gt;\n&lt;p&gt;同学们可以点进去看，这个就是前面提到的加密用户名和密码等一系列的加密文件了，如果有同学非要问我是怎么找到这个加密文件的，我也只有说：反复抓包，从在浏览器输入weibo.com过后就找js文件请求路径，然后再用代码格式化工具打开，挨着一个一个看，在代码中搜关键字，比如这里我们可以搜\"nonce\"、“servertime”等，就能找到加密文件了。&lt;/p&gt;\n&lt;p&gt;打开加密文件我们可以看到加密用户名的代码，在加密js文件中搜索\'username\'，可以看到有一行代码为:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;username = sinaSSOEncoder.base64.encode(urlencode(username));  &lt;/p&gt;\n</blockquote>\n&lt;p&gt;现在我们可以直接查找encode方法(代码太多就不贴上来了)，即可查找到对应方法了，为了验证我们的猜想，我们可以在webstorm中copy这个encode函数带上自己的用户名运行，返回的结果就是su的值，这个值在之后进行post提交的时候也会用到。如果对加密有一定经验的同学可能一眼就会看出这个是base64编码，python中有个base64模块可以干这个事情。我们再回到图一，&lt;/p&gt;\n<blockquote>\n&lt;p&gt;http://login.sina.com.cn/sso/login.php?client=ssologin.js(v1.4.18)  这个地址就是进行post提交数据的地址，下面是我自己提交的数据：&lt;/p&gt;\n</blockquote>\n&lt;p&gt;&lt;img width=\"600px\" src=\"http://upload-images.jianshu.io/upload_images/1514374-e2fb91272734ad1d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"&gt;&lt;/p&gt;\n&lt;p&gt;这里我们需要自己构造<strong>su</strong>(加密后的用户名),<strong>sp</strong>(加密后的密码),<strong>servertime</strong>,<strong>nonce</strong>，<strong>rsakv</strong>等数据，其它数据都不用变。有同学问我为哈其它数据不用变？你自己可以多登陆几次，看变化的值，那么那些值就是需要构造的值，其它值就直接拿过来用就行了。这里的su,servertime,nonce,rsakv都已经拿到了，所以当前需要的就只是sp的值了。我们还是按照原来的方法在js文件中查找“sp”,可以找到requests.sp=password这段代码，所以我们就只需要看password怎么构造的了。通过查找可以看到关键加密代码：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;password = RSAKey.encrypt([me.servertime,me.nonce].join(\"\\t\") +\"\\n\"+ password)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这一段代码便是加密密码的代码，有经验的同学一看就知道是用的RSA加密，python中也有相应的<strong>rsa加密库</strong>可用。但是我们假设大家都没看出来或者不知道python中有rsa这个第三方库。这时候就要给大家介绍一些我的经验了.&lt;/p&gt;\n&lt;p&gt;我现在已经知道的有三种模拟登陆方案：\na)最简单暴力，效率也是最高的，直接把js源码转化为相应的python代码，模拟加密流程进行加密 &lt;/p&gt;\n&lt;p&gt;b)使用selenium+phantomjs/firefox的方案直接模拟人的操作填写表单提交数据进行模拟登陆，这种方式最为简单，效率稍微低一些。如果有同学对这种简单暴力的方式感兴趣，可以到我的github上查看一下源码 &lt;/p&gt;\n&lt;p&gt;c)比较折中的方案，通过pyv8/pyexecjs等渲染js代码进行执行，本文主要就是讲的这种方式。第一种方式如果是遇到微博调整了登陆加密算法，就必须改加密代码，第二种方式和第三种方式不存在这个问题。&lt;/p&gt;\n&lt;p&gt;由于我用的是Python3，并不支持PyV8,所以我选了和它类似的<strong>PyexecJS</strong>,这个也可以直接执行js代码。我也不是很熟悉Javascript代码，所以我直接定义了一个函数处理加密密码，并没对其加密源代码修改太多：&lt;/p&gt;\n&lt;pre&gt;\n\nfunction get_pass(mypass,nonce,servertime,rsakey){\n    varRSAKey = newsinaSSOEncoder.RSAKey();\n    RSAKey.setPublic(rsakey,\"10001\");\n    password= RSAKey.encrypt([servertime,nonce].join(\"\\t\") +\"\\n\"+ mypass)\n    return password\n\n}\n&lt;/pre&gt;\n\n&lt;p&gt;这个函数中的东西其实就是copy的加密文件的加密过程代码。为了试验，我直接使用之前自己登陆抓到的nonce、servertime、rsakey等数据，在webstorm中调用这个函数，但是报错了，提示\"<strong>navigator is undefined</strong>\",webstorm 使用的nodejs的运行时环境，而navigator为浏览器的某个属性，所以运行会出问题。于是我就是<strong>用phantomjs来作为运行时环境</strong>.考虑到有同学不知道phantomjs怎么使用，这里我简要说一下吧。使用windows的同学先要去phantomjs官网下载它的可执行文件，然后设置环境变量。在命令行输入\"phantomjs some.js\"即可执行some.js文件，其实就和在命令行执行python或者java文件一样，如果不清楚的可以百度执行命令行执行python的方法，仿照着来就可以了，再不清楚就问我。使用ubuntu的同学可以直接用<strong>sudo apt-get install phantomjs</strong>，就可以安装使用了。我直接把加密的js文件使用phantomjs运行，果然好着呢。原因是因为phantomjs其实就是一款无ui的浏览器，自然支持navigator、window等属性。而pyexecjs支持使用phantomjs作为运行时环境，具体用法pyexecjs的git主页有，我也在代码中有所体现。&lt;/p&gt;\n&lt;pre&gt;\nwith open(\'G:/javascript/sinajs.js\',\'r\') as f:\n    source = f.read()\n    phantom = execjs.get(\'PhantomJS\')\n    getpass = phantom.compile(source)\n    mypass = getpass.call(\'get_pass\',my_pass,nonce,servertime,pubkey)\n&lt;/pre&gt;\n\n&lt;p&gt;这段代码就可以得到加密过后的密码了。&lt;/p&gt;\n&lt;p&gt;之后，便可以进行post提交，提交地址可以从抓包工具看到：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;http://login.sina.com.cn/sso/login.php?client=ssologin.js(v1.4.18)。&lt;/p&gt;\n</blockquote>\n&lt;p&gt;根据经验，到这里过程基本就完了。但是微博有点坑啊，这里还需要有一步,就是图一所示的类似&lt;/p&gt;\n<blockquote>\n&lt;p&gt;http://passport.weibo.com/wbsso/login?ssosavestate=1493447127&amp;url=http%3A%2F%2Fweibo.com%2Fajaxlogin.php\n%3Fframelogin%3D1%26callback%3Dparent.sinaSSOController.\nfeedBackUrlCallBack&amp;ticket=ST-NTc3NTg1MjMwNw==-1461911127-gz-1DE185DF04280D7E96BDCD14D9D8E235&amp;retcode=0&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这一步会将请求重定向，返回当前账号的登陆信息，如下图：\n&lt;img width=\"600px\" src=\"http://upload-images.jianshu.io/upload_images/1514374-825c8dd411743b67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"&gt;&lt;/p&gt;\n&lt;p&gt;那么问题来了，怎么获取上面的请求地址呢。分析上面地址，有ticket字段，这个应该是让你登陆的凭据，所以这个地址应该是服务端返回的，如果不是，起码ticket是服务端返回的，于是我们又使用抓包工具查看在请求这段url之前返回的信息，发现有和上述url吻合的信息：&lt;/p&gt;\n&lt;p&gt;&lt;img width=\"600px\" src=\"http://upload-images.jianshu.io/upload_images/1514374-a31ddc162d6ce914.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\"&gt;&lt;/p&gt;\n&lt;p&gt;这段代码是使用post后回复的内容，所以可以直接从中提取出我们需要的url。然后再使用get方式请求上述的url，它会经历一次重定向，直接返回登陆信息。这个时候，就代表成功登陆了。&lt;/p&gt;\n&lt;p&gt;PS:授人以鱼不如授人以渔，这是我一直秉承的信念。可能有的老手觉得我写得很啰嗦，但其实很多新手可能都不知道这些细节，所以我把我在分析新浪微博模拟登陆的过程全写了出来。另外，除了这种方式，本文提到的另外两种方式也有实现。最暴力的方式需要使用rsa这个第三方库，具体我在代码上有详细注释，还有一种是使用<strong>selenium+phantomjs</strong>这种方式，我也在代码中关键地方有注释。&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Talk is cheap，show me the code!&lt;/p&gt;\n</blockquote>\n&lt;p&gt;最后奉上本文的所有方式的模拟登陆代码（如果觉得喜欢或者看了对你有帮助，不妨在github上给个star，也欢迎fork）&lt;/p&gt;\n&lt;p&gt;<a href=\"https://github.com/ResolveWang/smart_login/blob/master/sina_login/sina_login_direct.py\">代码链接</a>，欢迎fork和<strong>star</strong>&lt;/p&gt;','前面已经讲过了[Python爬虫的预备知识](http://www.rookiefly.cn/detail/57)和[使用python模拟登陆csdn](http://www.rookiefly.cn/detail/65)，今天我将谈谈使用Python登陆新浪微博。\n\n该文章我在简书上写过，这里我把它引用过来，顺便进行一些修改和完善。\n\n一直在研究微博的爬虫，第一步便是模拟登陆，从开始摸索到走通模拟登陆这条路其实还是挺艰难的，需要一定的经验，为了让朋友们以后少走点弯路，这里我把我的分析过程和代码都附上来。\n\n首先，我们先用正常的账号登陆，具体看会有些什么请求。这里我用的是Http Analyzer抓包(Filders也是一个不错的选择)。下面是正常登陆流程的截图：\n\n<img width=\'600px\' src=\"http://upload-images.jianshu.io/upload_images/1514374-aa13818dfdbdd8f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" >\n\n接下来我会详细说明各个过程。\n\n第一步：预登陆。\n\n现在微博、空间等大型网站在输入用户名后基本都会做编码或者加密处理，这里在用户名输入框输入我的账号，通过抓包工具可以看到服务器会返回一段字符串：\n\n<img width=\'600px\' src=\"http://upload-images.jianshu.io/upload_images/1514374-affa0e2ac8848f62.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\">\n\n这一步就是预登陆过程，同学们可以自己试试。登陆的时候我们需要用到其中的servertime、nonce、pubkey等字段。当然这个不是我自己猜想的，后面的步骤会做说明。\n\n还有一点，就是预登陆的url:\n\n>http://login.sina.com.cn/sso/prelogin.php?entry=weibo&callback=sinaSSOController.preloginCallBack\n&su=&rsakt=mod&checkpin=1&client=ssologin.js(v1.4.18)\n&_=1461819359582\n\n\n\n这里su的值是自己用户名经过base64编码的值。但可能你们会问我是如何知道的呢，待会儿我会讲到。经过实测，如果我们这里不给su传参数，其实也是可以的。为了最真实的模拟用户登录，我们最好还是带上它的值。\n\n请看图一的第一条js请求**http://i.sso.sina.com.cn/js/ssologin.js**\n\n同学们可以点进去看，这个就是前面提到的加密用户名和密码等一系列的加密文件了，如果有同学非要问我是怎么找到这个加密文件的，我也只有说：反复抓包，从在浏览器输入weibo.com过后就找js文件请求路径，然后再用代码格式化工具打开，挨着一个一个看，在代码中搜关键字，比如这里我们可以搜\"nonce\"、“servertime”等，就能找到加密文件了。\n\n打开加密文件我们可以看到加密用户名的代码，在加密js文件中搜索\'username\'，可以看到有一行代码为:\n>username = sinaSSOEncoder.base64.encode(urlencode(username));  \n\n现在我们可以直接查找encode方法(代码太多就不贴上来了)，即可查找到对应方法了，为了验证我们的猜想，我们可以在webstorm中copy这个encode函数带上自己的用户名运行，返回的结果就是su的值，这个值在之后进行post提交的时候也会用到。如果对加密有一定经验的同学可能一眼就会看出这个是base64编码，python中有个base64模块可以干这个事情。我们再回到图一，\n>http://login.sina.com.cn/sso/login.php?client=ssologin.js(v1.4.18)  这个地址就是进行post提交数据的地址，下面是我自己提交的数据：\n\n<img width=\'600px\' src=\"http://upload-images.jianshu.io/upload_images/1514374-e2fb91272734ad1d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" >\n\n这里我们需要自己构造**su**(加密后的用户名),**sp**(加密后的密码),**servertime**,**nonce**，**rsakv**等数据，其它数据都不用变。有同学问我为哈其它数据不用变？你自己可以多登陆几次，看变化的值，那么那些值就是需要构造的值，其它值就直接拿过来用就行了。这里的su,servertime,nonce,rsakv都已经拿到了，所以当前需要的就只是sp的值了。我们还是按照原来的方法在js文件中查找“sp”,可以找到requests.sp=password这段代码，所以我们就只需要看password怎么构造的了。通过查找可以看到关键加密代码：\n\n>password = RSAKey.encrypt([me.servertime,me.nonce].join(\"\\t\") +\"\\n\"+ password)\n\n这一段代码便是加密密码的代码，有经验的同学一看就知道是用的RSA加密，python中也有相应的**rsa加密库**可用。但是我们假设大家都没看出来或者不知道python中有rsa这个第三方库。这时候就要给大家介绍一些我的经验了.\n\n我现在已经知道的有三种模拟登陆方案：\na)最简单暴力，效率也是最高的，直接把js源码转化为相应的python代码，模拟加密流程进行加密 \n\nb)使用selenium+phantomjs/firefox的方案直接模拟人的操作填写表单提交数据进行模拟登陆，这种方式最为简单，效率稍微低一些。如果有同学对这种简单暴力的方式感兴趣，可以到我的github上查看一下源码 \n\nc)比较折中的方案，通过pyv8/pyexecjs等渲染js代码进行执行，本文主要就是讲的这种方式。第一种方式如果是遇到微博调整了登陆加密算法，就必须改加密代码，第二种方式和第三种方式不存在这个问题。\n\n由于我用的是Python3，并不支持PyV8,所以我选了和它类似的**PyexecJS**,这个也可以直接执行js代码。我也不是很熟悉Javascript代码，所以我直接定义了一个函数处理加密密码，并没对其加密源代码修改太多：\n\n<pre>\n\nfunction get_pass(mypass,nonce,servertime,rsakey){\n	varRSAKey = newsinaSSOEncoder.RSAKey();\n	RSAKey.setPublic(rsakey,\"10001\");\n	password= RSAKey.encrypt([servertime,nonce].join(\"\\t\") +\"\\n\"+ mypass)\n	return password\n\n}\n</pre>\n\n这个函数中的东西其实就是copy的加密文件的加密过程代码。为了试验，我直接使用之前自己登陆抓到的nonce、servertime、rsakey等数据，在webstorm中调用这个函数，但是报错了，提示\"**navigator is undefined**\",webstorm 使用的nodejs的运行时环境，而navigator为浏览器的某个属性，所以运行会出问题。于是我就是**用phantomjs来作为运行时环境**.考虑到有同学不知道phantomjs怎么使用，这里我简要说一下吧。使用windows的同学先要去phantomjs官网下载它的可执行文件，然后设置环境变量。在命令行输入\"phantomjs some.js\"即可执行some.js文件，其实就和在命令行执行python或者java文件一样，如果不清楚的可以百度执行命令行执行python的方法，仿照着来就可以了，再不清楚就问我。使用ubuntu的同学可以直接用**sudo apt-get install phantomjs**，就可以安装使用了。我直接把加密的js文件使用phantomjs运行，果然好着呢。原因是因为phantomjs其实就是一款无ui的浏览器，自然支持navigator、window等属性。而pyexecjs支持使用phantomjs作为运行时环境，具体用法pyexecjs的git主页有，我也在代码中有所体现。\n\n<pre>\nwith open(\'G:/javascript/sinajs.js\',\'r\') as f:\n	source = f.read()\n	phantom = execjs.get(\'PhantomJS\')\n	getpass = phantom.compile(source)\n	mypass = getpass.call(\'get_pass\',my_pass,nonce,servertime,pubkey)\n</pre>\n这段代码就可以得到加密过后的密码了。\n\n之后，便可以进行post提交，提交地址可以从抓包工具看到：\n> http://login.sina.com.cn/sso/login.php?client=ssologin.js(v1.4.18)。\n\n根据经验，到这里过程基本就完了。但是微博有点坑啊，这里还需要有一步,就是图一所示的类似\n\n> http://passport.weibo.com/wbsso/login?ssosavestate=1493447127&url=http%3A%2F%2Fweibo.com%2Fajaxlogin.php\n%3Fframelogin%3D1%26callback%3Dparent.sinaSSOController.\nfeedBackUrlCallBack&ticket=ST-NTc3NTg1MjMwNw==-1461911127-gz-1DE185DF04280D7E96BDCD14D9D8E235&retcode=0\n\n这一步会将请求重定向，返回当前账号的登陆信息，如下图：\n<img width=\'600px\' src=\"http://upload-images.jianshu.io/upload_images/1514374-825c8dd411743b67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" >\n\n那么问题来了，怎么获取上面的请求地址呢。分析上面地址，有ticket字段，这个应该是让你登陆的凭据，所以这个地址应该是服务端返回的，如果不是，起码ticket是服务端返回的，于是我们又使用抓包工具查看在请求这段url之前返回的信息，发现有和上述url吻合的信息：\n\n<img width=\'600px\' src=\"http://upload-images.jianshu.io/upload_images/1514374-a31ddc162d6ce914.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" >\n\n这段代码是使用post后回复的内容，所以可以直接从中提取出我们需要的url。然后再使用get方式请求上述的url，它会经历一次重定向，直接返回登陆信息。这个时候，就代表成功登陆了。\n\nPS:授人以鱼不如授人以渔，这是我一直秉承的信念。可能有的老手觉得我写得很啰嗦，但其实很多新手可能都不知道这些细节，所以我把我在分析新浪微博模拟登陆的过程全写了出来。另外，除了这种方式，本文提到的另外两种方式也有实现。最暴力的方式需要使用rsa这个第三方库，具体我在代码上有详细注释，还有一种是使用**selenium+phantomjs**这种方式，我也在代码中关键地方有注释。\n\n>Talk is cheap，show me the code!\n\n最后奉上本文的所有方式的模拟登陆代码（如果觉得喜欢或者看了对你有帮助，不妨在github上给个star，也欢迎fork）\n\n[代码链接](https://github.com/ResolveWang/smart_login/blob/master/sina_login/sina_login_direct.py)，欢迎fork和**star**',1,'爬虫,python',1472739305,0,100,0,1,1),(84,'Python爬虫系列:(四)页面抓取','&lt;p&gt;<a href=\"http://rookiefly.cn/detail/83\">上一篇</a>我们讲了模拟登陆微博的相关知识，这一篇来简单聊聊网页抓取的一些知识。&lt;/p&gt;\n&lt;p&gt;在<a href=\"http://rookiefly.cn/detail/57\">爬虫预备知识</a>中我们谈到了http的几种常用请求方法，最常用的莫过于<strong>get/post</strong>两种方法，我们平时就是用这两种方法和页面进行交互，所以，如果爬虫想要获取到页面，也必须模拟这两种方法，好在目前存在很多优秀的http请求库，例如Python的<a href=\"http://docs.python-requests.org/zh_CN/latest/\">requests</a>、Java的<a href=\"https://hc.apache.org/httpcomponents-client-ga/\">httpclient</a>等，都封装了各种http请求。我们用的主要就是requests库，以微博页面为例，我们来看看它的用法吧(可能耐性看了上一篇<a href=\"http://rookiefly.cn/detail/83\">微博模拟登陆</a>的同学已经知道怎么用<strong>requests</strong>了，不过我还是啰嗦一下...)&lt;/p&gt;\n&lt;p&gt;最简单的，我们抓取微博首页：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r = requests.get(\'http://weibo.com\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这里的<em>r</em>是服务器响应内容，其中包括了html源码、状态码、响应头、编码方式等。&lt;/p&gt;\n<blockquote>\n&lt;p&gt;r.status_code&lt;/p&gt;\n&lt;p&gt;200&lt;/p&gt;\n&lt;p&gt;r.encoding&lt;/p&gt;\n&lt;p&gt;\'ISO-8859-1\'&lt;/p&gt;\n&lt;p&gt;r.text&lt;/p&gt;\n&lt;p&gt;网页源码&lt;/p&gt;\n</blockquote>\n&lt;p&gt;我再来说说这几者的作用。&lt;/p&gt;\n&lt;p&gt;<strong>status_code</strong>可用于返回的东西是否是符合规定的，比如我们请求一个不存在的网页，就会返回404,某些需要登陆的网页可能就会返回403等，所以有时候可以直接根据返回的状态码确定下一步的动作，比如是否需要做解析和存储，如果返回403是否需要通知用户账户状态不对...&lt;/p&gt;\n&lt;p&gt;即使是状态码就是200，返回的内容也不见得是我们想要的。当我们抓取微博内容时，即使是我们请求了一个不存在的微博连接，它的状态码仍是200，只是页面内容变化了。而我们可以通过<strong>r.text</strong>来获取页面内容&lt;/p&gt;\n&lt;p&gt;有的时候我们拿到了页面信息，却发现看不懂其中的内容，所以解析页面就无从下手了，比如微博搜索页面，就是这样。这个时候<strong>r.encoding</strong>就起作用了，可以这样用:\n&lt;pre&gt;\nr = requests.get(url)\n# 如果是乱码则设置为某种编码\nr.encoding=\'utf-8\'\ndata = r.text\nprint(data)\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;也可以这样用：\n&lt;pre&gt;\nr = requests.get(url)\ndata = r.text\nencode_data = data.encode(\'utf-8\', \'ignore\').decode(\'utf-8\', \'ignore\')\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;我一般是用的第二种方式。&lt;/p&gt;\n&lt;p&gt;其实关于编码的知识应该是页面解析部分知识了，先讲了...&lt;/p&gt;\n&lt;p&gt;&lt;hr&gt;\n刚讲的是最简单的请求情况，一般为了让爬虫伪装得更像真正的浏览器，我们都需要带上请求头参数(headers)，headers可以通过<strong>抓包软件</strong>进行获取和构造，也可以通过<strong>chrome按F12点击network</strong>查看请求头再模拟构造。它的数据结构在requests中是一个字典类型，目标服务器一般根据的是headers中的<strong>User-Agent</strong>、<strong>Referer</strong>、<strong>Cookie</strong>等信息来判断是否是爬虫，但是如果你如果在设置了这些参数后还是请求不到想要的信息，那么最好通过手动访问，把手动访问的所有headers信息都设置进来。&lt;/p&gt;\n&lt;p&gt;除了请求头参数，还有请求参数，请求参数是用一个dict进行封装的，然后用<strong>params=yourdict</strong>这种形式进行使用。下面是一个例子：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;requests.get(url, params={\'key\': \'test\'}, headers=yourheaders)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;常用的就是这么设置了，上面举的都是get的相关例子,对于用<strong>post提交表单也同样适用</strong>。如果需要特殊的一些用法，那么请查看<a href=\"http://docs.python-requests.org/zh_CN/latest/\">requests文档</a>。&lt;/p&gt;\n&lt;p&gt;关于页面抓取的知识差不多就说完了，许多还是要自己实践才能懂得并掌握的。这个系列的博客我会一直更新，直到我把微博相关的爬虫和自动化的爬取方式等高级内容讲完了，就不会更新了。&lt;/p&gt;\n&lt;p&gt;&lt;hr&gt;\n奉上我的微博爬虫的github地址，觉得有用就给个star吧(渴求.jpg):<a href=\"https://github.com/ResolveWang/WeiboSpider\">WeiboSpider</a>&lt;/p&gt;','[上一篇](http://rookiefly.cn/detail/83)我们讲了模拟登陆微博的相关知识，这一篇来简单聊聊网页抓取的一些知识。\n\n在[爬虫预备知识](http://rookiefly.cn/detail/57)中我们谈到了http的几种常用请求方法，最常用的莫过于**get/post**两种方法，我们平时就是用这两种方法和页面进行交互，所以，如果爬虫想要获取到页面，也必须模拟这两种方法，好在目前存在很多优秀的http请求库，例如Python的[requests](http://docs.python-requests.org/zh_CN/latest/)、Java的[httpclient](https://hc.apache.org/httpcomponents-client-ga/)等，都封装了各种http请求。我们用的主要就是requests库，以微博页面为例，我们来看看它的用法吧(可能耐性看了上一篇[微博模拟登陆](http://rookiefly.cn/detail/83)的同学已经知道怎么用**requests**了，不过我还是啰嗦一下...)\n\n最简单的，我们抓取微博首页：\n> r = requests.get(\'http://weibo.com\')\n\n这里的*r*是服务器响应内容，其中包括了html源码、状态码、响应头、编码方式等。\n> r.status_code\n\n> 200\n\n> r.encoding\n\n> \'ISO-8859-1\'\n\n> r.text\n\n> 网页源码\n\n我再来说说这几者的作用。\n\n**status_code**可用于返回的东西是否是符合规定的，比如我们请求一个不存在的网页，就会返回404,某些需要登陆的网页可能就会返回403等，所以有时候可以直接根据返回的状态码确定下一步的动作，比如是否需要做解析和存储，如果返回403是否需要通知用户账户状态不对...\n\n即使是状态码就是200，返回的内容也不见得是我们想要的。当我们抓取微博内容时，即使是我们请求了一个不存在的微博连接，它的状态码仍是200，只是页面内容变化了。而我们可以通过**r.text**来获取页面内容\n\n有的时候我们拿到了页面信息，却发现看不懂其中的内容，所以解析页面就无从下手了，比如微博搜索页面，就是这样。这个时候**r.encoding**就起作用了，可以这样用:\n<pre>\nr = requests.get(url)\n\\# 如果是乱码则设置为某种编码\nr.encoding=\'utf-8\'\ndata = r.text\nprint(data)\n</pre>\n\n也可以这样用：\n<pre>\nr = requests.get(url)\ndata = r.text\nencode_data = data.encode(\'utf-8\', \'ignore\').decode(\'utf-8\', \'ignore\')\n</pre>\n\n我一般是用的第二种方式。\n\n其实关于编码的知识应该是页面解析部分知识了，先讲了...\n\n<hr>\n刚讲的是最简单的请求情况，一般为了让爬虫伪装得更像真正的浏览器，我们都需要带上请求头参数(headers)，headers可以通过**抓包软件**进行获取和构造，也可以通过**chrome按F12点击network**查看请求头再模拟构造。它的数据结构在requests中是一个字典类型，目标服务器一般根据的是headers中的**User-Agent**、**Referer**、**Cookie**等信息来判断是否是爬虫，但是如果你如果在设置了这些参数后还是请求不到想要的信息，那么最好通过手动访问，把手动访问的所有headers信息都设置进来。\n\n除了请求头参数，还有请求参数，请求参数是用一个dict进行封装的，然后用**params=yourdict**这种形式进行使用。下面是一个例子：\n> requests.get(url, params={\'key\': \'test\'}, headers=yourheaders)\n\n常用的就是这么设置了，上面举的都是get的相关例子,对于用**post提交表单也同样适用**。如果需要特殊的一些用法，那么请查看[requests文档](http://docs.python-requests.org/zh_CN/latest/)。\n\n关于页面抓取的知识差不多就说完了，许多还是要自己实践才能懂得并掌握的。这个系列的博客我会一直更新，直到我把微博相关的爬虫和自动化的爬取方式等高级内容讲完了，就不会更新了。\n\n<hr>\n奉上我的微博爬虫的github地址，觉得有用就给个star吧(渴求.jpg):[WeiboSpider](https://github.com/ResolveWang/WeiboSpider)\n',1,'python,爬虫',1473253721,0,53,0,1,1),(85,'linux终端使用shadowsocks客户端科学上网','<p>最近，由于项目需要使用<em>google</em>搜索的<em>API</em>,但是爬虫服务器使用的是<em>Centos</em>，而且没有安装图形化界面，所以只有使用终端翻墙。我采用的方案是<strong>shadowsocks</strong>,下面是客户端安装和配置的过程。</p>\n<hr>\n\n<h3>1.安装和配置shadowsocks</h3>\n<p>在<strong>Ubuntu</strong>/<strong>CentOS</strong>中安装shadowsocks很简单，使用<strong>pip</strong>即可进行安装：</p>\n<blockquote>\n<p>pip install shadowsocks</p>\n</blockquote>\n<p>然后把shadowsocks的服务器和本地信息写在配置文件中:</p>\n<blockquote>\n<p>vim /etc/shadowsocks.json</p>\n</blockquote>\n<p>配置文件以<strong>json</strong>格式保存,详细信息如下：\n<pre>\n{\n    \"server\":\"216.189.158.147\",\n    \"server_port\":39579,\n    \"local_address\": \"127.0.0.1\",\n    \"local_port\":1080,\n    \"password\":\"dou-bi.co39579\",\n    \"timeout\":300,\n    \"method\":\"chacha20\",\n    \"fast_open\": false\n}\n</pre></p>\n<p><em>server</em>代表shadowsocks服务器IP，<em>server_port</em>是服务器端口，<em>local_address</em>是本地IP, <em>local_port</em>为本地端口(默认为<strong>1080</strong>),<em>password</em>是shadowsocks账号的密码, <em>timeout</em>是超时时间，<em>method</em>为加密方式，<em>fast_open</em>默认设置为<strong>false</strong>。</p>\n<p>至此，关于ss的安装和配置就讲完了。可以通过后台启动运行和停止ss:</p>\n<blockquote>\n<p>启动：sslocal -c /etc/shadowsocks.json -d start</p>\n<p>停止：sslocal -c /etc/shadowsocks.json -d stop</p>\n</blockquote>\n<p>如果服务器用的<strong>CentOS</strong>，可能会报错:<strong>libsodium not found</strong>,所以我们需要安装和配置<em>libsodium</em>,它的安装和配置方法如下：</p>\n<blockquote>\n<p>wget https://download.libsodium.org/libsodium/releases/LATEST.tar.gz</p>\n<p>tar zxf LATEST.tar.gz</p>\n<p>cd libsodium*</p>\n<p>./configure</p>\n<p>make &amp;&amp; make install</p>\n</blockquote>\n<p># 修复关联</p>\n<blockquote>\n<p>echo /usr/local/lib &gt; /etc/ld.so.conf.d/usr_local_lib.conf</p>\n<p>ldconfig</p>\n</blockquote>\n<p>如果第一步通过<strong>wget</strong>下载<em>libsodium</em>失败的话，那么请在其<a href=\"https://download.libsodium.org/libsodium/releases/\">官网</a>手动下载<strong>.tar.gz</strong>文件,再安装上述步骤执行。顺利的话，就可以直接在后台启动ss客户端了</p>\n<p>光安装并运行了ss的客户端，还是不能使用终端访问google。SS使用socks5协议，而终端很多工具目前只支持http和https等协议，所以我们为终端设置Shadowsocks的思路就是将socks5协议转换成http协议。而Proxychains4就是linux平台上很好用的这么一个工具。</p>\n<hr>\n\n<h3>2.安装配置Proxychains4</h3>\n<p>该项目开源在github上，项目地址为:<a href=\"https://github.com/rofl0r/proxychains-ng\">proxychains-ng</a>。下面是安装和配置方法：\n<pre>\ngit clone https://github.com/rofl0r/proxychains-ng.git\ncd proxychains-ng\n./configure\nmake &amp;&amp; make install\ncp ./src/proxychains.conf /etc/proxychains.conf\ncd .. &amp;&amp; rm -rf proxychains-ng\n</pre></p>\n<p>再修改proxychains4的配置:</p>\n<blockquote>\n<p>vim /etc/proxychains.conf</p>\n</blockquote>\n<p>将<strong>socks4 127.0.0.1 9095</strong>改为<strong>socks5 127.0.0.1 1080</strong></p>\n<p>至此，便可以使用终端配合<strong>proxychains4+SS</strong>访问墙外的网站了，使用方式为:</p>\n<blockquote>\n<p>proxychains4 + 命令</p>\n</blockquote>\n<p>比如获取google搜索页面:</p>\n<blockquote>\n<p>proxychains4 wget https://www.google.com</p>\n</blockquote>\n<p>又比如现在查看我们使用的IP:</p>\n<blockquote>\n<p>proxychains4 curl ip.gs</p>\n<p>当前 IP：216.189.158.147 来自：美国加利福尼亚州洛杉矶 hostus.us</p>\n</blockquote>\n<p>如果不使用proxychains4的话：</p>\n<blockquote>\n<p>curl ip.gs</p>\n<p>当前 IP：202.115.<strong>.</strong> 来自：中国四川成都四川联合大学 教育网</p>\n</blockquote>\n<hr>\n\n<p>刚刚那个是局部代理，如果需要全局代理，可以考虑<strong>Polipo</strong>，听说很好用，具体用法请参考<a href=\"https://www.irif.univ-paris-diderot.fr/~jch/software/polipo/\">官网</a>和它的<a href=\"https://github.com/jech/polipo\">github项目地址</a>。我没有试过，所以就不多写了。</p>\n<p>最后，推荐一个比较好的网站，用于<strong>免费获取ss账号</strong>，很良心的一个站：<a href=\"https://www.dou-bi.co/sszhfx/\">逗比根据地</a>。</p>','最近，由于项目需要使用*google*搜索的*API*,但是爬虫服务器使用的是*Centos*，而且没有安装图形化界面，所以只有使用终端翻墙。我采用的方案是**shadowsocks**,下面是客户端安装和配置的过程。\n\n<hr>\n\n###1.安装和配置shadowsocks\n在**Ubuntu**/**CentOS**中安装shadowsocks很简单，使用**pip**即可进行安装：\n> pip install shadowsocks\n\n然后把shadowsocks的服务器和本地信息写在配置文件中:\n> vim /etc/shadowsocks.json\n\n配置文件以**json**格式保存,详细信息如下：\n<pre>\n{\n    \"server\":\"216.189.158.147\",\n    \"server_port\":39579,\n    \"local_address\": \"127.0.0.1\",\n    \"local_port\":1080,\n    \"password\":\"dou-bi.co39579\",\n    \"timeout\":300,\n    \"method\":\"chacha20\",\n    \"fast_open\": false\n}\n</pre>\n\n*server*代表shadowsocks服务器IP，*server_port*是服务器端口，*local_address*是本地IP, *local_port*为本地端口(默认为**1080**),*password*是shadowsocks账号的密码, *timeout*是超时时间，*method*为加密方式，*fast_open*默认设置为**false**。\n\n至此，关于ss的安装和配置就讲完了。可以通过后台启动运行和停止ss:\n>启动：sslocal -c /etc/shadowsocks.json -d start\n\n>停止：sslocal -c /etc/shadowsocks.json -d stop\n\n如果服务器用的**CentOS**，可能会报错:**libsodium not found**,所以我们需要安装和配置*libsodium*,它的安装和配置方法如下：\n>wget https://download.libsodium.org/libsodium/releases/LATEST.tar.gz\n\n>tar zxf LATEST.tar.gz\n\n>cd libsodium*\n\n>./configure\n\n>make && make install\n\n\\# 修复关联\n> echo /usr/local/lib > /etc/ld.so.conf.d/usr_local_lib.conf\n\n>ldconfig\n\n如果第一步通过**wget**下载*libsodium*失败的话，那么请在其[官网](https://download.libsodium.org/libsodium/releases/)手动下载**.tar.gz**文件,再安装上述步骤执行。顺利的话，就可以直接在后台启动ss客户端了\n\n光安装并运行了ss的客户端，还是不能使用终端访问google。SS使用socks5协议，而终端很多工具目前只支持http和https等协议，所以我们为终端设置Shadowsocks的思路就是将socks5协议转换成http协议。而Proxychains4就是linux平台上很好用的这么一个工具。\n\n<hr>\n\n###2.安装配置Proxychains4\n该项目开源在github上，项目地址为:[proxychains-ng](https://github.com/rofl0r/proxychains-ng)。下面是安装和配置方法：\n<pre>\ngit clone https://github.com/rofl0r/proxychains-ng.git\ncd proxychains-ng\n./configure\nmake && make install\ncp ./src/proxychains.conf /etc/proxychains.conf\ncd .. && rm -rf proxychains-ng\n</pre>\n\n再修改proxychains4的配置:\n>vim /etc/proxychains.conf\n\n将**socks4 127.0.0.1 9095**改为**socks5 127.0.0.1 1080**\n\n至此，便可以使用终端配合**proxychains4+SS**访问墙外的网站了，使用方式为:\n> proxychains4 + 命令\n\n比如获取google搜索页面:\n> proxychains4 wget https://www.google.com\n\n又比如现在查看我们使用的IP:\n> proxychains4 curl ip.gs\n\n> 当前 IP：216.189.158.147 来自：美国加利福尼亚州洛杉矶 hostus.us\n\n如果不使用proxychains4的话：\n> curl ip.gs\n\n>当前 IP：202.115.**.** 来自：中国四川成都四川联合大学 教育网\n\n\n<hr>\n\n刚刚那个是局部代理，如果需要全局代理，可以考虑**Polipo**，听说很好用，具体用法请参考[官网](https://www.irif.univ-paris-diderot.fr/~jch/software/polipo/)和它的[github项目地址](https://github.com/jech/polipo)。我没有试过，所以就不多写了。\n\n最后，推荐一个比较好的网站，用于**免费获取ss账号**，很良心的一个站：[逗比根据地](https://www.dou-bi.co/sszhfx/)。\n',3,'科学上网',1473840802,0,80,0,1,1),(86,'CentOS安装Python','&lt;p&gt;服务器上(<strong>centos6.5</strong>)的Python版本是2.4,太落后了，好在服务器上没有部署python程序，所以我就打算折腾一下，打算把Python版本升级到3.5。&lt;/p&gt;\n&lt;p&gt;过程如下：\n1.<a href=\"https://www.python.org/downloads/release/python-352/\">官网</a>下载python源代码，可以通过wget在服务器上下载:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;wget https://www.python.org/ftp/python/3.5.2/Python-3.5.2.tgz&lt;/p&gt;\n</blockquote>\n&lt;p&gt;但是我们服务器网速太慢！所以我只好本地下载好了用xshell上传过去。&lt;/p&gt;\n&lt;p&gt;2.解压&lt;/p&gt;\n<blockquote>\n&lt;p&gt;tar -zxvf Python-3.5.2.tgz&lt;/p&gt;\n</blockquote>\n&lt;p&gt;3.切换到解压后的目录&lt;/p&gt;\n<blockquote>\n&lt;p&gt;cd Python-3.5.2&lt;/p&gt;\n</blockquote>\n&lt;p&gt;如果我们现在直接执行 <em>make &amp;&amp; make install</em>的话，那么可能就没有安装ssl模块，这个模块很多情况下都会用到，所以我们需要安装&lt;/p&gt;\n&lt;p&gt;4.切换到Module目录下，去掉关于SSL模块的注释&lt;/p&gt;\n<blockquote>\n&lt;p&gt;cd Modules&lt;/p&gt;\n&lt;p&gt;vim Setpy.dist /如果是python2.7，那么这里就是vim Setup&lt;/p&gt;\n</blockquote>\n&lt;p&gt;找到下面这段代码：\n&lt;pre&gt;\n# Socket module helper for SSL support; you must comment out the other\n# socket line above, and possibly edit the SSL variable:\n# SSL=/usr/local/ssl\n# _ssl _ssl.c \\\n#      -DUSE_SSL -I$(SSL)/include -I$(SSL)/include/openssl \\\n#      -L$(SSL)/lib -lssl -lcrypto\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;修改为下面所示:\n&lt;pre&gt;\n# Socket module helper for SSL support; you must comment out the other\n# socket line above, and possibly edit the SSL variable:\n# SSL=/usr/local/ssl\n _ssl _ssl.c \\\n    -DUSE_SSL -I$(SSL)/include -I$(SSL)/include/openssl \\\n    -L$(SSL)/lib -lssl -lcrypto\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;如果是没有安装openssl-devel的话,还需要安装<strong>openssl-devel包</strong>&lt;/p&gt;\n<blockquote>\n&lt;p&gt;yum install openssl-devel -y&lt;/p&gt;\n</blockquote>\n&lt;p&gt;5.编译安装Python&lt;/p&gt;\n<blockquote>\n&lt;p&gt;cd ..&lt;/p&gt;\n&lt;p&gt;./configure&lt;/p&gt;\n&lt;p&gt;make &amp;&amp; make install&lt;/p&gt;\n</blockquote>\n&lt;p&gt;如果没安装gcc的话，编译会失败，安装方式如下&lt;/p&gt;\n<blockquote>\n&lt;p&gt;yum install gcc&lt;/p&gt;\n</blockquote>\n&lt;p&gt;6.给Python3.52建立软连接&lt;/p&gt;\n<blockquote>\n&lt;p&gt;rm -f /usr/bin/python&lt;/p&gt;\n&lt;p&gt;ln -s /usr/local/bin/python3 /usr/bin/python&lt;/p&gt;\n</blockquote>\n&lt;p&gt;至此，关于Python3.5的安装的整个过程就结束了。Python2.x的安装过程也和上面写的一样。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;使用这种方式升级Python的话会<strong>导致yum不能使用</strong>,原因是yum默认使用系统自带的python版本，解决方法如下：&lt;/p&gt;\n&lt;p&gt;修改yum文件:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;vi /usr/bin/yum&lt;/p&gt;\n</blockquote>\n&lt;p&gt;将文件头部的&lt;/p&gt;\n<blockquote>\n&lt;p&gt;#!/usr/bin/python&lt;/p&gt;\n</blockquote>\n&lt;p&gt;改为如下内容&lt;/p&gt;\n<blockquote>\n&lt;p&gt;#!/usr/bin/python2.4&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这里python2.4是我们组的服务器<strong>系统自带</strong>的python版本,所以大家需要根据自身情况改成自己系统自带的python版本&lt;/p&gt;\n&lt;p&gt;整个升级过程完成了。&lt;/p&gt;','服务器上(**centos6.5**)的Python版本是2.4,太落后了，好在服务器上没有部署python程序，所以我就打算折腾一下，打算把Python版本升级到3.5。\n\n过程如下：\n1.[官网](https://www.python.org/downloads/release/python-352/)下载python源代码，可以通过wget在服务器上下载:\n> wget https://www.python.org/ftp/python/3.5.2/Python-3.5.2.tgz\n\n但是我们服务器网速太慢！所以我只好本地下载好了用xshell上传过去。\n\n2.解压\n> tar -zxvf Python-3.5.2.tgz\n\n3.切换到解压后的目录\n> cd Python-3.5.2\n\n如果我们现在直接执行 *make && make install*的话，那么可能就没有安装ssl模块，这个模块很多情况下都会用到，所以我们需要安装\n\n4.切换到Module目录下，去掉关于SSL模块的注释\n> cd Modules\n\n> vim Setpy.dist /如果是python2.7，那么这里就是vim Setup\n\n找到下面这段代码：\n<pre>\n\\# Socket module helper for SSL support; you must comment out the other\n\\# socket line above, and possibly edit the SSL variable:\n\\# SSL=/usr/local/ssl\n\\# _ssl _ssl.c \\\n\\#  	-DUSE_SSL -I$(SSL)/include -I$(SSL)/include/openssl \\\n\\#  	-L$(SSL)/lib -lssl -lcrypto\n</pre>\n\n修改为下面所示:\n<pre>\n\\# Socket module helper for SSL support; you must comment out the other\n\\# socket line above, and possibly edit the SSL variable:\n\\# SSL=/usr/local/ssl\n _ssl _ssl.c \\\n 	-DUSE_SSL -I$(SSL)/include -I$(SSL)/include/openssl \\\n 	-L$(SSL)/lib -lssl -lcrypto\n</pre>\n\n如果是没有安装openssl-devel的话,还需要安装**openssl-devel包**\n> yum install openssl-devel -y\n\n5.编译安装Python\n> cd ..\n\n> ./configure\n\n> make && make install\n\n如果没安装gcc的话，编译会失败，安装方式如下\n> yum install gcc\n\n6.给Python3.52建立软连接\n> rm -f /usr/bin/python\n\n> ln -s /usr/local/bin/python3 /usr/bin/python\n\n至此，关于Python3.5的安装的整个过程就结束了。Python2.x的安装过程也和上面写的一样。\n\n<hr>\n\n使用这种方式升级Python的话会**导致yum不能使用**,原因是yum默认使用系统自带的python版本，解决方法如下：\n\n修改yum文件:\n\n>vi /usr/bin/yum\n\n将文件头部的\n> \\#!/usr/bin/python\n\n改为如下内容\n> \\#!/usr/bin/python2.4\n\n这里python2.4是我们组的服务器**系统自带**的python版本,所以大家需要根据自身情况改成自己系统自带的python版本\n\n整个升级过程完成了。\n\n',1,'python',1474179369,0,30,0,1,1),(90,'CentOS上为Python安装pip或者setuptools','&lt;p&gt;<a href=\"rookiefly.cn/detail/86\">上一篇文章</a>是关于Python安装的，这一篇是对它的完善，聊一下怎么安装<strong>pip</strong>等包管理工具。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;最顺利的方式是这样的:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;yum install python-setuptools&lt;/p&gt;\n</blockquote>\n&lt;p&gt;如果需要安装pip,那么只需要：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;easy_install pip&lt;/p&gt;\n</blockquote>\n&lt;p&gt;可是，我使用yum安装setuptools的时候，虽然安装成功了，但是却用不了easy_install，总报一堆错误。后面我使用源码安装的方式。&lt;/p&gt;\n&lt;p&gt;1.到<a href=\"https://github.com/pypa/setuptools\">github项目地址</a>上找到setuptools的安装说明，按照说明输入以下命令：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;wget https://bootstrap.pypa.io/ez_setup.py -O - | python&lt;/p&gt;\n</blockquote>\n&lt;p&gt;如果顺利，那么直接就安装好了setuptools了，可以使用easy_install安装pip&lt;/p&gt;\n&lt;p&gt;不顺利的话，就是像我这样，在服务器上，下载过程中出现了<strong>ERROR: certificate common name...</strong>，原因是证书问题，可以通过添加以下参数(即不验证证书)解决：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;wget --no-check-certificate https://bootstrap.pypa.io/ez_setup.py -O - | python&lt;/p&gt;\n</blockquote>\n&lt;p&gt;然后又出现了下面错误:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;subprocess.CalledProcessError: Command \'[\'wget\', \'https://pypi.io/packages/source/s/setuptools/setuptools-27.2.0.zip\', \'--quiet\', \'--output-document\', \'/root/Python-3.5.2/setuptools-27.2.0.zip\']\'&lt;/p&gt;\n</blockquote>\n&lt;p&gt;原因也是一样的，下载<strong>setuptools-27.2.0.zip</strong>的时候验证ssl证书失败，那么我们直接手动下载下来试试:&lt;/p&gt;\n<blockquote>\n&lt;p&gt;wget --no-check-certificate https://pypi.io/packages/source/s/setuptools/setuptools-27.2.0.zip&lt;/p&gt;\n</blockquote>\n&lt;p&gt;2.执行第一步的命令&lt;/p&gt;\n<blockquote>\n&lt;p&gt;wget https://bootstrap.pypa.io/ez_setup.py -O - | python&lt;/p&gt;\n</blockquote>\n&lt;p&gt;安装顺利完成，使用easy_install或者pip安装requests试试：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;easy_install requests&lt;/p&gt;\n</blockquote>\n&lt;p&gt;过程很顺利，所以搞定！&lt;/p&gt;','[上一篇文章](rookiefly.cn/detail/86)是关于Python安装的，这一篇是对它的完善，聊一下怎么安装**pip**等包管理工具。\n\n<hr>\n\n最顺利的方式是这样的:\n> yum install python-setuptools\n\n如果需要安装pip,那么只需要：\n> easy_install pip\n\n可是，我使用yum安装setuptools的时候，虽然安装成功了，但是却用不了easy_install，总报一堆错误。后面我使用源码安装的方式。\n\n1.到[github项目地址](https://github.com/pypa/setuptools)上找到setuptools的安装说明，按照说明输入以下命令：\n> wget https://bootstrap.pypa.io/ez_setup.py -O - | python\n\n如果顺利，那么直接就安装好了setuptools了，可以使用easy_install安装pip\n\n不顺利的话，就是像我这样，在服务器上，下载过程中出现了**ERROR: certificate common name...**，原因是证书问题，可以通过添加以下参数(即不验证证书)解决：\n> wget \\-\\-no-check-certificate https://bootstrap.pypa.io/ez_setup.py -O - | python\n\n然后又出现了下面错误:\n>subprocess.CalledProcessError: Command \'[\'wget\', \'https://pypi.io/packages/source/s/setuptools/setuptools-27.2.0.zip\', \'--quiet\', \'--output-document\', \'/root/Python-3.5.2/setuptools-27.2.0.zip\']\'\n\n原因也是一样的，下载**setuptools-27.2.0.zip**的时候验证ssl证书失败，那么我们直接手动下载下来试试:\n> wget \\-\\-no-check-certificate https://pypi.io/packages/source/s/setuptools/setuptools-27.2.0.zip\n\n2.执行第一步的命令\n>  wget https://bootstrap.pypa.io/ez_setup.py -O - | python\n\n安装顺利完成，使用easy_install或者pip安装requests试试：\n> easy_install requests\n\n过程很顺利，所以搞定！',1,'python',1474182514,0,36,0,1,1),(91,'CentOS下安装git','<p>高产似母猪啊，再来一篇CentOS下安装git的文章，因为我发现网上已有的文章都比较老了，我也遇到很多坑，所以记录下来。</p>\n<p>CentOS下yum源中好像并没有git，只有通过源代码的方式安装。</p>\n<p>1.到<a href=\"https://github.com/git/git/releases/tag/v2.10.0\">git项目地址</a>下载其releases的源代码,我这里下载的是最新的2.1版本。</p>\n<blockquote>\n<p>wget https://github.com/git/git/archive/v2.10.0.tar.gz</p>\n</blockquote>\n<p>2.解压下载的文件并切换到解压的文件夹</p>\n<blockquote>\n<p>tar -zxvf v2.10.0 </p>\n<p>cd git-2.10.0/</p>\n</blockquote>\n<p>3.编译并且安装</p>\n<blockquote>\n<p>make &amp;&amp; make install </p>\n</blockquote>\n<p>出现错误</p>\n<blockquote>\n<p>warning: curl/curl.h: No such file or directory...</p>\n<p>warning: curl/easy.h: No such file or directory...</p>\n</blockquote>\n<p>4.安装curl-devel等包</p>\n<blockquote>\n<p>yum -y install zlib-devel openssl-devel perl cpio expat-devel gettext-devel openssl zlib curl curl-devel</p>\n</blockquote>\n<p>5.编译并且安装</p>\n<blockquote>\n<p>make &amp;&amp; make install </p>\n</blockquote>\n<p>并没有出现什么问题，输入<em>git</em>测试，果然安装成功</p>','高产似母猪啊，再来一篇CentOS下安装git的文章，因为我发现网上已有的文章都比较老了，我也遇到很多坑，所以记录下来。\n\nCentOS下yum源中好像并没有git，只有通过源代码的方式安装。\n\n1.到[git项目地址](https://github.com/git/git/releases/tag/v2.10.0)下载其releases的源代码,我这里下载的是最新的2.1版本。\n> wget https://github.com/git/git/archive/v2.10.0.tar.gz\n\n2.解压下载的文件并切换到解压的文件夹\n> tar -zxvf v2.10.0 \n\n> cd git-2.10.0/\n\n3.编译并且安装\n> make && make install \n\n出现错误\n> warning: curl/curl.h: No such file or directory...\n\n> warning: curl/easy.h: No such file or directory...\n\n4.安装curl-devel等包\n> yum -y install zlib-devel openssl-devel perl cpio expat-devel gettext-devel openssl zlib curl curl-devel\n\n5.编译并且安装\n> make && make install \n\n并没有出现什么问题，输入*git*测试，果然安装成功\n\n',1,'linux,git',1474199468,0,32,0,1,1),(92,'Requests使用socks5代理爬取网页','&lt;p&gt;<a href=\"http://rookiefly.cn/detail/85\">前面谋篇文章</a>写了<strong>关于shadowsocks</strong>的配置，目的就是为了使用google搜索，shadowsocks使用的是<strong>socks5</strong>，我们可以直接拿来为采集程序所用。&lt;/p&gt;\n&lt;p&gt;在<strong>requests</strong>中使用<strong>socks5</strong>代理很简单,要求<strong>requests版本高于2.10</strong>,并且安装有<a href=\"https://github.com/Anorov/PySocks\"><strong>pysocks</strong></a>这个模块。可以通过 <strong>pip list | grep requests</strong> 查看到当前requests的版本，我的requests版本为2.12，下面是使用requests+shadowsocks访问google的一个demo:&lt;/p&gt;\n&lt;pre&gt;\nimport requests\n\nproxies = {\n            \'http\': \'socks5://127.0.0.1:1080\',\n            \'https\': \'socks5://127.0.0.1:1080\'\n          }\n\nr = requests.get(\'https://www.google.com\', proxies=proxies)\nprint(r.text)\n&lt;/pre&gt;\n\n&lt;p&gt;就这么简单&lt;/p&gt;','[前面谋篇文章](http://rookiefly.cn/detail/85)写了**关于shadowsocks**的配置，目的就是为了使用google搜索，shadowsocks使用的是**socks5**，我们可以直接拿来为采集程序所用。\n\n在**requests**中使用**socks5**代理很简单,要求**requests版本高于2.10**,并且安装有[**pysocks**](https://github.com/Anorov/PySocks)这个模块。可以通过 **pip list | grep requests** 查看到当前requests的版本，我的requests版本为2.12，下面是使用requests+shadowsocks访问google的一个demo:\n\n<pre>\nimport requests\n\nproxies = {\n            \'http\': \'socks5://127.0.0.1:1080\',\n            \'https\': \'socks5://127.0.0.1:1080\'\n          }\n\nr = requests.get(\'https://www.google.com\', proxies=proxies)\nprint(r.text)\n</pre>\n\n就这么简单',1,'爬虫',1474204003,0,28,0,1,1),(93,'IDEA导入外部Jar包','<p>由于需要使用Java实现socks5代理配合ss访问google,项目选的是httpclient，我使用的是<strong>IDEA</strong>,下面是IDEA导入Httpclient的方法</p>\n<blockquote>\n<p>File -&gt; Project Structure -&gt; Modules -&gt; Dependencies -&gt; + -&gt; JARs or directories</p>\n</blockquote>\n<p>使用<em>ctrl+鼠标左键</em>进行连选，点击<em>Apply</em>即可</p>','由于需要使用Java实现socks5代理配合ss访问google,项目选的是httpclient，我使用的是**IDEA**,下面是IDEA导入Httpclient的方法\n\n> File -> Project Structure -> Modules -> Dependencies -> + -> JARs or directories\n\n使用*ctrl+鼠标左键*进行连选，点击*Apply*即可',1,'java',1474268767,0,20,0,1,1),(94,'怎么在开源项目中隐藏密码等敏感信息','&lt;p&gt;应该也有人像我一样，可能在上传代码的时候不小心将包含用户名和密码等的配置文件连同代码一起上传至了github，这个问题以前并没有引起我的重视，因为我觉得拥抱开源的程序猿都是心地善良、朴实的。直到某一天我发现我的新浪邮箱被异地登陆了，断定肯定是有人在我的<a href=\"https://github.com/ResolveWang/WeiboSpider\">微博爬虫</a>中使用了配置文件中的账号和密码,这个问题才被我真正重视起来。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;截至目前所知，我找到以下几种方法隐藏自己的敏感信息&lt;/p&gt;\n&lt;p&gt;1.将密码等敏感信息设置到当前环境变量中去.&lt;/p&gt;\n&lt;p&gt;以Python为例来简单说明一下:&lt;/p&gt;\n&lt;p&gt;比如我们通过手动设置环境变量<strong>\"weibo_pass\":\"123456\"</strong>,那么可以在Python中这样读出来&lt;/p&gt;\n<blockquote>\n&lt;p&gt;os.getenv(\'weibo_pass\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这种方式有一个缺点就是程序部署到别的机器上，就得自己再设置一次环境变量&lt;/p&gt;\n&lt;p&gt;2.将敏感信息写入数据库，从数据库中读出来&lt;/p&gt;\n&lt;p&gt;这种方法也要注意数据库配置文件的安全问题，不能由于疏忽而上传...&lt;/p&gt;\n&lt;p&gt;3.从公司内联网的服务器或者代理中获取&lt;/p&gt;\n&lt;p&gt;这种方法就不多说了&lt;/p&gt;\n&lt;p&gt;4.可以将包含敏感信息的源码先编译，然后再从编译过后的字节码文件中获取。这里我还是以python为例来说明&lt;/p&gt;\n&lt;p&gt;Python代码经过编译过后会生成<strong>.pyc文件</strong>，关于<strong>.pyc</strong>文件的相关知识我会在之后的文章介绍，这里就不详细说了。&lt;/p&gt;\n&lt;p&gt;我们有两个python文件，一个名为<em>foo.py</em>，一个名为<em>demo.py</em>,内容分别如下：&lt;/p&gt;\n&lt;pre&gt;\n\\# foo.py\nname = \'resolvewang\'\npassword = \'he is handsome\'\n&lt;/pre&gt;\n\n&lt;pre&gt;\n\\# demo.py, using python3.5\nimport importlib\n\ndef demo_func(name, password):\n    print(\',\'.join([name, password]))\n\nif __name__ == \'__main__\':\n    foo = importlib.import_module(\'foo\', \'f:/pyprogram/foo.pyc\')\n    demo_func(foo.name, foo.password)\n&lt;/pre&gt;\n\n&lt;p&gt;这里，我们先手动将foo.py编译为<em>.pyc</em>文件，代码如下：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;import py_compile\npy_compile.compile(\'foo.py\', \'f:/pyprogram/foo.pyc\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;执行完上述代码后，就会在F盘的pyprogram目录下生成<em>foo.pyc</em>,我们再执行<strong>demo.py</strong>,则可以看到以下结果：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;resolvewang,he is handsome&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这样其实就成功隐藏了敏感信息。其实这样也有一个不安全的地方，编译后的文件可以通过反编译破解。不过我觉得一般很少会有程序猿来干这么无聊并且不道德的事，毕竟我们都很善良QAQ.&lt;/p&gt;\n&lt;p&gt;5.从4改进的方案是借助cython. cython可以将python文件转换成c, 并编译成pyd文件. 一般将核心模块编译成pyd, 这样被破解的风险就大大降低了，引用一句说得很好的话&lt;/p&gt;\n<blockquote>\n&lt;p&gt;有一个经验之谈, 你可以将所有每个模块中的某个一个位置的变量抽出, 放到一个python文件中, 使用cython来处理这个文件. 这样就会增加破解者从其他pyc文件中移除pyd文件依赖的难度了&lt;/p&gt;\n</blockquote>\n&lt;p&gt;由于我没接触过cython，所以需要读者自行尝试。关于cython，推荐一篇<a href=\"http://www.oschina.net/question/54100_39042\">赖永浩的译文</a>,也可以自行查阅<a href=\"http://docs.cython.org/src/tutorial/\">官方文档</a>或者<a href=\"https://www.gitbook.com/book/moonlet/cython-document-zh_cn/details\">中文文档</a>&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;p&gt;参考文章: http://www.jianshu.com/p/25631aa535c3/comments/442387&lt;/p&gt;','应该也有人像我一样，可能在上传代码的时候不小心将包含用户名和密码等的配置文件连同代码一起上传至了github，这个问题以前并没有引起我的重视，因为我觉得拥抱开源的程序猿都是心地善良、朴实的。直到某一天我发现我的新浪邮箱被异地登陆了，断定肯定是有人在我的[微博爬虫](https://github.com/ResolveWang/WeiboSpider)中使用了配置文件中的账号和密码,这个问题才被我真正重视起来。\n\n<hr>\n\n截至目前所知，我找到以下几种方法隐藏自己的敏感信息\n\n1.将密码等敏感信息设置到当前环境变量中去.\n\n以Python为例来简单说明一下:\n\n比如我们通过手动设置环境变量**\"weibo_pass\":\"123456\"**,那么可以在Python中这样读出来\n> os.getenv(\'weibo_pass\')\n\n这种方式有一个缺点就是程序部署到别的机器上，就得自己再设置一次环境变量\n\n\n2.将敏感信息写入数据库，从数据库中读出来\n\n这种方法也要注意数据库配置文件的安全问题，不能由于疏忽而上传...\n\n\n3.从公司内联网的服务器或者代理中获取\n\n这种方法就不多说了\n\n\n4.可以将包含敏感信息的源码先编译，然后再从编译过后的字节码文件中获取。这里我还是以python为例来说明\n\nPython代码经过编译过后会生成**.pyc文件**，关于**.pyc**文件的相关知识我会在之后的文章介绍，这里就不详细说了。\n\n我们有两个python文件，一个名为*foo.py*，一个名为*demo.py*,内容分别如下：\n\n<pre>\n\\# foo.py\nname = \'resolvewang\'\npassword = \'he is handsome\'\n</pre>\n\n<pre>\n\\# demo.py, using python3.5\nimport importlib\n\ndef demo_func(name, password):\n    print(\',\'.join([name, password]))\n\nif __name__ == \'__main__\':\n    foo = importlib.import_module(\'foo\', \'f:/pyprogram/foo.pyc\')\n    demo_func(foo.name, foo.password)\n</pre>\n\n这里，我们先手动将foo.py编译为*.pyc*文件，代码如下：\n> import py_compile\n> py_compile.compile(\'foo.py\', \'f:/pyprogram/foo.pyc\')\n\n执行完上述代码后，就会在F盘的pyprogram目录下生成*foo.pyc*,我们再执行**demo.py**,则可以看到以下结果：\n> resolvewang,he is handsome\n\n这样其实就成功隐藏了敏感信息。其实这样也有一个不安全的地方，编译后的文件可以通过反编译破解。不过我觉得一般很少会有程序猿来干这么无聊并且不道德的事，毕竟我们都很善良QAQ.\n\n5.从4改进的方案是借助cython. cython可以将python文件转换成c, 并编译成pyd文件. 一般将核心模块编译成pyd, 这样被破解的风险就大大降低了，引用一句说得很好的话\n> 有一个经验之谈, 你可以将所有每个模块中的某个一个位置的变量抽出, 放到一个python文件中, 使用cython来处理这个文件. 这样就会增加破解者从其他pyc文件中移除pyd文件依赖的难度了\n\n由于我没接触过cython，所以需要读者自行尝试。关于cython，推荐一篇[赖永浩的译文](http://www.oschina.net/question/54100_39042),也可以自行查阅[官方文档](http://docs.cython.org/src/tutorial/)或者[中文文档](https://www.gitbook.com/book/moonlet/cython-document-zh_cn/details)\n\n<hr>\n\n参考文章: http://www.jianshu.com/p/25631aa535c3/comments/442387\n\n\n',1,'python',1474350738,0,35,0,1,1),(95,'谈谈 Python 程序的运行原理(转)','&lt;p&gt;这篇文章准确说是『Python 源码剖析』的读书笔记，整理完之后才发现很长，那就将就看吧。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;h2&gt;1.简单的例子&lt;/h2&gt;\n&lt;p&gt;先从一个简单的例子说起，包含了两个文件 foo.py 和 demo.py\n&lt;pre&gt;\n[foo.py]\ndef add(a, b):\n    return a + b\n&lt;/pre&gt;&lt;/p&gt;\n&lt;pre&gt;\n[demo.py]\nimport foo\n\na = [1, \'python\']\na = \'a string\'\n\ndef func():\n    a = 1\n    b = 257\n    print(a + b)\n\nprint(a)\n\nif __name__ == \'__main__\':\n    func()\n    foo.add(1, 2)\n&lt;/pre&gt;\n\n&lt;p&gt;执行这个程序&lt;/p&gt;\n<blockquote>\n&lt;p&gt;python demo.py&lt;/p&gt;\n</blockquote>\n&lt;p&gt;输出结果&lt;/p&gt;\n<blockquote>\n&lt;p&gt;a string&lt;/p&gt;\n&lt;p&gt;258&lt;/p&gt;\n</blockquote>\n&lt;p&gt;同时，该文件目录多出一个 foo.pyc 文件&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;h2&gt;2.背后的魔法&lt;/h2&gt;\n&lt;p&gt;看完程序的执行结果，接下来开始一行行解释代码。&lt;/p&gt;\n&lt;h3&gt;2.1 模块&lt;/h3&gt;\n&lt;p&gt;Python 将 .py 文件视为一个 module，这些 module 中，有一个主 module，也就是程序运行的入口。在这个例子中，主 module 是 demo.py。&lt;/p&gt;\n&lt;h3&gt;2.2 编译&lt;/h3&gt;\n&lt;p&gt;执行 python demo.py 后，将会启动 Python 的解释器，然后将 demo.py 编译成一个字节码对象 PyCodeObject。&lt;/p&gt;\n&lt;p&gt;有的人可能会很好奇，编译的结果不应是 pyc 文件吗，就像 Java 的 class 文件，那为什么是一个对象呢，这里稍微解释一下。&lt;/p&gt;\n<blockquote>\n&lt;p&gt;在 Python 的世界中，一切都是对象，函数也是对象，类型也是对象，类也是对象（类属于自定义的类型，在 Python 2.2 之前，int, dict 这些内置类型与类是存在不同的，在之后才统一起来，全部继承自 object），甚至连编译出来的字节码也是对象，.pyc 文件是字节码对象（PyCodeObject）在硬盘上的表现形式。&lt;/p&gt;\n</blockquote>\n&lt;p&gt;在运行期间，编译结果也就是 PyCodeObject 对象，只会存在于内存中，而当这个模块的 Python 代码执行完后，就会将编译结果保存到了 pyc 文件中，这样下次就不用编译，直接加载到内存中。pyc 文件只是 PyCodeObject 对象在硬盘上的表现形式。&lt;/p&gt;\n&lt;p&gt;这个 PyCodeObject 对象包含了 Python 源代码中的字符串，常量值，以及通过语法解析后编译生成的字节码指令。PyCodeObject 对象还会存储这些字节码指令与原始代码行号的对应关系，这样当出现异常时，就能指明位于哪一行的代码。&lt;/p&gt;\n&lt;h3&gt;2.3 pyc 文件&lt;/h3&gt;\n&lt;p&gt;一个 pyc 文件包含了三部分信息：Python 的 magic number、pyc 文件创建的时间信息，以及 PyCodeObject 对象。&lt;/p&gt;\n&lt;p&gt;magic number 是 Python 定义的一个整数值。一般来说，不同版本的 Python 实现都会定义不同的 magic number，这个值是用来保证 Python 兼容性的。比如要限制由低版本编译的 pyc 文件不能让高版本的 Python 程序来执行，只需要检查 magic number 不同就可以了。由于不同版本的 Python 定义的字节码指令可能会不同，如果不做检查，执行的时候就可能出错。&lt;/p&gt;\n&lt;p&gt;下面所示的代码可以来创建 pyc 文件，使用方法&lt;/p&gt;\n<blockquote>\n&lt;p&gt;python generate_pyc.py module_name&lt;/p&gt;\n</blockquote>\n&lt;p&gt;例如&lt;/p&gt;\n<blockquote>\n&lt;p&gt;python generate_pyc.py demo&lt;/p&gt;\n</blockquote>\n&lt;pre&gt;\n[generate_pyc.pyc]\nimport imp\nimport sys\n\ndef generate_pyc(name):\n    fp, pathname, description = imp.find_module(name)\n    try:\n        imp.load_module(name, fp, pathname, description)    \n    finally:\n        if fp:\n            fp.close()\n\nif __name__ == \'__main__\':\n    generate_pyc(sys.argv[1])\n&lt;/pre&gt;\n\n&lt;h3&gt;2.4 字节码指令&lt;/h3&gt;\n<blockquote>\n&lt;p&gt;为什么 pyc 文件也称作字节码文件？因为这些文件存储的都是一些二进制的字节数据，而不是能让人直观查看的文本数据。&lt;/p&gt;\n</blockquote>\n&lt;p&gt;Python 标准库提供了用来生成代码对应字节码的工具<strong>dis</strong>。dis 提供一个名为 dis 的方法，这个方法接收一个 code 对象，然后会输出 code 对象里的字节码指令信息。&lt;/p&gt;\n<blockquote>\n&lt;p&gt;s = open(\'demo.py\').read()&lt;/p&gt;\n&lt;p&gt;co = compile(s, \'demo.py\', \'exec\')&lt;/p&gt;\n&lt;p&gt;import dis&lt;/p&gt;\n&lt;p&gt;dis.dis(co)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;执行上面这段代码可以输出 demo.py 编译后的字节码指令\n&lt;pre&gt;\n  1           0 LOAD_CONST               0 (-1)\n              3 LOAD_CONST               1 (None)\n              6 IMPORT_NAME              0 (foo)\n              9 STORE_NAME               0 (foo)&lt;/p&gt;\n&lt;p&gt;3          12 LOAD_CONST               2 (1)\n             15 LOAD_CONST               3 (u\'python\')\n             18 BUILD_LIST               2\n             21 STORE_NAME               1 (a)&lt;/p&gt;\n&lt;p&gt;4          24 LOAD_CONST               4 (u\'a string\')\n             27 STORE_NAME               1 (a)\n             33 MAKE_FUNCTION            0\n             36 STORE_NAME               2 (func)&lt;/p&gt;\n&lt;p&gt;11          39 LOAD_NAME                1 (a)\n             42 PRINT_ITEM\n             43 PRINT_NEWLINE&lt;/p&gt;\n&lt;p&gt;13          44 LOAD_NAME                3 (<strong>name</strong>)\n             47 LOAD_CONST               6 (u\'<strong>main</strong>\')\n             50 COMPARE_OP               2 (==)\n             53 POP_JUMP_IF_FALSE       82&lt;/p&gt;\n&lt;p&gt;14          56 LOAD_NAME                2 (func)\n             59 CALL_FUNCTION            0\n             62 POP_TOP&lt;/p&gt;\n&lt;p&gt;15          63 LOAD_NAME                0 (foo)\n             66 LOAD_ATTR                4 (add)\n             69 LOAD_CONST               2 (1)\n             72 LOAD_CONST               7 (2)\n             75 CALL_FUNCTION            2\n             78 POP_TOP\n             79 JUMP_FORWARD             0 (to 82)\n        &gt;&gt;   82 LOAD_CONST               1 (None)\n             85 RETURN_VALUE\n&lt;/pre&gt;&lt;/p&gt;\n&lt;h3&gt;2.5 Python 虚拟机&lt;/h3&gt;\n&lt;p&gt;demo.py 被编译后，接下来的工作就交由 Python 虚拟机来执行字节码指令了。Python 虚拟机会从编译得到的 PyCodeObject 对象中依次读入每一条字节码指令，并在当前的上下文环境中执行这条字节码指令。我们的程序就是通过这样循环往复的过程才得以执行。&lt;/p&gt;\n&lt;h3&gt;2.6 import 指令&lt;/h3&gt;\n&lt;p&gt;demo.py 的第一行代码是 import foo。import 指令用来载入一个模块，另外一个载入模块的方法是 from xx import yy。用 from 语句的好处是，可以只复制需要的符号变量到当前的命名空间中（关于命名空间将在后面介绍）。&lt;/p&gt;\n&lt;p&gt;前文提到，当已经存在 pyc 文件时，就可以直接载入而省去编译过程。但是代码文件的内容会更新，如何保证更新后能重新编译而不入旧的 pyc 文件呢。答案就在 pyc 文件中存储的创建时间信息。当执行 import 指令的时候，如果已存在 pyc 文件，Python 会检查创建时间是否晚于代码文件的修改时间，这样就能判断是否需要重新编译，还是直接载入了。如果不存在 pyc 文件，就会先将 py 文件编译。&lt;/p&gt;\n&lt;h3&gt;2.7 绝对引入和相对引入&lt;/h3&gt;\n&lt;p&gt;前文已经介绍了 import foo 这行代码。这里隐含了一个问题，就是 foo 是什么，如何找到 foo。这就属于 Python 的模块引入规则，这里不展开介绍，可以参考 <a href=\"http://legacy.python.org/dev/peps/pep-0328/\">pep-0328</a>。&lt;/p&gt;\n&lt;h3&gt;2.8 赋值语句&lt;/h3&gt;\n&lt;p&gt;接下来，执行到 a = [1, \'python\']，这是一条赋值语句，定义了一个变量 a，它对应的值是 [1, \'python\']。这里要解释一下，变量是什么呢？&lt;/p&gt;\n&lt;p&gt;按照维基百科的解释&lt;/p&gt;\n<blockquote>\n&lt;p&gt;变量是一个存储位置和一个关联的符号名字，这个存储位置包含了一些已知或未知的量或者信息。&lt;/p&gt;\n</blockquote>\n&lt;p&gt;变量实际上是一个字符串的符号，用来关联一个存储在内存中的对象。在 Python 中，会使用 dict（就是 Python 的 dict 对象）来存储变量符号（字符串）与一个对象的映射。&lt;/p&gt;\n&lt;p&gt;那么赋值语句实际上就是用来建立这种关联，在这个例子中是将符号 a 与一个列表对象 [1, \'python\'] 建立映射。&lt;/p&gt;\n&lt;p&gt;紧接着的代码执行了 a = \'a string\'，这条指令则将符号 a 与另外一个字符串对象 a string 建立了映射。今后对变量 a 的操作，将反应到字符串对象 a string 上。&lt;/p&gt;\n&lt;h3&gt;2.9 def 指令&lt;/h3&gt;\n&lt;p&gt;我们的 Python 代码继续往下运行，这里执行到一条 def func()，从字节码指令中也可以看出端倪 MAKE_FUNCTION。没错这条指令是用来创建函数的。Python 是动态语言，def 实际上是执行一条指令，用来创建函数（class 则是创建类的指令），而不仅仅是个语法关键字。函数并不是事先创建好的，而是执行到的时候才创建的。&lt;/p&gt;\n&lt;p&gt;def func() 将会创建一个名称为 func 的函数对象。实际上是先创建一个函数对象，然后将 func 这个名称符号绑定到这个函数上。&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Python 中是无法实现 C 和 Java 中的重载的，因为重载要求函数名要相同，而参数的类型或数量不同，但是 Python 是通过变量符号（如这里的 func）来关联一个函数，当我们用 def 语句再次创建一个同名的函数时，这个变量名就绑定到新的函数对象上了。&lt;/p&gt;\n</blockquote>\n&lt;h3&gt;2.10 动态类型&lt;/h3&gt;\n&lt;p&gt;继续看函数 func 里面的代码，这时又有一条赋值语句 a = 1。变量 a 现在已经变成了第三种类型，它现在是一个整数了。那么 Python 是怎么实现动态类型的呢？答案就藏在具体存储的对象上。变量 a 仅仅只是一个符号（实际上是一个字符串对象），类型信息是存储在对象上的。在 Python 中，对象机制的核心是类型信息和引用计数（引用计数属于垃圾回收的部分）。&lt;/p&gt;\n<blockquote>\n&lt;p&gt;用 type(a)，可以输出 a 的类型，这里是 int&lt;/p&gt;\n</blockquote>\n&lt;p&gt;b = 257 跳过，我们直接来看看 print(a + b)，print 是输出函数，这里略过。这里想要探究的是 a + b。&lt;/p&gt;\n&lt;p&gt;因为 a 和 b 并不存储类型信息，因此当执行 a + b 的时候就必须先检查类型，比如 1 + 2 和 \"1\" + \"2\" 的结果是不一样的。&lt;/p&gt;\n&lt;p&gt;看到这里，我们就可以想象一下执行一句简单的 a + b，Python 虚拟机需要做多少繁琐的事情了。首先需要分别检查 a 和 b 所对应对象的类型，还要匹配类型是否一致（1 + \"2\" 将会出现异常），然后根据对象的类型调用正确的 + 函数（例如数值的 + 或字符串的 +）。&lt;/p&gt;\n&lt;h3&gt;2.11 命名空间 (namespace)&lt;/h3&gt;\n&lt;p&gt;在介绍上面的这些代码时，还漏掉了一个关键的信息就是命名空间。在 Python 中，类、函数、module 都对应着一个独立的命名空间。而一个独立的命名空间会对应一个 PyCodeObject 对象，所以上面的 demo.py 文件编译后会生成两个 PyCodeObject，只是在 demo.py 这个 module 层的 PyCodeObject 中通过一个变量符号 func 嵌套了一个函数的 PyCodeObject。&lt;/p&gt;\n&lt;p&gt;命名空间的意义，就是用来确定一个变量符号到底对应什么对象。命名空间可以一个套一个地形成一条命名空间链，Python 虚拟机在执行的过程中，会有很大一部分时间消耗在从这条命名空间链中确定一个符号所对应的对象是什么。&lt;/p&gt;\n&lt;p&gt;在 Python中，命名空间是由一个 dict 对象实现的，它维护了（name，obj）这样的关联关系。&lt;/p&gt;\n&lt;p&gt;说到这里，再补充一下 import foo 这行代码会在 demo.py 这个模块的命名空间中，创建一个新的变量名 foo，foo 将绑定到一个 PyCodeObject 对象，也就是 foo.py 的编译结果。&lt;/p&gt;\n&lt;p&gt;&lt;br&gt;&lt;/p&gt;\n&lt;h4&gt;2.11.1 dir 函数&lt;/h4&gt;\n&lt;p&gt;Python 的内置函数 dir 可以用来查看一个命名空间下的所有名字符号。一个用处是查看一个命名空间的所有属性和方法（这里的命名空间就是指类、函数、module）。&lt;/p&gt;\n&lt;p&gt;比如，查看当前的命名空间，可以使用 dir()，查看 sys 模块，可以使用 dir(sys)。&lt;/p&gt;\n&lt;h4&gt;2.11.2 LEGB 规则&lt;/h4&gt;\n&lt;p&gt;Python 使用 LEGB 的顺序来查找一个符号对应的对象&lt;/p&gt;\n<blockquote>\n&lt;p&gt;locals -&gt; enclosing function -&gt; globals -&gt; builtins&lt;/p&gt;\n</blockquote>\n&lt;p&gt;ocals，当前所在命名空间（如函数、模块），函数的参数也属于命名空间内的变量&lt;/p&gt;\n&lt;p&gt;enclosing，外部嵌套函数的命名空间（闭包中常见）\n&lt;pre&gt;\ndef fun1(a):\n    def fun2():\n        # a 位于外部嵌套函数的命名空间\n        print(a)\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;globals，全局变量，函数定义所在模块的命名空间&lt;/p&gt;\n&lt;pre&gt;\na = 1\ndef fun():\n    \\# 需要通过 global 指令来声明全局变量\n    global a\n    \\# 修改全局变量，而不是创建一个新的 local 变量\n    a = 2\n&lt;/pre&gt;\n\n&lt;p&gt;builtins，内置模块的命名空间。Python 在启动的时候会自动为我们载入很多内置的函数、类，比如 dict，list，type，print，这些都位于 <strong>builtins</strong> 模块中，可以使用 dir(<strong>builtins</strong>) 来查看。这也是为什么我们在没有 import 任何模块的情况下，就能使用这么多丰富的函数和功能了。&lt;/p&gt;\n&lt;p&gt;介绍完命名空间，就能理解 print(a) 这行代码输出的结果为什么是 a string 了。\n&lt;br&gt;&lt;/p&gt;\n&lt;h3&gt;2.12 内置属性 <strong>name</strong>&lt;/h3&gt;\n&lt;p&gt;现在到了解释 if <strong>name</strong> == \'<strong>main</strong>\' 这行代码的时候了。当 Python 程序启动后，Python 会自动为每个模块设置一个属性 <strong>name</strong> 通常使用的是模块的名字，也就是文件名，但唯一的例外是主模块，主模块将会被设置为 <strong>main</strong>。利用这一特性，就可以做一些特别的事。比如当该模块以主模块来运行的时候，可以运行测试用例。而当被其他模块 import 时，则只是乖乖的，提供函数和功能就好。&lt;/p&gt;\n&lt;h3&gt;2.13 函数调用&lt;/h3&gt;\n&lt;p&gt;最后两行是函数调用，这里略去不讲。&lt;/p&gt;\n&lt;hr&gt;\n\n&lt;h2&gt;3. 回顾&lt;/h2&gt;\n&lt;p&gt;讲到最后，还有些内容需要再回顾和补充一下。&lt;/p&gt;\n&lt;h3&gt;3.1 pyc 文件&lt;/h3&gt;\n&lt;p&gt;Python 只会对那些以后可能继续被使用和载入的模块才会生成 pyc 文件，Python 认为使用了 import 指令的模块，属于这种类型，因此会生成 pyc 文件。而对于只是临时用一次的模块，并不会生成 pyc 文件，Python 将主模块当成了这种类型的文件。这就解释了为什么 python demo.py 执行完后，只会生成一个 foo.pyc 文件。&lt;/p&gt;\n<blockquote>\n&lt;p&gt;如果要问 pyc 文件什么时候生成，答案就是在执行了 import 指令之后，from xx import yy 同样属于 import 指令。&lt;/p&gt;\n</blockquote>\n&lt;h3&gt;3.2 小整数对象池&lt;/h3&gt;\n&lt;p&gt;在 demo.py 这里例子中，所用的整数特意用了一个 257，这是为了介绍小整数对象池的。整数在程序中的使用非常广泛，Python 为了优化速度，使用了小整数对象池，避免为整数频繁申请和销毁内存空间。&lt;/p&gt;\n&lt;p&gt;Python 对小整数的定义是 [-5, 257)，这些整数对象是提前建立好的，不会被垃圾回收。在一个 Python 的程序中，所有位于这个范围内的整数使用的都是同一个对象，从下面这个例子就可以看出。&lt;/p&gt;\n&lt;pre&gt;\n&gt;&gt;&gt; a = 1\n&gt;&gt;&gt; id(a)\n40059744\n&gt;&gt;&gt; b = 1\n&gt;&gt;&gt; id(b)\n40059744\n&gt;&gt;&gt; c = 257\n&gt;&gt;&gt; id(c)\n41069072\n&gt;&gt;&gt; d = 257\n&gt;&gt;&gt; id(257)\n41069096\n&lt;/pre&gt;\n\n<blockquote>\n&lt;p&gt;id 函数可以用来查看一个对象的唯一标志，可以认为是内存地址&lt;/p&gt;\n</blockquote>\n&lt;p&gt;对于大整数，Python 使用的是一个大整数对象池。这句话的意思是：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;每当创建一个大整数的时候，都会新建一个对象，但是这个对象不再使用的时候，并不会销毁，后面再建立的对象会复用之前已经不再使用的对象的内存空间。（这里的不再使用指的是引用计数为0，可以被销毁）&lt;/p&gt;\n</blockquote>\n&lt;h3&gt;3.3 字符串对象缓冲池&lt;/h3&gt;\n&lt;p&gt;如果仔细思考一下，一定会猜到字符串也采用了这种类似的技术，我们来看一下\n&lt;pre&gt;\n&gt;&gt;&gt; a = \'a\'\n&gt;&gt;&gt; b = \'a\'\n&gt;&gt;&gt; id(a)\n14660456\n&gt;&gt;&gt; id(b)\n14660456\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;没错，Python 的设计者为一个字节的字符对应的字符串对象 (PyStringObject) 也设计了这样一个对象池。同时还有一个 intern 机制，可以将内容相同的字符串变量转换成指向同一个字符串对象。&lt;/p&gt;\n&lt;p&gt;intern 机制的关键，就是在系统中有一个（key，value）映射关系的集合，集合的名称叫做 interned。在这个集合中，记录着被 intern 机制处理过的 PyStringObject 对象。不过 Python 始终会为字符串创建 PyStringObject 对象，即便在interned 中已经有一个与之对应的 PyStringObject 对象了，而 intern 机制是在字符串被创建后才起作用。&lt;/p&gt;\n&lt;pre&gt;\n&gt;&gt;&gt; a = \'a string\'\n&gt;&gt;&gt; b = \'a string\'\n&gt;&gt;&gt; a is b\nFalse\n&gt;&gt;&gt; a = intern(\'a string\') # 手动调用 intern 方法\n&gt;&gt;&gt; b = intern(\'a string\')\n&gt;&gt;&gt; a is b\nTrue\n&lt;/pre&gt;\n\n&lt;p&gt;<strong>更正</strong>:我在Python3.5上做实验，发现&lt;/p&gt;\n<blockquote>\n&lt;p&gt;a = \'a string\'&lt;/p&gt;\n&lt;p&gt;b = \'a string\'&lt;/p&gt;\n&lt;p&gt;a is b&lt;/p&gt;\n</blockquote>\n&lt;p&gt;结果为True，也就是说在Python3的情况下，它可能已经默认调用了intern()&lt;/p&gt;\n&lt;p&gt;关于 intern 函数 可以参考<a href=\"https://docs.python.org/2/library/functions.html#intern\">官方文档</a>，更多扩展阅读：&lt;/p&gt;\n&lt;p&gt;http://stackoverflow.com/questions/15541404/python-string-interning&lt;/p&gt;\n<blockquote>\n&lt;p&gt;值得说明的是，数值类型和字符串类型在 Python 中都是不可变的，这意味着你无法修改这个对象的值，每次对变量的修改，实际上是创建一个新的对象。得益于这样的设计，才能使用对象缓冲池这种优化。&lt;/p&gt;\n</blockquote>\n&lt;p&gt;Python 的实现上大量采用了这种内存对象池的技术，不仅仅对于这些特定的对象，还有专门的内存池用于小对象，使用这种技术可以避免频繁地申请和释放内存空间，目的就是让 Python 能稍微更快一点。更多内容可以参考<a href=\"http://blog.csdn.net/zhzhl202/article/details/7547445\">这里</a>。&lt;/p&gt;\n<blockquote>\n&lt;p&gt;如果想了解更快的 Python，可以看看 <a href=\"http://pypy.org/\">PyPy</a>&lt;/p&gt;\n</blockquote>\n&lt;h3&gt;3.4 import 指令&lt;/h3&gt;\n&lt;p&gt;前文提到 import 指令是用来载入 module 的，如果需要，也会顺道做编译的事。但 import 指令，还会做一件重要的事情就是把 import 的那个 module 的代码执行一遍，这件事情很重要。Python 是解释执行的，连函数都是执行的时候才创建的。如果不把那个 module 的代码执行一遍，那么 module 里面的函数都没法创建，更别提去调用这些函数了。&lt;/p&gt;\n&lt;p&gt;执行代码的另外一个重要作用，就是在这个 module 的命名空间中，创建模块内定义的函数和各种对象的符号名称（也就是变量名），并将其绑定到对象上，这样其他 module 才能通过变量名来引用这些对象。&lt;/p&gt;\n&lt;p&gt;Python 虚拟机还会将已经 import 过的 module 缓存起来，放到一个全局 module 集合 sys.modules 中。这样做有一个好处，即如果程序的在另一个地方再次 import 这个模块，Python 虚拟机只需要将全局 module 集合中缓存的那个 module 对象返回即可。&lt;/p&gt;\n<blockquote>\n&lt;p&gt;你现在一定想到了 sys.modules 是一个 dict 对象，可以通过 type(sys.modules) 来验证&lt;/p&gt;\n</blockquote>\n&lt;h3&gt;3.5 多线程&lt;/h3&gt;\n&lt;p&gt;demo.py 这个例子并没有用到多线程，但还是有必要提一下。&lt;/p&gt;\n&lt;p&gt;在提到多线程的时候，往往要关注线程如何同步，如何访问共享资源。Python 是通过一个全局解释器锁 GIL（Global Interpreter Lock）来实现线程同步的。当 Python 程序只有单线程时，并不会启用 GIL，而当用户创建了一个 thread 时，表示要使用多线程，Python 解释器就会自动激活 GIL，并创建所需要的上下文环境和数据结构。&lt;/p&gt;\n&lt;p&gt;Python 字节码解释器的工作原理是按照指令的顺序一条一条地顺序执行，Python 内部维护着一个数值，这个数值就是 Python 内部的时钟，如果这个数值为 N，则意味着 Python 在执行了 N 条指令以后应该立即启动线程调度机制，可以通过下面的代码获取这个数值。&lt;/p&gt;\n<blockquote>\n&lt;p&gt;import sys&lt;/p&gt;\n&lt;p&gt;sys.getcheckinterval() # 100&lt;/p&gt;\n</blockquote>\n&lt;p&gt;线程调度机制将会为线程分配 GIL，获取到 GIL 的线程就能开始执行，而其他线程则必须等待。由于 GIL 的存在，Python 的多线程性能十分低下，无法发挥多核 CPU 的优势，性能甚至不如单线程。因此如果你想用到多核 CPU，一个建议是使用多进程。&lt;/p&gt;\n&lt;h3&gt;3.6 垃圾回收&lt;/h3&gt;\n&lt;p&gt;在讲到垃圾回收的时候，通常会使用引用计数的模型，这是一种最直观，最简单的垃圾收集技术。Python 同样也使用了引用计数，但是引用计数存在这些缺点：\n- 频繁更新引用计数会降低运行效率\n- 引用计数无法解决循环引用问题&lt;/p&gt;\n&lt;p&gt;Python 在引用计数机制的基础上，使用了主流垃圾收集技术中的标记——清除和分代收集两种技术。&lt;/p&gt;\n&lt;p&gt;关于垃圾回收，可以参考&lt;/p&gt;\n&lt;p&gt;http://hbprotoss.github.io/posts/pythonla-ji-hui-shou-ji-zhi.html&lt;/p&gt;\n&lt;p&gt;原文链接：http://www.cnblogs.com/restran/p/4903056.html&lt;/p&gt;','这篇文章准确说是『Python 源码剖析』的读书笔记，整理完之后才发现很长，那就将就看吧。\n\n<hr>\n\n##1.简单的例子\n先从一个简单的例子说起，包含了两个文件 foo.py 和 demo.py\n<pre>\n[foo.py]\ndef add(a, b):\n    return a + b\n</pre>\n\n<pre>\n[demo.py]\nimport foo\n\na = [1, \'python\']\na = \'a string\'\n\ndef func():\n    a = 1\n    b = 257\n    print(a + b)\n\nprint(a)\n\nif __name__ == \'__main__\':\n    func()\n    foo.add(1, 2)\n</pre>\n\n执行这个程序\n> python demo.py\n\n输出结果\n> a string\n\n>258\n\n同时，该文件目录多出一个 foo.pyc 文件\n\n<hr>\n\n##2.背后的魔法\n看完程序的执行结果，接下来开始一行行解释代码。\n\n###2.1 模块\nPython 将 .py 文件视为一个 module，这些 module 中，有一个主 module，也就是程序运行的入口。在这个例子中，主 module 是 demo.py。\n\n###2.2 编译\n执行 python demo.py 后，将会启动 Python 的解释器，然后将 demo.py 编译成一个字节码对象 PyCodeObject。\n\n有的人可能会很好奇，编译的结果不应是 pyc 文件吗，就像 Java 的 class 文件，那为什么是一个对象呢，这里稍微解释一下。\n\n>在 Python 的世界中，一切都是对象，函数也是对象，类型也是对象，类也是对象（类属于自定义的类型，在 Python 2.2 之前，int, dict 这些内置类型与类是存在不同的，在之后才统一起来，全部继承自 object），甚至连编译出来的字节码也是对象，.pyc 文件是字节码对象（PyCodeObject）在硬盘上的表现形式。\n\n在运行期间，编译结果也就是 PyCodeObject 对象，只会存在于内存中，而当这个模块的 Python 代码执行完后，就会将编译结果保存到了 pyc 文件中，这样下次就不用编译，直接加载到内存中。pyc 文件只是 PyCodeObject 对象在硬盘上的表现形式。\n\n这个 PyCodeObject 对象包含了 Python 源代码中的字符串，常量值，以及通过语法解析后编译生成的字节码指令。PyCodeObject 对象还会存储这些字节码指令与原始代码行号的对应关系，这样当出现异常时，就能指明位于哪一行的代码。\n\n###2.3 pyc 文件\n一个 pyc 文件包含了三部分信息：Python 的 magic number、pyc 文件创建的时间信息，以及 PyCodeObject 对象。\n\nmagic number 是 Python 定义的一个整数值。一般来说，不同版本的 Python 实现都会定义不同的 magic number，这个值是用来保证 Python 兼容性的。比如要限制由低版本编译的 pyc 文件不能让高版本的 Python 程序来执行，只需要检查 magic number 不同就可以了。由于不同版本的 Python 定义的字节码指令可能会不同，如果不做检查，执行的时候就可能出错。\n\n下面所示的代码可以来创建 pyc 文件，使用方法\n>  python generate_pyc.py module_name\n\n例如\n>  python generate_pyc.py demo\n\n<pre>\n[generate_pyc.pyc]\nimport imp\nimport sys\n\ndef generate_pyc(name):\n    fp, pathname, description = imp.find_module(name)\n    try:\n        imp.load_module(name, fp, pathname, description)    \n    finally:\n        if fp:\n            fp.close()\n\nif __name__ == \'__main__\':\n    generate_pyc(sys.argv[1])\n</pre>\n\n###2.4 字节码指令\n>为什么 pyc 文件也称作字节码文件？因为这些文件存储的都是一些二进制的字节数据，而不是能让人直观查看的文本数据。\n\nPython 标准库提供了用来生成代码对应字节码的工具**dis**。dis 提供一个名为 dis 的方法，这个方法接收一个 code 对象，然后会输出 code 对象里的字节码指令信息。\n\n>s = open(\'demo.py\').read()\n\n>co = compile(s, \'demo.py\', \'exec\')\n\n>import dis\n\n>dis.dis(co)\n\n执行上面这段代码可以输出 demo.py 编译后的字节码指令\n<pre>\n  1           0 LOAD_CONST               0 (-1)\n              3 LOAD_CONST               1 (None)\n              6 IMPORT_NAME              0 (foo)\n              9 STORE_NAME               0 (foo)\n\n  3          12 LOAD_CONST               2 (1)\n             15 LOAD_CONST               3 (u\'python\')\n             18 BUILD_LIST               2\n             21 STORE_NAME               1 (a)\n\n  4          24 LOAD_CONST               4 (u\'a string\')\n             27 STORE_NAME               1 (a)\n             33 MAKE_FUNCTION            0\n             36 STORE_NAME               2 (func)\n\n 11          39 LOAD_NAME                1 (a)\n             42 PRINT_ITEM\n             43 PRINT_NEWLINE\n\n 13          44 LOAD_NAME                3 (__name__)\n             47 LOAD_CONST               6 (u\'__main__\')\n             50 COMPARE_OP               2 (==)\n             53 POP_JUMP_IF_FALSE       82\n\n 14          56 LOAD_NAME                2 (func)\n             59 CALL_FUNCTION            0\n             62 POP_TOP\n\n 15          63 LOAD_NAME                0 (foo)\n             66 LOAD_ATTR                4 (add)\n             69 LOAD_CONST               2 (1)\n             72 LOAD_CONST               7 (2)\n             75 CALL_FUNCTION            2\n             78 POP_TOP\n             79 JUMP_FORWARD             0 (to 82)\n        >>   82 LOAD_CONST               1 (None)\n             85 RETURN_VALUE\n</pre>\n\n###2.5 Python 虚拟机\ndemo.py 被编译后，接下来的工作就交由 Python 虚拟机来执行字节码指令了。Python 虚拟机会从编译得到的 PyCodeObject 对象中依次读入每一条字节码指令，并在当前的上下文环境中执行这条字节码指令。我们的程序就是通过这样循环往复的过程才得以执行。\n\n###2.6 import 指令\ndemo.py 的第一行代码是 import foo。import 指令用来载入一个模块，另外一个载入模块的方法是 from xx import yy。用 from 语句的好处是，可以只复制需要的符号变量到当前的命名空间中（关于命名空间将在后面介绍）。\n\n前文提到，当已经存在 pyc 文件时，就可以直接载入而省去编译过程。但是代码文件的内容会更新，如何保证更新后能重新编译而不入旧的 pyc 文件呢。答案就在 pyc 文件中存储的创建时间信息。当执行 import 指令的时候，如果已存在 pyc 文件，Python 会检查创建时间是否晚于代码文件的修改时间，这样就能判断是否需要重新编译，还是直接载入了。如果不存在 pyc 文件，就会先将 py 文件编译。\n\n###2.7 绝对引入和相对引入\n前文已经介绍了 import foo 这行代码。这里隐含了一个问题，就是 foo 是什么，如何找到 foo。这就属于 Python 的模块引入规则，这里不展开介绍，可以参考 [pep-0328](http://legacy.python.org/dev/peps/pep-0328/)。\n\n###2.8 赋值语句\n接下来，执行到 a = [1, \'python\']，这是一条赋值语句，定义了一个变量 a，它对应的值是 [1, \'python\']。这里要解释一下，变量是什么呢？\n\n按照维基百科的解释\n> 变量是一个存储位置和一个关联的符号名字，这个存储位置包含了一些已知或未知的量或者信息。\n\n变量实际上是一个字符串的符号，用来关联一个存储在内存中的对象。在 Python 中，会使用 dict（就是 Python 的 dict 对象）来存储变量符号（字符串）与一个对象的映射。\n\n那么赋值语句实际上就是用来建立这种关联，在这个例子中是将符号 a 与一个列表对象 [1, \'python\'] 建立映射。\n\n紧接着的代码执行了 a = \'a string\'，这条指令则将符号 a 与另外一个字符串对象 a string 建立了映射。今后对变量 a 的操作，将反应到字符串对象 a string 上。\n\n###2.9 def 指令\n我们的 Python 代码继续往下运行，这里执行到一条 def func()，从字节码指令中也可以看出端倪 MAKE_FUNCTION。没错这条指令是用来创建函数的。Python 是动态语言，def 实际上是执行一条指令，用来创建函数（class 则是创建类的指令），而不仅仅是个语法关键字。函数并不是事先创建好的，而是执行到的时候才创建的。\n\ndef func() 将会创建一个名称为 func 的函数对象。实际上是先创建一个函数对象，然后将 func 这个名称符号绑定到这个函数上。\n\n> Python 中是无法实现 C 和 Java 中的重载的，因为重载要求函数名要相同，而参数的类型或数量不同，但是 Python 是通过变量符号（如这里的 func）来关联一个函数，当我们用 def 语句再次创建一个同名的函数时，这个变量名就绑定到新的函数对象上了。\n\n###2.10 动态类型\n继续看函数 func 里面的代码，这时又有一条赋值语句 a = 1。变量 a 现在已经变成了第三种类型，它现在是一个整数了。那么 Python 是怎么实现动态类型的呢？答案就藏在具体存储的对象上。变量 a 仅仅只是一个符号（实际上是一个字符串对象），类型信息是存储在对象上的。在 Python 中，对象机制的核心是类型信息和引用计数（引用计数属于垃圾回收的部分）。\n>用 type(a)，可以输出 a 的类型，这里是 int\n\nb = 257 跳过，我们直接来看看 print(a + b)，print 是输出函数，这里略过。这里想要探究的是 a + b。\n\n因为 a 和 b 并不存储类型信息，因此当执行 a + b 的时候就必须先检查类型，比如 1 + 2 和 \"1\" + \"2\" 的结果是不一样的。\n\n看到这里，我们就可以想象一下执行一句简单的 a + b，Python 虚拟机需要做多少繁琐的事情了。首先需要分别检查 a 和 b 所对应对象的类型，还要匹配类型是否一致（1 + \"2\" 将会出现异常），然后根据对象的类型调用正确的 + 函数（例如数值的 + 或字符串的 +）。\n\n###2.11 命名空间 (namespace)\n在介绍上面的这些代码时，还漏掉了一个关键的信息就是命名空间。在 Python 中，类、函数、module 都对应着一个独立的命名空间。而一个独立的命名空间会对应一个 PyCodeObject 对象，所以上面的 demo.py 文件编译后会生成两个 PyCodeObject，只是在 demo.py 这个 module 层的 PyCodeObject 中通过一个变量符号 func 嵌套了一个函数的 PyCodeObject。\n\n命名空间的意义，就是用来确定一个变量符号到底对应什么对象。命名空间可以一个套一个地形成一条命名空间链，Python 虚拟机在执行的过程中，会有很大一部分时间消耗在从这条命名空间链中确定一个符号所对应的对象是什么。\n\n在 Python中，命名空间是由一个 dict 对象实现的，它维护了（name，obj）这样的关联关系。\n\n说到这里，再补充一下 import foo 这行代码会在 demo.py 这个模块的命名空间中，创建一个新的变量名 foo，foo 将绑定到一个 PyCodeObject 对象，也就是 foo.py 的编译结果。\n\n<br>\n####2.11.1 dir 函数\n\nPython 的内置函数 dir 可以用来查看一个命名空间下的所有名字符号。一个用处是查看一个命名空间的所有属性和方法（这里的命名空间就是指类、函数、module）。\n\n比如，查看当前的命名空间，可以使用 dir()，查看 sys 模块，可以使用 dir(sys)。\n\n####2.11.2 LEGB 规则\n\nPython 使用 LEGB 的顺序来查找一个符号对应的对象\n\n>locals -> enclosing function -> globals -> builtins\n\nocals，当前所在命名空间（如函数、模块），函数的参数也属于命名空间内的变量\n\nenclosing，外部嵌套函数的命名空间（闭包中常见）\n<pre>\ndef fun1(a):\n    def fun2():\n        \\# a 位于外部嵌套函数的命名空间\n        print(a)\n</pre>\n\nglobals，全局变量，函数定义所在模块的命名空间\n\n<pre>\na = 1\ndef fun():\n    \\# 需要通过 global 指令来声明全局变量\n    global a\n    \\# 修改全局变量，而不是创建一个新的 local 变量\n    a = 2\n</pre>\n\nbuiltins，内置模块的命名空间。Python 在启动的时候会自动为我们载入很多内置的函数、类，比如 dict，list，type，print，这些都位于 __builtins__ 模块中，可以使用 dir(__builtins__) 来查看。这也是为什么我们在没有 import 任何模块的情况下，就能使用这么多丰富的函数和功能了。\n\n介绍完命名空间，就能理解 print(a) 这行代码输出的结果为什么是 a string 了。\n<br>\n###2.12 内置属性 __name__\n现在到了解释 if __name__ == \'__main__\' 这行代码的时候了。当 Python 程序启动后，Python 会自动为每个模块设置一个属性 __name__ 通常使用的是模块的名字，也就是文件名，但唯一的例外是主模块，主模块将会被设置为 __main__。利用这一特性，就可以做一些特别的事。比如当该模块以主模块来运行的时候，可以运行测试用例。而当被其他模块 import 时，则只是乖乖的，提供函数和功能就好。\n\n###2.13 函数调用\n最后两行是函数调用，这里略去不讲。\n\n<hr>\n\n##3. 回顾\n讲到最后，还有些内容需要再回顾和补充一下。\n\n###3.1 pyc 文件\nPython 只会对那些以后可能继续被使用和载入的模块才会生成 pyc 文件，Python 认为使用了 import 指令的模块，属于这种类型，因此会生成 pyc 文件。而对于只是临时用一次的模块，并不会生成 pyc 文件，Python 将主模块当成了这种类型的文件。这就解释了为什么 python demo.py 执行完后，只会生成一个 foo.pyc 文件。\n\n>如果要问 pyc 文件什么时候生成，答案就是在执行了 import 指令之后，from xx import yy 同样属于 import 指令。\n\n###3.2 小整数对象池\n在 demo.py 这里例子中，所用的整数特意用了一个 257，这是为了介绍小整数对象池的。整数在程序中的使用非常广泛，Python 为了优化速度，使用了小整数对象池，避免为整数频繁申请和销毁内存空间。\n\nPython 对小整数的定义是 [-5, 257)，这些整数对象是提前建立好的，不会被垃圾回收。在一个 Python 的程序中，所有位于这个范围内的整数使用的都是同一个对象，从下面这个例子就可以看出。\n\n<pre>\n>>> a = 1\n>>> id(a)\n40059744\n>>> b = 1\n>>> id(b)\n40059744\n>>> c = 257\n>>> id(c)\n41069072\n>>> d = 257\n>>> id(257)\n41069096\n</pre>\n\n>id 函数可以用来查看一个对象的唯一标志，可以认为是内存地址\n\n对于大整数，Python 使用的是一个大整数对象池。这句话的意思是：\n> 每当创建一个大整数的时候，都会新建一个对象，但是这个对象不再使用的时候，并不会销毁，后面再建立的对象会复用之前已经不再使用的对象的内存空间。（这里的不再使用指的是引用计数为0，可以被销毁）\n\n###3.3 字符串对象缓冲池\n如果仔细思考一下，一定会猜到字符串也采用了这种类似的技术，我们来看一下\n<pre>\n\\>\\>\\> a = \'a\'\n\\>\\>\\> b = \'a\'\n\\>\\>\\> id(a)\n14660456\n\\>\\>\\> id(b)\n14660456\n</pre>\n\n没错，Python 的设计者为一个字节的字符对应的字符串对象 (PyStringObject) 也设计了这样一个对象池。同时还有一个 intern 机制，可以将内容相同的字符串变量转换成指向同一个字符串对象。\n\nintern 机制的关键，就是在系统中有一个（key，value）映射关系的集合，集合的名称叫做 interned。在这个集合中，记录着被 intern 机制处理过的 PyStringObject 对象。不过 Python 始终会为字符串创建 PyStringObject 对象，即便在interned 中已经有一个与之对应的 PyStringObject 对象了，而 intern 机制是在字符串被创建后才起作用。\n\n<pre>\n>>> a = \'a string\'\n>>> b = \'a string\'\n>>> a is b\nFalse\n>>> a = intern(\'a string\') # 手动调用 intern 方法\n>>> b = intern(\'a string\')\n>>> a is b\nTrue\n</pre>\n\n**更正**:我在Python3.5上做实验，发现\n> a = \'a string\'\n\n> b = \'a string\'\n\n> a is b\n\n结果为True，也就是说在Python3的情况下，它可能已经默认调用了intern()\n\n关于 intern 函数 可以参考[官方文档](https://docs.python.org/2/library/functions.html#intern)，更多扩展阅读：\n\nhttp://stackoverflow.com/questions/15541404/python-string-interning\n\n>值得说明的是，数值类型和字符串类型在 Python 中都是不可变的，这意味着你无法修改这个对象的值，每次对变量的修改，实际上是创建一个新的对象。得益于这样的设计，才能使用对象缓冲池这种优化。\n\nPython 的实现上大量采用了这种内存对象池的技术，不仅仅对于这些特定的对象，还有专门的内存池用于小对象，使用这种技术可以避免频繁地申请和释放内存空间，目的就是让 Python 能稍微更快一点。更多内容可以参考[这里](http://blog.csdn.net/zhzhl202/article/details/7547445)。\n\n> 如果想了解更快的 Python，可以看看 [PyPy](http://pypy.org/)\n\n###3.4 import 指令\n前文提到 import 指令是用来载入 module 的，如果需要，也会顺道做编译的事。但 import 指令，还会做一件重要的事情就是把 import 的那个 module 的代码执行一遍，这件事情很重要。Python 是解释执行的，连函数都是执行的时候才创建的。如果不把那个 module 的代码执行一遍，那么 module 里面的函数都没法创建，更别提去调用这些函数了。\n\n执行代码的另外一个重要作用，就是在这个 module 的命名空间中，创建模块内定义的函数和各种对象的符号名称（也就是变量名），并将其绑定到对象上，这样其他 module 才能通过变量名来引用这些对象。\n\nPython 虚拟机还会将已经 import 过的 module 缓存起来，放到一个全局 module 集合 sys.modules 中。这样做有一个好处，即如果程序的在另一个地方再次 import 这个模块，Python 虚拟机只需要将全局 module 集合中缓存的那个 module 对象返回即可。\n\n> 你现在一定想到了 sys.modules 是一个 dict 对象，可以通过 type(sys.modules) 来验证\n\n###3.5 多线程\ndemo.py 这个例子并没有用到多线程，但还是有必要提一下。\n\n在提到多线程的时候，往往要关注线程如何同步，如何访问共享资源。Python 是通过一个全局解释器锁 GIL（Global Interpreter Lock）来实现线程同步的。当 Python 程序只有单线程时，并不会启用 GIL，而当用户创建了一个 thread 时，表示要使用多线程，Python 解释器就会自动激活 GIL，并创建所需要的上下文环境和数据结构。\n\nPython 字节码解释器的工作原理是按照指令的顺序一条一条地顺序执行，Python 内部维护着一个数值，这个数值就是 Python 内部的时钟，如果这个数值为 N，则意味着 Python 在执行了 N 条指令以后应该立即启动线程调度机制，可以通过下面的代码获取这个数值。\n\n>import sys\n\n>sys.getcheckinterval() \\# 100\n\n线程调度机制将会为线程分配 GIL，获取到 GIL 的线程就能开始执行，而其他线程则必须等待。由于 GIL 的存在，Python 的多线程性能十分低下，无法发挥多核 CPU 的优势，性能甚至不如单线程。因此如果你想用到多核 CPU，一个建议是使用多进程。\n\n###3.6 垃圾回收\n在讲到垃圾回收的时候，通常会使用引用计数的模型，这是一种最直观，最简单的垃圾收集技术。Python 同样也使用了引用计数，但是引用计数存在这些缺点：\n- 频繁更新引用计数会降低运行效率\n- 引用计数无法解决循环引用问题\n\nPython 在引用计数机制的基础上，使用了主流垃圾收集技术中的标记——清除和分代收集两种技术。\n\n关于垃圾回收，可以参考\n\nhttp://hbprotoss.github.io/posts/pythonla-ji-hui-shou-ji-zhi.html\n\n原文链接：http://www.cnblogs.com/restran/p/4903056.html',1,'python',1474355404,0,41,0,1,1),(96,'一次和女友闹矛盾的经历','<p>昨晚，她高兴的吃着猕猴桃，我还是按照往常那样忙着家里的事情，她说她需要纸，我就给了她一卷而不是扯给她一张纸。她就心里不舒服了，对我脸色就变了。我在前面几分钟不小心把灯关了，可能对她也有些影响。</p>\n<p>看着她生气了，我心里其实很委屈的。一从实验室回到家就是我做各种事情，她只需要泡脚、看一些和学习有关或者无关的视频，我觉得即使做得没让你称心如意，你也不用给我摆脸色吧。为了不闹矛盾，我就去逗她开心，并且问她我哪里把她惹到了。她还是不理我。后面我的情绪就爆发了，我也不理她，即使是她那时候态度好了很多，但是她丝毫不提她发脾气的事情。之后两人就在床上各管个的，我睡觉而她还在玩手机。大概12点20的时候，她又把我弄醒，像是道歉又并非道歉，躺在我身边。我的气还未消，过了一会儿她就一个人哭起来了，并且故意离我很远。</p>\n<p>后来她就一直抽泣，我还是有些心疼，虽说我觉得她是无理取闹。所以我就上去安慰她。安慰了一会儿过后无效，我就放弃了，哎，现在想起来，还是应该坚持，不过感觉明明是自己受了委屈，现在弱势方反而转成小胖友了。后来她又把衣服穿上，大晚上的出门！</p>\n<p>我仓促穿上衣服，带上门就追了上去。但是她就把我躲了！后来找了很久没找到，又问门卫看到有年轻女孩出去没，门卫说没有，我才放心一些。我本想开门，结果一拧钥匙断了！！！当时我心里觉得老天都支持我们分手，一冲动把我中指的戒指扔了！！！而她的戒指早就搞丢了。于是就想着分手来着。但是我大晚上的又不敢刺激她，害怕她出什么事。后来找到她了，就在远处守着她。我两谁都不说话。后面就到了黎明了！</p>\n<p>我给她说分手，因为我确实觉得我受到了很大的伤害。后面过了几十分钟她又打电话过来挽留，说了很多很多，结果是和好了。其实很多时候我说分手都是因为我拿她实在没办法了，我在她面前根本没话语权。哎。。。我的好友说是我惯着她了，但好友是男生，自然从我的立场考虑。</p>\n<p>现在想起来，其实自己也挺小气的，有的时候包容一下就好了，有的时候多坚持一下，多哄哄她，或许就好了。每次一大吵都会这样，睡觉也睡不了，很伤身体。又是一个通宵，直到现在才清醒了。</p>','昨晚，她高兴的吃着猕猴桃，我还是按照往常那样忙着家里的事情，她说她需要纸，我就给了她一卷而不是扯给她一张纸。她就心里不舒服了，对我脸色就变了。我在前面几分钟不小心把灯关了，可能对她也有些影响。\n\n看着她生气了，我心里其实很委屈的。一从实验室回到家就是我做各种事情，她只需要泡脚、看一些和学习有关或者无关的视频，我觉得即使做得没让你称心如意，你也不用给我摆脸色吧。为了不闹矛盾，我就去逗她开心，并且问她我哪里把她惹到了。她还是不理我。后面我的情绪就爆发了，我也不理她，即使是她那时候态度好了很多，但是她丝毫不提她发脾气的事情。之后两人就在床上各管个的，我睡觉而她还在玩手机。大概12点20的时候，她又把我弄醒，像是道歉又并非道歉，躺在我身边。我的气还未消，过了一会儿她就一个人哭起来了，并且故意离我很远。\n\n后来她就一直抽泣，我还是有些心疼，虽说我觉得她是无理取闹。所以我就上去安慰她。安慰了一会儿过后无效，我就放弃了，哎，现在想起来，还是应该坚持，不过感觉明明是自己受了委屈，现在弱势方反而转成小胖友了。后来她又把衣服穿上，大晚上的出门！\n\n我仓促穿上衣服，带上门就追了上去。但是她就把我躲了！后来找了很久没找到，又问门卫看到有年轻女孩出去没，门卫说没有，我才放心一些。我本想开门，结果一拧钥匙断了！！！当时我心里觉得老天都支持我们分手，一冲动把我中指的戒指扔了！！！而她的戒指早就搞丢了。于是就想着分手来着。但是我大晚上的又不敢刺激她，害怕她出什么事。后来找到她了，就在远处守着她。我两谁都不说话。后面就到了黎明了！\n\n我给她说分手，因为我确实觉得我受到了很大的伤害。后面过了几十分钟她又打电话过来挽留，说了很多很多，结果是和好了。其实很多时候我说分手都是因为我拿她实在没办法了，我在她面前根本没话语权。哎。。。我的好友说是我惯着她了，但好友是男生，自然从我的立场考虑。\n\n现在想起来，其实自己也挺小气的，有的时候包容一下就好了，有的时候多坚持一下，多哄哄她，或许就好了。每次一大吵都会这样，睡觉也睡不了，很伤身体。又是一个通宵，直到现在才清醒了。\n\n',3,'',1474443772,0,37,0,1,1),(97,'也谈Python多线程/多进程的Join()','&lt;p&gt;我对<strong>join()</strong>的认识，源于<a href=\"http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001431927781401bb47ccf187b24c3b955157bb12c5882d000\">廖雪峰的Python教程</a>&lt;/p&gt;\n<blockquote>\n&lt;p&gt;join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。&lt;/p&gt;\n</blockquote>\n&lt;p&gt;后面由于<a href=\"https://github.com/ResolveWang/WeiboSpider\">微博爬虫</a>需要定时登陆，还需要设置每隔两个小时从数据库中查询URL种子然后抓取，定时任务比较复杂（这里就不详细讲了）。我是在两个进程间分别控制模拟登陆和微博+用户信息抓取的，模拟登陆是写的一个死循环，每23小时重新登陆一次，微博和用户信息抓取的某次任务可能会运行很长时间，所以模拟登陆用了死循环，然后通过进程间通信的方式让抓取进程来共享<strong>session</strong>。当抓取进程结束后，我就强制结束模拟登陆的进程，然后让主进程休眠两个小时，开始下一轮抓取。这个就是我第一次使用join()的情景。伪代码大概如下：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;login_process.start() # 开始模拟登陆&lt;/p&gt;\n&lt;p&gt;crawl_process.start() # 开始抓取任务&lt;/p&gt;\n&lt;p&gt;crawl_process.join()  # 等待抓取任务执行完成&lt;/p&gt;\n&lt;p&gt;login_process.terminate()  # 强制终止模拟登陆&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这是join()使用的最简单的场景，主要作用就是<strong>等待任务完成</strong>，即等待调用该方法的进程执行结束。另外，在调用了join()之后，<strong>主进程就会被阻塞</strong>。怎么理解呢，比如我在上述伪代码之后再加一行&lt;/p&gt;\n<blockquote>\n&lt;p&gt;print(\'crwal_process has come to the end\')&lt;/p&gt;\n</blockquote>\n&lt;p&gt;如果按照并行执行来理解的话，主进程也可以和子进程一起执行，但是上述语句只会在crawl_process这个进程完成之后执行，原因就是主进程被阻塞。那么我们可以让主进程不被阻塞吗？答案是肯定的。&lt;/p&gt;\n&lt;p&gt;如果我们没调用join()方法，那么<strong>print</strong>语句会最先打印，通过实验我发现，<strong>无论主进程执行时间多长，不带join()的时候都会优先执行主进程，并且只有等主进程全部执行完成才会执行子进程</strong>，即使主进程的某些语句写在crawl_process.start()之后。&lt;/p&gt;\n&lt;p&gt;join()函数还可以带一个<strong>timeout</strong>参数,这个timeout又有什么用呢？&lt;/p&gt;\n&lt;p&gt;通过上面的过程我们知道了<em>阻塞主进程</em>是什么意思。timeout参数的作用就是设置<strong>阻塞时间</strong>，如果调用join(timeout=mytime)的子进程在mytime时间内没有执行完成，那么主进程也会在<strong>mytime</strong>后跟着执行，经过实测，这时候不会优先执行主进程了，而是三个进程会并行执行。&lt;/p&gt;\n&lt;p&gt;关于join()的知识点就讲完了，总结一下：&lt;/p&gt;\n<blockquote>\n<ol>\n<li>\n&lt;p&gt;不带参数的时候，join()的作用是等待子进程执行完成，并且同时会阻塞主进程&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;带参数的情况下，只有在timeout时间内会阻塞主进程，之后主进程会于没执行完的子进程并行执行&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;不调用join()的时候，主进程所有语句会先于子进程执行，并且只有当主进程执行完成子进程才可以执行&lt;/p&gt;\n</li>\n</ol>\n</blockquote>','我对**join()**的认识，源于[廖雪峰的Python教程](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001431927781401bb47ccf187b24c3b955157bb12c5882d000)\n> join()方法可以等待子进程结束后再继续往下运行，通常用于进程间的同步。\n\n后面由于[微博爬虫](https://github.com/ResolveWang/WeiboSpider)需要定时登陆，还需要设置每隔两个小时从数据库中查询URL种子然后抓取，定时任务比较复杂（这里就不详细讲了）。我是在两个进程间分别控制模拟登陆和微博+用户信息抓取的，模拟登陆是写的一个死循环，每23小时重新登陆一次，微博和用户信息抓取的某次任务可能会运行很长时间，所以模拟登陆用了死循环，然后通过进程间通信的方式让抓取进程来共享**session**。当抓取进程结束后，我就强制结束模拟登陆的进程，然后让主进程休眠两个小时，开始下一轮抓取。这个就是我第一次使用join()的情景。伪代码大概如下：\n> login_process.start() \\# 开始模拟登陆\n\n> crawl_process.start() \\# 开始抓取任务\n\n> crawl_process.join()  \\# 等待抓取任务执行完成\n\n> login_process.terminate()  \\# 强制终止模拟登陆\n\n这是join()使用的最简单的场景，主要作用就是**等待任务完成**，即等待调用该方法的进程执行结束。另外，在调用了join()之后，**主进程就会被阻塞**。怎么理解呢，比如我在上述伪代码之后再加一行\n> print(\'crwal_process has come to the end\')\n\n如果按照并行执行来理解的话，主进程也可以和子进程一起执行，但是上述语句只会在crawl_process这个进程完成之后执行，原因就是主进程被阻塞。那么我们可以让主进程不被阻塞吗？答案是肯定的。\n\n如果我们没调用join()方法，那么**print**语句会最先打印，通过实验我发现，**无论主进程执行时间多长，不带join()的时候都会优先执行主进程，并且只有等主进程全部执行完成才会执行子进程**，即使主进程的某些语句写在crawl_process.start()之后。\n\njoin()函数还可以带一个**timeout**参数,这个timeout又有什么用呢？\n\n通过上面的过程我们知道了*阻塞主进程*是什么意思。timeout参数的作用就是设置**阻塞时间**，如果调用join(timeout=mytime)的子进程在mytime时间内没有执行完成，那么主进程也会在**mytime**后跟着执行，经过实测，这时候不会优先执行主进程了，而是三个进程会并行执行。\n\n关于join()的知识点就讲完了，总结一下：\n\n>1. 不带参数的时候，join()的作用是等待子进程执行完成，并且同时会阻塞主进程\n\n>2. 带参数的情况下，只有在timeout时间内会阻塞主进程，之后主进程会于没执行完的子进程并行执行\n\n>3. 不调用join()的时候，主进程所有语句会先于子进程执行，并且只有当主进程执行完成子进程才可以执行',1,'python,多进程',1474448066,0,32,0,1,1),(98,'聊聊Python多进程/多线程中的守护进程/守护线程','&lt;p&gt;今天阅读《Python核心编程》看到关于守护线程的解释&lt;/p&gt;\n<blockquote>\n&lt;p&gt;如果把一个线程设置为守护线程，就表示这个线程是不重要的，进程退出时不需要等待这个线程执行完成&lt;/p&gt;\n</blockquote>\n&lt;p&gt;下面看一个关于守护进程的例子:\n&lt;pre&gt;\n#-<em>- coding = utf8 -</em>-&lt;/p&gt;\n&lt;p&gt;import multiprocessing\nimport time&lt;/p&gt;\n&lt;p&gt;def daemon():\n    name = multiprocessing.current_process().name\n    print(\'Starting {name}\'.format(name=name))\n    time.sleep(5)\n    print(\'Exiting, {name}\'.format(name=name))&lt;/p&gt;\n&lt;p&gt;def non_daemon():\n    name = multiprocessing.current_process().name\n    print(\'Starting {name}\'.format(name=name))\n    print(\'Exiting name {name}\'.format(name=name))&lt;/p&gt;\n&lt;p&gt;if <strong>name</strong> == \'<strong>main</strong>\':\n    d = multiprocessing.Process(name=\'daemon\', target=daemon)\n    d.daemon = True\n    n = multiprocessing.Process(name=\'non_daemon\', target=non_daemon)\n    n.daemon = False\n    d.start()\n    n.start()\n    d.join(timeout=1)\n    n.join()\n    print(\'d.is_alive() {live}\'.format(live=d.is_alive()))\n    print(\'n.is_alive() {live}\'.format(live=n.is_alive()))&lt;/p&gt;\n&lt;/pre&gt;\n\n&lt;p&gt;打印结果&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Starting daemon&lt;/p&gt;\n&lt;p&gt;Starting non_daemon&lt;/p&gt;\n&lt;p&gt;Exiting name non_daemon&lt;/p&gt;\n&lt;p&gt;d.is_alive() True&lt;/p&gt;\n&lt;p&gt;n.is_alive() False&lt;/p&gt;\n</blockquote>\n&lt;p&gt;可以看到<strong>daemon进程</strong>在主进程运行的最后一刻还是活着的,当主进程结束了，并没打印出&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Exiting, daemon&lt;/p&gt;\n</blockquote>\n&lt;p&gt;如果我们不设置daemon进程为守护进程呢(即改为<em>d.daemon = False</em> )？运行上述代码，打印结果&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Starting daemon&lt;/p&gt;\n&lt;p&gt;Starting non_daemon&lt;/p&gt;\n&lt;p&gt;Exiting name non_daemon&lt;/p&gt;\n&lt;p&gt;d.is_alive() True&lt;/p&gt;\n&lt;p&gt;n.is_alive() False&lt;/p&gt;\n&lt;p&gt;Exiting, daemon&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这时候打印出了&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Exiting, daemon&lt;/p&gt;\n</blockquote>\n&lt;p&gt;表示名为daemon的进程也执行完了。对比两者，就不难理解文章开头提的那句话意思了，<strong>主进程的退出并不受守护进程/守护线程的影响</strong>&lt;/p&gt;\n&lt;p&gt;那么当主进程退出后，守护进程又还在运行吗？答案是<strong>没运行</strong>。验证这个可以在上面的守护进程中把休眠时间和主进程执行时间改长一些，linux上使用<strong>ps aux</strong>便可以看到正在执行的进程了，通过主进程执行前后使用该命令可看到<strong>在主进程执行结束后，守护进程也终止了</strong>&lt;/p&gt;\n&lt;p&gt;Python的守护进程大概就是这样，我在网上查了一些资料，有一些有误，说主进程执行完成之后，守住进程会继续执行。这个结论是错误的，可以通过上述的代码进行实验。&lt;/p&gt;\n&lt;p&gt;&lt;hr&gt;\n请区分把多进程中的守护进程和操作系统的守护进程，两者不在一个层次。多进程的守护进程，守护的是主进程，主进程结束它就跟着结束了。而操作系统的守护进程，引用<a href=\"http://www.ruanyifeng.com/blog/2016/02/linux-daemon.html\">阮一峰的博客</a>来解释：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;一直在后台运行的进程&lt;/p&gt;\n</blockquote>\n&lt;p&gt;推荐大家阅读这篇博客。linux上的表现形式如命令<strong>nohup+command+&amp;</strong>运行的程序，就可以看做一个守护进程，在当前用户退出后，进程会持续执行。在windows上可以理解为<strong>service</strong>。比如<strong>mysqld</strong>&lt;/p&gt;\n&lt;p&gt;本文旨在讲解python多进程中的守护进程，关于linux的守护进程请参考:<a href=\"http://www.ruanyifeng.com/blog/2016/02/linux-daemon.html\">这里</a>&lt;/p&gt;','今天阅读《Python核心编程》看到关于守护线程的解释\n> 如果把一个线程设置为守护线程，就表示这个线程是不重要的，进程退出时不需要等待这个线程执行完成\n\n下面看一个关于守护进程的例子:\n<pre>\n\\#-*- coding = utf8 -*-\n\nimport multiprocessing\nimport time\n\n\ndef daemon():\n    name = multiprocessing.current_process().name\n    print(\'Starting {name}\'.format(name=name))\n    time.sleep(5)\n    print(\'Exiting, {name}\'.format(name=name))\n\n\ndef non_daemon():\n    name = multiprocessing.current_process().name\n    print(\'Starting {name}\'.format(name=name))\n    print(\'Exiting name {name}\'.format(name=name))\n\n\nif __name__ == \'__main__\':\n    d = multiprocessing.Process(name=\'daemon\', target=daemon)\n    d.daemon = True\n    n = multiprocessing.Process(name=\'non_daemon\', target=non_daemon)\n    n.daemon = False\n    d.start()\n    n.start()\n    d.join(timeout=1)\n    n.join()\n    print(\'d.is_alive() {live}\'.format(live=d.is_alive()))\n    print(\'n.is_alive() {live}\'.format(live=n.is_alive()))\n\n</pre>\n\n打印结果\n>Starting daemon\n\n>Starting non_daemon\n\n>Exiting name non_daemon\n\n>d.is_alive() True\n\n>n.is_alive() False\n\n可以看到**daemon进程**在主进程运行的最后一刻还是活着的,当主进程结束了，并没打印出\n>  Exiting, daemon\n\n如果我们不设置daemon进程为守护进程呢(即改为*d.daemon = False* )？运行上述代码，打印结果\n>Starting daemon\n\n>Starting non_daemon\n\n>Exiting name non_daemon\n\n>d.is_alive() True\n\n>n.is_alive() False\n\n>Exiting, daemon\n\n这时候打印出了\n>Exiting, daemon\n\n表示名为daemon的进程也执行完了。对比两者，就不难理解文章开头提的那句话意思了，**主进程的退出并不受守护进程/守护线程的影响**\n\n那么当主进程退出后，守护进程又还在运行吗？答案是**没运行**。验证这个可以在上面的守护进程中把休眠时间和主进程执行时间改长一些，linux上使用**ps aux**便可以看到正在执行的进程了，通过主进程执行前后使用该命令可看到**在主进程执行结束后，守护进程也终止了**\n\nPython的守护进程大概就是这样，我在网上查了一些资料，有一些有误，说主进程执行完成之后，守住进程会继续执行。这个结论是错误的，可以通过上述的代码进行实验。\n\n<hr>\n请区分把多进程中的守护进程和操作系统的守护进程，两者不在一个层次。多进程的守护进程，守护的是主进程，主进程结束它就跟着结束了。而操作系统的守护进程，引用[阮一峰的博客](http://www.ruanyifeng.com/blog/2016/02/linux-daemon.html)来解释：\n>一直在后台运行的进程\n\n推荐大家阅读这篇博客。linux上的表现形式如命令**nohup+command+&**运行的程序，就可以看做一个守护进程，在当前用户退出后，进程会持续执行。在windows上可以理解为**service**。比如**mysqld**\n\n本文旨在讲解python多进程中的守护进程，关于linux的守护进程请参考:[这里](http://www.ruanyifeng.com/blog/2016/02/linux-daemon.html)\n',1,'python,多进程',1474450000,0,63,0,1,1),(99,'python读取配置文件','&lt;p&gt;Python3读取配置文件的类为<strong>configparser</strong>,在Python2中是<strong>ConfigParser</strong>，两者接口相似。以Python3为例说明其用法。&lt;/p&gt;\n&lt;p&gt;配置文件通常以<strong>.conf</strong>或者<strong>.ini</strong>结尾，当然你也可以换成别的，只要格式符合要求即可。我们看看配置文件的格式：\n&lt;pre&gt;\n[db]\nhost = 1.2.3.4\nport = 1234\nuser = root\npassword = 123456&lt;/p&gt;\n&lt;p&gt;[weibo]\nname = okstr\npassword = dafw\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;下面是操作该配置文件的代码：&lt;/p&gt;\n&lt;pre&gt;\nimport configparser\n\ndef main():\n    cf = configparser.ConfigParser()\n    cf.read_file(open(\'f:/test.conf\'))\n\n    # 返回所有区段的键\n    secs = cf.sections()\n    print(\'secs:%s\' % secs)\n\n    # 返回指定区段的键\n    opts = cf.options(\'db\')\n    print(\'opts:%s\' % opts)\n\n    # 返回指定区段的所有键值对\n    its = cf.items(\'db\')\n    print(\'its:%s\' % its)\n\n    # 根据指定名读取值，并且在读取的时候可指定类型\n    port = cf.getint(\'db\', \'port\')\n    host = cf.get(\'db\', \'host\')\n    user = cf.get(\'weibo\', \'name\')\n    password = cf.get(\'weibo\', \'password\')\n    print(\'host:%s\' % host)\n    print(\'port:%s\' % port)\n    print(\'user:%s\' % user)\n    print(\'pass:%s\' % password)\n\n    # 修改配置文件中指定键的值，注意最后要写入文件才会生效\n    cf.set(\'weibo\', \'password\', password[::-1])\n    #cf.write(open(\'test.conf\', \'w\'))\n\n    # 添加区块和键值对\n    cf.add_section(\'section\')\n    cf.set(\'section\', \'ok\', \'okstr\')\n    #cf.write(open(\'test.conf\', \'w\'))\n\n    # 删除指定区块或者键值对\n    cf.remove_section(\'weibo\')\n    cf.remove_option(\'db\', \'host\')\n    cf.write(open(\'test.conf\', \'w\'))\n\nif __name__ == \"__main__\":\n    main()\n&lt;/pre&gt;\n\n&lt;hr&gt;\n\n&lt;p&gt;如果需要一次性以dict的方式返回配置文件某个section中的数据，那么可以这样&lt;/p&gt;\n<blockquote>\n&lt;p&gt;dict(cf.items(\'db\'))&lt;/p&gt;\n</blockquote>','Python3读取配置文件的类为**configparser**,在Python2中是**ConfigParser**，两者接口相似。以Python3为例说明其用法。\n\n配置文件通常以**.conf**或者**.ini**结尾，当然你也可以换成别的，只要格式符合要求即可。我们看看配置文件的格式：\n<pre>\n[db]\nhost = 1.2.3.4\nport = 1234\nuser = root\npassword = 123456\n\n[weibo]\nname = okstr\npassword = dafw\n</pre>\n\n下面是操作该配置文件的代码：\n\n<pre>\nimport configparser\n\n\ndef main():\n    cf = configparser.ConfigParser()\n    cf.read_file(open(\'f:/test.conf\'))\n\n    # 返回所有区段的键\n    secs = cf.sections()\n    print(\'secs:%s\' % secs)\n\n    # 返回指定区段的键\n    opts = cf.options(\'db\')\n    print(\'opts:%s\' % opts)\n\n    # 返回指定区段的所有键值对\n    its = cf.items(\'db\')\n    print(\'its:%s\' % its)\n\n    # 根据指定名读取值，并且在读取的时候可指定类型\n    port = cf.getint(\'db\', \'port\')\n    host = cf.get(\'db\', \'host\')\n    user = cf.get(\'weibo\', \'name\')\n    password = cf.get(\'weibo\', \'password\')\n    print(\'host:%s\' % host)\n    print(\'port:%s\' % port)\n    print(\'user:%s\' % user)\n    print(\'pass:%s\' % password)\n\n    # 修改配置文件中指定键的值，注意最后要写入文件才会生效\n    cf.set(\'weibo\', \'password\', password[::-1])\n    #cf.write(open(\'test.conf\', \'w\'))\n\n    # 添加区块和键值对\n    cf.add_section(\'section\')\n    cf.set(\'section\', \'ok\', \'okstr\')\n    #cf.write(open(\'test.conf\', \'w\'))\n\n    # 删除指定区块或者键值对\n    cf.remove_section(\'weibo\')\n    cf.remove_option(\'db\', \'host\')\n    cf.write(open(\'test.conf\', \'w\'))\n\nif __name__ == \"__main__\":\n    main()\n</pre>\n\n<hr>\n\n如果需要一次性以dict的方式返回配置文件某个section中的数据，那么可以这样\n>dict(cf.items(\'db\'))\n\n\n',1,'python',1474868569,0,47,0,1,1),(100,'聊聊猴子补丁(monkey patch)','&lt;p&gt;在看<strong>requests</strong>源码的时候，看到\n&lt;pre&gt;\ntry:\n    import eventlet\n    eventlet.monkey_patch()\nexcept ImportError:\n    pass\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;在源码的后面搜索<strong>monkey_patch()</strong>并没搜到，难道这个光import,然后调用一下就行了吗？它有什么作用呢？后来看到知乎上赖永浩大神的回答&lt;/p&gt;\n<blockquote>\n&lt;p&gt;当一个库的代码是纯 Python 的时候，加上 monkey patch 技法，那么这个库使用的就是 gevent.socket 了，从而不需要任何更改就能够获得 gevent 的同步代码异步执行的“超级牛力”。&lt;/p&gt;\n</blockquote>\n&lt;p&gt;用过gevent就会知道,会在最开头的地方gevent.monkey.patch_all();把标准库中的thread/socket等给替换掉.这样我们在后面使用socket的时候可以跟平常一样使用,无需修改任何代码,但是它变成非阻塞的了.&lt;/p&gt;\n&lt;p&gt;其实monkey patch不一定非要用于io操作，说全一些，它是在运行时动态替换,一般是在startup的时候.&lt;/p&gt;\n&lt;p&gt;设想这么一个情景，某个项目很多地方用的import json,后来发现ujson比自带json快了N倍,于是问题来了,难道几十个文件要一个个把import json改成import ujson as json吗?&lt;/p&gt;\n&lt;p&gt;其实只需要在进程startup的地方monkey patch就行了.是影响<strong>整个进程空间</strong>的.&lt;/p&gt;\n&lt;p&gt;同一进程空间中一个module只会被运行一次.下面是示例代码：\n&lt;pre&gt;\n# main.py\nimport json\nimport ujson&lt;/p&gt;\n&lt;p&gt;def monkey_patch_json():\n    json.<strong>name</strong> = \'ujson\'\n    json.dumps = ujson.dumps\n    json.loads = ujson.loads&lt;/p&gt;\n&lt;p&gt;if <strong>name</strong> == \'<strong>main</strong>\':\n    monkey_patch_json()\n    print(\'main.py\', json.<strong>name</strong>)\n    import sub\n&lt;/pre&gt;&lt;/p&gt;\n&lt;pre&gt;\n# sub.py\nimport json\nprint(\'sub.py\', json.__name__)\n&lt;/pre&gt;\n\n&lt;p&gt;输出：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;main.py ujson&lt;/p&gt;\n&lt;p&gt;sub.py ujson&lt;/p&gt;\n</blockquote>\n&lt;p&gt;以上说明<em>sub.py</em>中的json模块是被patch过的。如果我们把<em>import json</em> 放在<em>monkey_patch_json</em>的前面，那么输出就是这样&lt;/p&gt;\n<blockquote>\n&lt;p&gt;sub.py json&lt;/p&gt;\n&lt;p&gt;main.py ujson&lt;/p&gt;\n</blockquote>\n&lt;p&gt;所以需要在monkey_patch函数运行之后进行别的操作,这样patch才会生效&lt;/p&gt;\n&lt;p&gt;最后,注意不能单纯的json = ujson来替换.&lt;/p&gt;\n&lt;p&gt;参考：<a href=\"http://blog.csdn.net/handsomekang/article/details/40297775\">什么是猴子补丁(monkey patch)</a>&lt;/p&gt;','在看**requests**源码的时候，看到\n<pre>\ntry:\n    import eventlet\n    eventlet.monkey_patch()\nexcept ImportError:\n    pass\n</pre>\n\n在源码的后面搜索**monkey_patch()**并没搜到，难道这个光import,然后调用一下就行了吗？它有什么作用呢？后来看到知乎上赖永浩大神的回答\n> 当一个库的代码是纯 Python 的时候，加上 monkey patch 技法，那么这个库使用的就是 gevent.socket 了，从而不需要任何更改就能够获得 gevent 的同步代码异步执行的“超级牛力”。\n\n用过gevent就会知道,会在最开头的地方gevent.monkey.patch_all();把标准库中的thread/socket等给替换掉.这样我们在后面使用socket的时候可以跟平常一样使用,无需修改任何代码,但是它变成非阻塞的了.\n\n其实monkey patch不一定非要用于io操作，说全一些，它是在运行时动态替换,一般是在startup的时候.\n\n设想这么一个情景，某个项目很多地方用的import json,后来发现ujson比自带json快了N倍,于是问题来了,难道几十个文件要一个个把import json改成import ujson as json吗?\n\n其实只需要在进程startup的地方monkey patch就行了.是影响**整个进程空间**的.\n\n同一进程空间中一个module只会被运行一次.下面是示例代码：\n<pre>\n\\# main.py\nimport json\nimport ujson\n\n\ndef monkey_patch_json():\n    json.__name__ = \'ujson\'\n    json.dumps = ujson.dumps\n    json.loads = ujson.loads\n\nif __name__ == \'__main__\':\n    monkey_patch_json()\n    print(\'main.py\', json.__name__)\n    import sub\n</pre>\n\n<pre>\n# sub.py\nimport json\nprint(\'sub.py\', json.__name__)\n</pre>\n\n输出：\n>main.py ujson\n\n>sub.py ujson\n\n以上说明*sub.py*中的json模块是被patch过的。如果我们把*import json* 放在*monkey_patch_json*的前面，那么输出就是这样\n>sub.py json\n\n>main.py ujson\n\n所以需要在monkey_patch函数运行之后进行别的操作,这样patch才会生效\n\n最后,注意不能单纯的json = ujson来替换.\n\n参考：[什么是猴子补丁(monkey patch)](http://blog.csdn.net/handsomekang/article/details/40297775)',1,'python',1475048856,0,35,0,1,1),(101,'cx_Oracle和sqlalchemy:LOB variable no longer valid after subsequent fetch','<p>这几天在重构<a href=\"https://github.com/ResolveWang/WeiboSpider\">微博爬虫</a>，想把原生查询改为ORM操作，我选择的是<em>sqlalchemy</em>。在测试从数据库中获取微博内容的时候，出现了如下错误</p>\n<blockquote>\n<p>cx_Oracle.ProgrammingError: LOB variable no longer valid after subsequent fetch</p>\n</blockquote>\n<p>sqlalchemy用的oracle驱动也是cx_Oracle，在cx_Oracle官网可以看到这么一段话</p>\n<blockquote>\n<p>Internally, Oracle uses LOB locators which are allocated based on the cursor array size. Thus, it is important that the data in the LOB object be manipulated before another internal fetch takes place. The safest way to do this is to use the cursor as an iterator. In particular, do not use the fetchall() method. <strong>The exception “LOB variable no longer valid after subsequent fetch” will be raised if an attempt to access a LOB variable after a subsequent fetch is detected.</strong></p>\n</blockquote>\n<p>大概意思就是说Oracle使用基于游标的LOB定位器，所以在迭代到下一个fetch之前最好对当前fetch的LOB字段进行操作，最好的方法就是使用把游标当成迭代器而不是调用fetchall()方法。该异常会在试图从子结果获取LOB变量的时候发生。</p>\n<p>下面是解决方法\n<pre>\n    con = db_connect.get_con()\n    curs = con.cursor()\n    curs.execute(sql)\n    for rows in curs:\n        print(rows[3]) # 这里的row[3]在Oracle中是CLOB字段\n</pre></p>','这几天在重构[微博爬虫](https://github.com/ResolveWang/WeiboSpider)，想把原生查询改为ORM操作，我选择的是*sqlalchemy*。在测试从数据库中获取微博内容的时候，出现了如下错误\n>cx_Oracle.ProgrammingError: LOB variable no longer valid after subsequent fetch\n\nsqlalchemy用的oracle驱动也是cx_Oracle，在cx_Oracle官网可以看到这么一段话\n>Internally, Oracle uses LOB locators which are allocated based on the cursor array size. Thus, it is important that the data in the LOB object be manipulated before another internal fetch takes place. The safest way to do this is to use the cursor as an iterator. In particular, do not use the fetchall() method. **The exception “LOB variable no longer valid after subsequent fetch” will be raised if an attempt to access a LOB variable after a subsequent fetch is detected.**\n\n大概意思就是说Oracle使用基于游标的LOB定位器，所以在迭代到下一个fetch之前最好对当前fetch的LOB字段进行操作，最好的方法就是使用把游标当成迭代器而不是调用fetchall()方法。该异常会在试图从子结果获取LOB变量的时候发生。\n\n下面是解决方法\n<pre>\n    con = db_connect.get_con()\n    curs = con.cursor()\n    curs.execute(sql)\n    for rows in curs:\n        print(rows[3]) # 这里的row[3]在Oracle中是CLOB字段\n</pre>\n',1,'python,oracle',1475117067,0,50,0,1,1),(102,'python中计算时间差','&lt;h2&gt;场景&lt;/h2&gt;\n&lt;p&gt;已知过去某个时间点的时间戳，计算和此刻的时间差&lt;/p&gt;\n&lt;h2&gt;解决方法&lt;/h2&gt;\n&lt;p&gt;使用datetime模块，将时间戳转化为datetime类型，然后用减法做差，再转化为秒&lt;/p&gt;\n&lt;p&gt;例子：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;post_stamp = 1475670028&lt;/p&gt;\n&lt;p&gt;post_time = datetime.fromtimestamp(post_stamp)&lt;/p&gt;\n&lt;p&gt;now = datetime.now()&lt;/p&gt;\n&lt;p&gt;t = (now - post_time).total_seconds()&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这里的<strong>post_stamp</strong>是已知的时间戳，而fromtimestamp()方法就是把时间戳转化为datetime类(本地时间)，和它相似的还有一个utcfromtimestamp()函数，这个是转化为<strong>UTC时间</strong>。total_seconds()是将timedelta(时间差对象)转化为秒&lt;/p&gt;','## 场景\n已知过去某个时间点的时间戳，计算和此刻的时间差\n\n## 解决方法\n使用datetime模块，将时间戳转化为datetime类型，然后用减法做差，再转化为秒\n\n例子：\n>post_stamp = 1475670028\n\n>post_time = datetime.fromtimestamp(post_stamp)\n\n>now = datetime.now()\n\n>t = (now - post_time).total_seconds()\n\n这里的**post_stamp**是已知的时间戳，而fromtimestamp()方法就是把时间戳转化为datetime类(本地时间)，和它相似的还有一个utcfromtimestamp()函数，这个是转化为**UTC时间**。total_seconds()是将timedelta(时间差对象)转化为秒',1,'python',1475739059,0,27,0,1,1),(103,'使用python+微博进行远程关机','&lt;p&gt;很长一段时间没有更新简书的内容了，打算把微博爬虫完善得差不多之后，再系统的把做微博爬虫的每个模块和阶段都记录下来。其中微博页面抓取和解析、用户页面抓取和分析等模块，都是可以复用的。现在还只是单机单线程，因为微博的反爬虫机制还没完全研究透，等找到抓取的阈值后再考虑分布式或者多进程。<a href=\"https://github.com/ResolveWang/WeiboSpider\">这里</a>是微博扩散分析的项目地址，有兴趣的可以看看，喜欢的话不防点个<a href=\"https://github.com/ResolveWang/WeiboSpider\"><strong>star</strong></a>，如何？&lt;/p&gt;\n&lt;hr/&gt;\n&lt;p&gt;这篇文章写的是基于<a href=\"http://www.rookiefly.cn/detail/83\">模拟登陆微博</a>的一个小工具。使用情况是人不在办公室，但是电脑没有关闭，需要远程关闭电脑。对模拟登陆微博有问题的同学，请移步我的<a href=\"http://www.rookiefly.cn/detail/83\">这篇文章</a>。下面进入正题。&lt;/p&gt;\n&lt;p&gt;思路\n- 定时模拟登陆（定时是因为微博cookie<strong>24小时</strong>失效）,关于模拟登陆详细步骤可参考<a href=\"http://www.rookiefly.cn/detail/83\">我的博文</a>，代码可参考<a href=\"https://github.com/ResolveWang/smart_login\">github项目</a>\n- 定时(10分钟)获取最新一条微博，并把发布时间和系统时间做比较，如果相差在<strong>半个小时</strong>以内，我们就认为命令有效，那么就让系统执行关机命令&lt;/p&gt;\n&lt;p&gt;项目依赖\n- 模拟登陆+页面解析：\n - requests+pyexecjs+beautifulsoup\n - pip install requests \n - pip install bs4 \n - pip install PyExecJS\n- 命令行解析<strong>docopt</strong>\n - pip install docopt \n- phantomjs \n - windows:在<a href=\"http://phantomjs.org/\">phantomjs官网</a>下载它，并且把它的路径<strong>添加到环境变量</strong>中 \n - ubuntu：<em>sudo apt-get install phantomjs</em> 或者到官网下载并且<strong>添加到环境变量</strong>中&lt;/p&gt;\n&lt;p&gt;各个模块和代码&lt;/p&gt;\n&lt;p&gt;<strong>login.py</strong> &lt;/p&gt;\n<blockquote>\n&lt;p&gt;该模块代码负责模拟登陆，<a href=\"http://www.rookiefly.cn/detail/83\">之前</a>已经详细讲过这部分代码了，在这里就不啰嗦了，最后返回的是session和uid(微博ID,用于拼凑主页URL)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;<strong> weibo_parser.py</strong>&lt;/p&gt;\n<blockquote>\n&lt;p&gt;解析微博主页，并且返回最新一条微博和发布时间&lt;/p&gt;\n</blockquote>\n&lt;p&gt;具体代码如下\n&lt;pre&gt;\n def get_newest(session, uid):\n    # 获取只含有原创内容的个人主页\n    url = \'http://weibo.com/\' + uid + \'/profile?profile_ftype=1&amp;is_ori=1#_0\'\n    page = session.get(url).text\n    soup = BeautifulSoup(page, \'html.parser\')\n    scripts = soup.find_all(\'script\')\n    status = \' \'\n    for s in scripts:\n        if \'pl.content.homeFeed.index\' in s.string:\n                status = s.string\n    # 用正则表达式获取微博原创内容\n    pattern = re.compile(r\'FM.view((.*))\')\n    rs = pattern.search(status)\n    if rs:\n        cur_status = rs.group(1)\n        html = json.loads(cur_status).get(\'html\')\n        soup = BeautifulSoup(html, \'html.parser\')\n        # 获取最新一条微博所有信息\n        newest = soup.find(attrs={\'action-type\': \'feed_list_item\'})\n        # 获取最新发布内容\n        post_cont = newest.find(attrs={\'node-type\': \'feed_list_content\'}).text.strip()\n        # 获取最新发布时间\n        post_stamp = int(newest.find(attrs={\'node-type\': \'feed_list_item_date\'}).get(\'date\')[:-3])\n        post_time = datetime.fromtimestamp(post_stamp)\n        now = datetime.now()\n        # 计算此刻和发布时间的时间差(单位为秒)\n        t = (now - post_time).total_seconds()\n        return post_cont, t\n    else:\n        return None\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;这里面用到的知识包括beautifulsoup和正则表达式，它们的具体使用我就不细说了，关于正则表达式，<strong>search()</strong>函数我是用得最多的，beautifulsoup我用得最多的是<strong>find(attrs={key: value})</strong>,<strong>attrs</strong>这个参数真心好用！这个是beautifulsoup的官方文档:<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html\">bs中文文档</a>.关于页面解析，可能我会专门写一篇文章详细说，这里就略去了。&lt;/p&gt;\n&lt;p&gt;<strong>pc_shutdown.py</strong>\n&lt;pre&gt;\n\"\"\"Resolvewang&lt;/p&gt;\n&lt;p&gt;Usage:  &lt;br/&gt;\n    pc_shutdow.py name &lt;name&gt; password &lt;password&gt;  &lt;br/&gt;\n    pc_shutdow.py (-h | --help)  &lt;br/&gt;\n    pc_shutdow.py --version&lt;/p&gt;\n&lt;p&gt;Options:  &lt;br/&gt;\n    -h --help   Show this screen.  &lt;br/&gt;\n    --version   Show version\n\"\"\"\nfrom login import get_cur_session\nfrom weibo_parser import get_newest\nfrom docopt import docopt\nfrom os import system\nimport platform\nimport time&lt;/p&gt;\n&lt;p&gt;def shutdown(name, password):  &lt;br/&gt;\n    session, uid = get_cur_session(name, password)  &lt;br/&gt;\n    return get_newest(session, uid)&lt;/p&gt;\n&lt;p&gt;if <strong>name</strong> == \'<strong>main</strong>\':  &lt;br/&gt;\n    # 从命令行获取登陆账号和密码\n    args = docopt(<strong>doc</strong>, version=\'ShutdownMyPC 1.0\')  &lt;br/&gt;\n    login_name = args.get(\'&lt;name&gt;\')  &lt;br/&gt;\n    login_pass = args.get(\'&lt;password&gt;\')&lt;br/&gt;\n    # 循环用于定时查看是否有新微博发布 \n    while True:    &lt;br/&gt;\n        # 获取发布内容和时间，内容用 \" \"隔开，比如“关机 10”&lt;br/&gt;\n        cont, ptdelta = shutdown(login_name, login_pass)      &lt;br/&gt;\n        info = cont.split(\' \')\n        # 判断是关机命令还是正常微博    &lt;br/&gt;\n        if info[0] == \'关机\' and ptdelta &lt; 30 * 60:          &lt;br/&gt;\n            shut_time = 0          &lt;br/&gt;\n            try:              &lt;br/&gt;\n                shut_time = int(info[1])          &lt;br/&gt;\n            except Exception:              &lt;br/&gt;\n                print(\'马上自动关机\')          &lt;br/&gt;\n            else:              &lt;br/&gt;\n                print(\'{time}分钟后自动关机\'.format(time=info[1]))          &lt;br/&gt;\n            finally:\n                # 判断操作系统平台，由于没有mac实验环境，所以这里没添加mac的相关判断              &lt;br/&gt;\n                os_system = platform.system().lower()              &lt;br/&gt;\n                if os_system == \'windows\':                  &lt;br/&gt;\n                    command = \'shutdown -s -t {shut_time}\'.format(shut_time=shut_time<em>60) \n                else:                  &lt;br/&gt;\n                    command = \'shutdown -h {shut_time}\'.format(shut_time=shut_time)\n                # 执行关机命令\n                system(command)      &lt;br/&gt;\n        time.sleep(10</em>60)\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;这段代码的逻辑基本都写在注释里了，其中有个docopt模块，是关于命令行参数的，如果有不清楚的同学可以看看<a href=\"https://wp-lai.gitbooks.io/learn-python/content/0MOOC/docopt.html\">这篇博客</a>，也可以看看它的<a href=\"https://github.com/docopt/docopt\">github</a>，里面有很多例子&lt;/p&gt;\n&lt;hr/&gt;\n&lt;p&gt;关于使用微博进行远程关机的讲解都完了，上述代码还有可以改进的地方，特别是<em>pc_shutdown.py</em>,比如&lt;/p&gt;\n<ul>\n<li>使用定时器进行查看新微博</li>\n<li>session复用直到24小时失效，这样就不用每隔十分钟就重新登陆一次了，可以通过多进程或者多线程共享变量实现</li>\n<li>可以把这个小工具修改成一个开机启动脚本(linux平台)或者服务(win平台)。</li>\n</ul>\n&lt;p&gt;吾生也有涯，而知也无涯。大家加油，共勉！&lt;/p&gt;','很长一段时间没有更新简书的内容了，打算把微博爬虫完善得差不多之后，再系统的把做微博爬虫的每个模块和阶段都记录下来。其中微博页面抓取和解析、用户页面抓取和分析等模块，都是可以复用的。现在还只是单机单线程，因为微博的反爬虫机制还没完全研究透，等找到抓取的阈值后再考虑分布式或者多进程。[这里](https://github.com/ResolveWang/WeiboSpider)是微博扩散分析的项目地址，有兴趣的可以看看，喜欢的话不防点个[**star**](https://github.com/ResolveWang/WeiboSpider)，如何？\n\n---\n\n这篇文章写的是基于[模拟登陆微博](http://www.rookiefly.cn/detail/83)的一个小工具。使用情况是人不在办公室，但是电脑没有关闭，需要远程关闭电脑。对模拟登陆微博有问题的同学，请移步我的[这篇文章](http://www.rookiefly.cn/detail/83)。下面进入正题。\n\n思路\n- 定时模拟登陆（定时是因为微博cookie**24小时**失效）,关于模拟登陆详细步骤可参考[我的博文](http://www.rookiefly.cn/detail/83)，代码可参考[github项目](https://github.com/ResolveWang/smart_login)\n- 定时(10分钟)获取最新一条微博，并把发布时间和系统时间做比较，如果相差在**半个小时**以内，我们就认为命令有效，那么就让系统执行关机命令\n\n项目依赖\n- 模拟登陆+页面解析：\n - requests+pyexecjs+beautifulsoup\n - pip install requests \n - pip install bs4 \n - pip install PyExecJS\n- 命令行解析**docopt**\n - pip install docopt \n- phantomjs \n - windows:在[phantomjs官网](http://phantomjs.org/)下载它，并且把它的路径**添加到环境变量**中 \n - ubuntu：*sudo apt-get install phantomjs* 或者到官网下载并且**添加到环境变量**中\n\n各个模块和代码\n\n**login.py** \n> 该模块代码负责模拟登陆，[之前](http://www.rookiefly.cn/detail/83)已经详细讲过这部分代码了，在这里就不啰嗦了，最后返回的是session和uid(微博ID,用于拼凑主页URL)\n\n** weibo_parser.py**\n> 解析微博主页，并且返回最新一条微博和发布时间\n\n具体代码如下\n<pre>\n def get_newest(session, uid):\n    \\# 获取只含有原创内容的个人主页\n    url = \'http://weibo.com/\' + uid + \'/profile?profile_ftype=1&is_ori=1#_0\'\n    page = session.get(url).text\n    soup = BeautifulSoup(page, \'html.parser\')\n    scripts = soup.find_all(\'script\')\n    status = \' \'\n    for s in scripts:\n        if \'pl.content.homeFeed.index\' in s.string:\n                status = s.string\n    \\# 用正则表达式获取微博原创内容\n    pattern = re.compile(r\'FM.view\\((.*)\\)\')\n    rs = pattern.search(status)\n    if rs:\n        cur_status = rs.group(1)\n        html = json.loads(cur_status).get(\'html\')\n        soup = BeautifulSoup(html, \'html.parser\')\n        \\# 获取最新一条微博所有信息\n        newest = soup.find(attrs={\'action-type\': \'feed_list_item\'})\n        \\# 获取最新发布内容\n        post_cont = newest.find(attrs={\'node-type\': \'feed_list_content\'}).text.strip()\n        \\# 获取最新发布时间\n        post_stamp = int(newest.find(attrs={\'node-type\': \'feed_list_item_date\'}).get(\'date\')[:-3])\n        post_time = datetime.fromtimestamp(post_stamp)\n        now = datetime.now()\n        \\# 计算此刻和发布时间的时间差(单位为秒)\n        t = (now - post_time).total_seconds()\n        return post_cont, t\n    else:\n        return None\n</pre>\n\n这里面用到的知识包括beautifulsoup和正则表达式，它们的具体使用我就不细说了，关于正则表达式，**search()**函数我是用得最多的，beautifulsoup我用得最多的是**find(attrs={key: value})**,**attrs**这个参数真心好用！这个是beautifulsoup的官方文档:[bs中文文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.html).关于页面解析，可能我会专门写一篇文章详细说，这里就略去了。\n\n**pc_shutdown.py**\n<pre>\n\"\"\"Resolvewang\n\nUsage:    \n    pc_shutdow.py name <name> password <password>    \n    pc_shutdow.py (-h | --help)    \n    pc_shutdow.py --version\n\nOptions:    \n    -h --help   Show this screen.    \n    --version   Show version\n\"\"\"\nfrom login import get_cur_session\nfrom weibo_parser import get_newest\nfrom docopt import docopt\nfrom os import system\nimport platform\nimport time\n\ndef shutdown(name, password):    \n    session, uid = get_cur_session(name, password)    \n    return get_newest(session, uid)\n\nif __name__ == \'__main__\':    \n    # 从命令行获取登陆账号和密码\n    args = docopt(__doc__, version=\'ShutdownMyPC 1.0\')    \n    login_name = args.get(\'<name>\')    \n    login_pass = args.get(\'<password>\')  \n    # 循环用于定时查看是否有新微博发布 \n    while True:      \n        # 获取发布内容和时间，内容用 \" \"隔开，比如“关机 10”  \n        cont, ptdelta = shutdown(login_name, login_pass)        \n        info = cont.split(\' \')\n        # 判断是关机命令还是正常微博      \n        if info[0] == \'关机\' and ptdelta < 30 * 60:            \n            shut_time = 0            \n            try:                \n                shut_time = int(info[1])            \n            except Exception:                \n                print(\'马上自动关机\')            \n            else:                \n                print(\'{time}分钟后自动关机\'.format(time=info[1]))            \n            finally:\n                # 判断操作系统平台，由于没有mac实验环境，所以这里没添加mac的相关判断                \n                os_system = platform.system().lower()                \n                if os_system == \'windows\':                    \n                    command = \'shutdown -s -t {shut_time}\'.format(shut_time=shut_time*60) \n                else:                    \n                    command = \'shutdown -h {shut_time}\'.format(shut_time=shut_time)\n                # 执行关机命令\n                system(command)        \n        time.sleep(10*60)\n</pre>\n\n这段代码的逻辑基本都写在注释里了，其中有个docopt模块，是关于命令行参数的，如果有不清楚的同学可以看看[这篇博客](https://wp-lai.gitbooks.io/learn-python/content/0MOOC/docopt.html)，也可以看看它的[github](https://github.com/docopt/docopt)，里面有很多例子\n\n---\n\n关于使用微博进行远程关机的讲解都完了，上述代码还有可以改进的地方，特别是*pc_shutdown.py*,比如\n\n- 使用定时器进行查看新微博\n- session复用直到24小时失效，这样就不用每隔十分钟就重新登陆一次了，可以通过多进程或者多线程共享变量实现\n- 可以把这个小工具修改成一个开机启动脚本(linux平台)或者服务(win平台)。\n\n吾生也有涯，而知也无涯。大家加油，共勉！',1,'python',1475820663,0,25,0,1,1),(104,'python的鸭子类型理解','&lt;p&gt;本文转自：<a href=\"https://www.zybuluo.com/kingwhite/note/143364\">Python鸭子类型</a>&lt;/p&gt;\n&lt;p&gt;鸭子类型（duck typing）&lt;/p&gt;\n&lt;p&gt;在程序设计中，鸭子类型是动态类型的一种风格。&lt;/p&gt;\n&lt;p&gt;在这种风格中，一个对象有效的语义， 不是由继承自特定的类或实现特定的接口，而是由当前方法和属性的集合决定。&lt;/p&gt;\n&lt;p&gt;这个概念的名字来源于由James Whitcomb Riley提出的鸭子测试，“鸭子测试”可以这样表述：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;当看到一只鸟走起来像鸭子、游泳像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。\n在鸭子类型中，关注的不是对象的类型本身，而是它是如何使用的。&lt;/p&gt;\n</blockquote>\n&lt;p&gt;例如，在不使用鸭子类型的语言中，我们可以编写一个函数，它接受一个类型为鸭子的对象，并调用它的走和叫的方法。在使用鸭子类型的语言中，这样的一个函数可以接受一个任意类型的对象，并调用它的走和叫方法。如果这些需要被调用的方法不存在，那么将会引发一个运行时错误。任何拥有这样的正确的走和叫方法的对象都可被函数接受的这种行为引出了以上表述，这种决定类型的方式因此得名。&lt;/p&gt;\n&lt;p&gt;<strong>鸭子类型通常得益于不测试方法和函数中参数的类型，而是依赖文档、清晰的代码和测试来确保正确使用。</strong>&lt;/p&gt;\n&lt;p&gt;从静态类型语言转向动态类型语言的用户通常试图添加一些<strong>静态的（在运行之前的）类型检查</strong>，从而影响了鸭子类型的益处和可伸缩性，并约束了语言的动态特性（Python文档中有一句：鸭子类型应避免使用type()或instance()等方法来测试类型是否合法）&lt;/p&gt;\n&lt;p&gt;看下面一段代码：\n&lt;pre&gt;\nclass Duck:\ndef quack(self):\n    print(\'呱呱呱！\')\ndef feathers(self):\n    print(\'这个鸭子拥有灰白的羽毛\')\nclass Person:\ndef quack(self):\n    print(\'我不是鸭子\')\ndef feathers(self):\n    print(\'这个人穿着一件鸭绒大衣\')\ndef in_the_forest(duck):\nduck.quack()\nduck.feathers()\ndef game():\ndonald = Duck()\njohn = Person()\nin_the_forest(donald)\nin_the_forest(john)\ngame()\n#返回：\n#呱呱呱！\n#这个鸭子拥有灰白的羽毛\n#我不是鸭子\n#这个人穿着一件鸭绒大衣\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;从哪里可以看出Python是鸭子类型的风格呢？&lt;/p&gt;\n&lt;p&gt;in_the_forest()函数对参数duck只有一个要求：就是可以实现quack()和feathers()方法。然而Duck类和Person类都实现了quack()和feathers()方法，因此它们的实例对象donald和john都可以用作in_the_forest()的参数。这就是鸭子类型。&lt;/p&gt;\n&lt;p&gt;我们可以看出，鸭子类型给予Python这样的动态语言以多态。但是这种多态的实现完全由程序员来约束强制实现（文档、清晰的代码和测试），并没有语言上的约束（如C++继承和虚函数）。因此这种方法既灵活，又提高了对程序员的要求。&lt;/p&gt;\n&lt;p&gt;在Python中，鸭子类型的最典型例子就是类似file的类。这些类可以实现file的一些或全部方法，并可以用于file通常使用的地方。例如，GzipFile实现了一个用于访问gzip压缩的数据的类似file的对象。cStringIO允许把一个Python字符串视作一个文件。套接字（socket）也和文件共同拥有许多相同的方法。然而套接字缺少tell()方法，不能用于GzipFile可以使用的所有地方。这体现了鸭子类型的可伸缩性：一个类似file的对象可以实现它有能力实现的方法，且只能被用于它有意义的情形下。&lt;/p&gt;','本文转自：[Python鸭子类型](https://www.zybuluo.com/kingwhite/note/143364)\n\n鸭子类型（duck typing）\n\n在程序设计中，鸭子类型是动态类型的一种风格。\n\n在这种风格中，一个对象有效的语义， 不是由继承自特定的类或实现特定的接口，而是由当前方法和属性的集合决定。\n\n这个概念的名字来源于由James Whitcomb Riley提出的鸭子测试，“鸭子测试”可以这样表述：\n\n>当看到一只鸟走起来像鸭子、游泳像鸭子、叫起来也像鸭子，那么这只鸟就可以被称为鸭子。\n在鸭子类型中，关注的不是对象的类型本身，而是它是如何使用的。\n\n例如，在不使用鸭子类型的语言中，我们可以编写一个函数，它接受一个类型为鸭子的对象，并调用它的走和叫的方法。在使用鸭子类型的语言中，这样的一个函数可以接受一个任意类型的对象，并调用它的走和叫方法。如果这些需要被调用的方法不存在，那么将会引发一个运行时错误。任何拥有这样的正确的走和叫方法的对象都可被函数接受的这种行为引出了以上表述，这种决定类型的方式因此得名。\n\n**鸭子类型通常得益于不测试方法和函数中参数的类型，而是依赖文档、清晰的代码和测试来确保正确使用。**\n\n从静态类型语言转向动态类型语言的用户通常试图添加一些**静态的（在运行之前的）类型检查**，从而影响了鸭子类型的益处和可伸缩性，并约束了语言的动态特性（Python文档中有一句：鸭子类型应避免使用type()或instance()等方法来测试类型是否合法）\n\n看下面一段代码：\n<pre>\nclass Duck:\ndef quack(self):\n    print(\'呱呱呱！\')\ndef feathers(self):\n    print(\'这个鸭子拥有灰白的羽毛\')\nclass Person:\ndef quack(self):\n    print(\'我不是鸭子\')\ndef feathers(self):\n    print(\'这个人穿着一件鸭绒大衣\')\ndef in_the_forest(duck):\nduck.quack()\nduck.feathers()\ndef game():\ndonald = Duck()\njohn = Person()\nin_the_forest(donald)\nin_the_forest(john)\ngame()\n\\#返回：\n\\#呱呱呱！\n\\#这个鸭子拥有灰白的羽毛\n\\#我不是鸭子\n\\#这个人穿着一件鸭绒大衣\n</pre>\n\n从哪里可以看出Python是鸭子类型的风格呢？\n\nin_the_forest()函数对参数duck只有一个要求：就是可以实现quack()和feathers()方法。然而Duck类和Person类都实现了quack()和feathers()方法，因此它们的实例对象donald和john都可以用作in_the_forest()的参数。这就是鸭子类型。\n\n我们可以看出，鸭子类型给予Python这样的动态语言以多态。但是这种多态的实现完全由程序员来约束强制实现（文档、清晰的代码和测试），并没有语言上的约束（如C++继承和虚函数）。因此这种方法既灵活，又提高了对程序员的要求。\n\n在Python中，鸭子类型的最典型例子就是类似file的类。这些类可以实现file的一些或全部方法，并可以用于file通常使用的地方。例如，GzipFile实现了一个用于访问gzip压缩的数据的类似file的对象。cStringIO允许把一个Python字符串视作一个文件。套接字（socket）也和文件共同拥有许多相同的方法。然而套接字缺少tell()方法，不能用于GzipFile可以使用的所有地方。这体现了鸭子类型的可伸缩性：一个类似file的对象可以实现它有能力实现的方法，且只能被用于它有意义的情形下。',1,'python',1475892850,0,28,0,1,1),(105,'一天两道Python面试题:语言特性(一)','&lt;p&gt;问题一&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Python中是以什么方式传递参数的，值传递还是引用传递？&lt;/p&gt;\n</blockquote>\n&lt;p&gt;解答：Python中既不是通过值也不是通过引用传递参数，而是<strong>通过对象传递</strong>，或者说是通过对象的引用来进行传递参数。在理解这一点之前，我们需要知道<strong>在Python中，一切皆对象，而对象分两种，可变对象和不可变对象</strong>。其中Number(包括int、float、bool、complex)、String、Tuple属于不可变对象，List、Set和Dict属于可变对象。对于不可变对象，传递参数表现出来的形式就和值传递类似，而对于可变对象，传递参数表现出来的形式就和引用传递类似。举个例子说明吧：\n&lt;pre&gt;\na = 1\ndef change_bukebian(arg):\n    arg += 1\n    print(id(arg))&lt;/p&gt;\n&lt;p&gt;change_bukebian(a)\nprint(id(a))\nprint(a)&lt;/p&gt;\n&lt;p&gt;b = [1]\ndef change_kebian(args):\n    args.append(5)\n    print(id(args))&lt;/p&gt;\n&lt;p&gt;change_kebian(b)\nprint(id(b))\nprint(b)\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;结果&lt;/p&gt;\n<blockquote>\n&lt;p&gt;1980432880&lt;/p&gt;\n&lt;p&gt;1980432848&lt;/p&gt;\n&lt;p&gt;1&lt;/p&gt;\n&lt;p&gt;1293869229256&lt;/p&gt;\n&lt;p&gt;1293869229256&lt;/p&gt;\n&lt;p&gt;[1, 5]&lt;/p&gt;\n</blockquote>\n&lt;p&gt;从上面代码结合运行结果可以看到，当我们将不可变对象(a)传入函数时，运行函数后它的值仍然没有改变，只是在函数运行的时候会生成一个新的对象(由前后两者的地址可以看出来)，而当我们将可变对象(b)传入函数时，运行函数后它的结果发生了改变，并且在函数中也是引用的同一个地址。&lt;/p&gt;\n&lt;hr/&gt;\n&lt;p&gt;问题二&lt;/p&gt;\n<blockquote>\n&lt;p&gt;__getattr__、__getattribute__、__setattr__区别和陷阱&lt;/p&gt;\n</blockquote>\n&lt;p&gt;首先，谈谈__getattr__和__getattribute__的区别：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;__getattr__会在访问对象属性，而对象属性不存在的情况下调用&lt;/p&gt;\n&lt;p&gt;__getattribute__  Python3的无论对象属性是否存在，在访问对象属性的时候，都会被调用。&lt;/p&gt;\n&lt;p&gt;如果__getattr__和__getattibute__同时存在于类中，当对象属性不存在且未用catch捕获AttributeEror的时候，会触发__getattr__函数，如果__getattr__也没处理，那么将会抛出异常&lt;/p&gt;\n</blockquote>\n&lt;p&gt;代码\n&lt;pre&gt;\nclass TestAttr(object):\n    def __init__(self, name):\n        self.name = name\n    def __getattribute__(self, item):\n        try:\n            return super(TestAttr, self).<strong>getattribute</strong>(item)\n        except AttributeError:\n            return \'attribute{not_exised} is missing\'.format(not_exised=item)\n    def __getattr__(self, item):\n        return \'default\'&lt;/p&gt;\n&lt;p&gt;at = TestAttr(\'test\')\nprint(at.name)\nprint(at.not_exised)\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;结果&lt;/p&gt;\n<blockquote>\n&lt;p&gt;test&lt;/p&gt;\n&lt;p&gt;attributenot_exised is missing&lt;/p&gt;\n</blockquote>\n&lt;p&gt;说明了对于或者不存在的属性，都会调用__getattribute__,并且对于不存在的属性，如果捕捉了异常(AttributError),那么就不会触发_\\_getattr__&lt;/p&gt;\n&lt;p&gt;修改上述代码，删除try...except...代码段，直接返回<em>super(TestAttr, self).__getattribute__(item)</em>&lt;/p&gt;\n&lt;p&gt;结果&lt;/p&gt;\n<blockquote>\n&lt;p&gt;test&lt;/p&gt;\n&lt;p&gt;default&lt;/p&gt;\n</blockquote>\n&lt;p&gt;说明了自动调用了__getattr__函数&lt;/p&gt;\n&lt;p&gt;然后，再删除__getattr__函数，看看发生什么&lt;/p&gt;\n&lt;p&gt;结果&lt;/p&gt;\n<blockquote>\n&lt;p&gt;test\nAttributeError: \'TestAttr\' object has no attribute \'not_exised\' ....&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这次程序运行出了错误。&lt;/p&gt;\n&lt;p&gt;上述代码基本证实了前面说的三条规则&lt;/p&gt;\n&lt;p&gt;下面说说存在的陷阱\n可能有同学注意到了，我前面用的是<strong>super(TestAttr, self).__getattribute__(item)</strong>，而不是直接返回的<em>self.item</em>, 我们修改代码，看看改为<em>self.item</em>,会出现什么问题&lt;/p&gt;\n&lt;p&gt;结果&lt;/p&gt;\n<blockquote>\n&lt;p&gt;RecursionError: maximum recursion depth exceeded while calling a Python object&lt;/p&gt;\n</blockquote>\n&lt;p&gt;直接无限递归了。原因？在调用self.item的时候，self.item是TestAttr的属性，自然又会进行调用__getattribute__这个方法，那么又会调用self.item, 如此往复，自然会无限递归到超出内存。解决方法就是前面用的使用父类来调用该方法。而如果父类没有属性，且__getattr__没有进行处理，那么就会发生AttributeError,需要我们进行捕获。__setattr__同理，也可能发生无限递归的错误，需要我们注意。&lt;/p&gt;\n&lt;hr/&gt;\n&lt;p&gt;发现这些问题要了解清楚，会涉及到很多别的知识，比如参数传递中还可以类比浅拷贝(有一些不同)，getattribute中的super()，都是很有意思的知识点，我弄清楚了也会做一些总结，但是不会放到面试题总结中。&lt;/p&gt;','问题一\n>Python中是以什么方式传递参数的，值传递还是引用传递？\n\n解答：Python中既不是通过值也不是通过引用传递参数，而是**通过对象传递**，或者说是通过对象的引用来进行传递参数。在理解这一点之前，我们需要知道**在Python中，一切皆对象，而对象分两种，可变对象和不可变对象**。其中Number(包括int、float、bool、complex)、String、Tuple属于不可变对象，List、Set和Dict属于可变对象。对于不可变对象，传递参数表现出来的形式就和值传递类似，而对于可变对象，传递参数表现出来的形式就和引用传递类似。举个例子说明吧：\n<pre>\na = 1\ndef change_bukebian(arg):\n	arg += 1\n	print(id(arg))\n\nchange_bukebian(a)\nprint(id(a))\nprint(a)\n\nb = [1]\ndef change_kebian(args):\n	args.append(5)\n	print(id(args))\n\nchange_kebian(b)\nprint(id(b))\nprint(b)\n</pre>\n\n结果\n> 1980432880\n\n> 1980432848\n\n> 1\n\n> 1293869229256\n\n> 1293869229256\n\n> [1, 5]\n\n从上面代码结合运行结果可以看到，当我们将不可变对象(a)传入函数时，运行函数后它的值仍然没有改变，只是在函数运行的时候会生成一个新的对象(由前后两者的地址可以看出来)，而当我们将可变对象(b)传入函数时，运行函数后它的结果发生了改变，并且在函数中也是引用的同一个地址。\n\n---\n\n问题二\n> \\_\\_getattr\\_\\_、\\_\\_getattribute\\_\\_、\\_\\_setattr\\_\\_区别和陷阱\n\n首先，谈谈\\_\\_getattr\\_\\_和\\_\\_getattribute\\_\\_的区别：\n> \\_\\_getattr\\_\\_会在访问对象属性，而对象属性不存在的情况下调用\n\n>\\_\\_getattribute\\_\\_  Python3的无论对象属性是否存在，在访问对象属性的时候，都会被调用。\n\n> 如果\\_\\_getattr\\_\\_和\\_\\_getattibute\\_\\_同时存在于类中，当对象属性不存在且未用catch捕获AttributeEror的时候，会触发\\_\\_getattr\\_\\_函数，如果\\_\\_getattr\\_\\_也没处理，那么将会抛出异常\n\n代码\n<pre>\nclass TestAttr(object):\n    def \\_\\_init\\_\\_(self, name):\n        self.name = name\n    def \\_\\_getattribute\\_\\_(self, item):\n        try:\n            return super(TestAttr, self).__getattribute__(item)\n        except AttributeError:\n            return \'attribute{not_exised} is missing\'.format(not_exised=item)\n    def \\_\\_getattr\\_\\_(self, item):\n        return \'default\'\n\nat = TestAttr(\'test\')\nprint(at.name)\nprint(at.not_exised)\n</pre>\n\n结果\n> test\n\n> attributenot_exised is missing\n\n说明了对于或者不存在的属性，都会调用\\_\\_getattribute\\_\\_,并且对于不存在的属性，如果捕捉了异常(AttributError),那么就不会触发_\\\\_getattr\\_\\_\n\n修改上述代码，删除try...except...代码段，直接返回*super(TestAttr, self).\\_\\_getattribute\\_\\_(item)*\n\n结果\n> test\n\n> default\n\n说明了自动调用了\\_\\_getattr\\_\\_函数\n\n然后，再删除\\_\\_getattr\\_\\_函数，看看发生什么\n\n结果\n>test\n> AttributeError: \'TestAttr\' object has no attribute \'not_exised\' ....\n\n这次程序运行出了错误。\n\n上述代码基本证实了前面说的三条规则\n\n下面说说存在的陷阱\n可能有同学注意到了，我前面用的是**super(TestAttr, self).\\_\\_getattribute\\_\\_(item)**，而不是直接返回的*self.item*, 我们修改代码，看看改为*self.item*,会出现什么问题\n\n结果\n> RecursionError: maximum recursion depth exceeded while calling a Python object\n\n直接无限递归了。原因？在调用self.item的时候，self.item是TestAttr的属性，自然又会进行调用\\_\\_getattribute\\_\\_这个方法，那么又会调用self.item, 如此往复，自然会无限递归到超出内存。解决方法就是前面用的使用父类来调用该方法。而如果父类没有属性，且\\_\\_getattr\\_\\_没有进行处理，那么就会发生AttributeError,需要我们进行捕获。\\_\\_setattr\\_\\_同理，也可能发生无限递归的错误，需要我们注意。\n\n---\n发现这些问题要了解清楚，会涉及到很多别的知识，比如参数传递中还可以类比浅拷贝(有一些不同)，getattribute中的super()，都是很有意思的知识点，我弄清楚了也会做一些总结，但是不会放到面试题总结中。\n',1,'python,面试题',1475983654,0,29,0,1,1),(106,'python中的浅拷贝和深拷贝(转)','&lt;p&gt;前一篇文章讲了Python的参数传递机制，由于和浅拷贝有几分相似，然而对于浅拷贝和深拷贝这个知识点我一直都是一知半解，今天静下来看看它的相关知识。发现了一篇很简短但是让人很明白的文章。&lt;/p&gt;\n&lt;p&gt;文章出处：<a href=\"http://www.cnblogs.com/coderzh/archive/2008/05/17/1201506.html\">CoderZh</a>&lt;/p&gt;\n&lt;p&gt;Python中的对象之间赋值时是按引用传递的，如果需要拷贝对象，需要使用标准库中的copy模块。&lt;/p&gt;\n<ol>\n<li>copy.copy 浅拷贝 只拷贝父对象，不会拷贝对象的内部的子对象。</li>\n<li>copy.deepcopy 深拷贝 拷贝对象及其子对象</li>\n</ol>\n&lt;p&gt;一个很好的例子：\n&lt;pre&gt;\nimport copy\na = [1, 2, 3, 4, [\'a\', \'b\']]  #原始对象&lt;/p&gt;\n&lt;p&gt;b = a  #赋值，传对象的引用\nc = copy.copy(a)  #对象拷贝，浅拷贝\nd = copy.deepcopy(a)  #对象拷贝，深拷贝&lt;/p&gt;\n&lt;p&gt;a.append(5)  #修改对象a\na[4].append(\'c\')  #修改对象a中的[\'a\', \'b\']数组对象&lt;/p&gt;\n&lt;p&gt;print(\'a = \', a)\nprint(\'b = \', b)\nprint(\'c = \', c)\nprint(\'d = \', d)\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;输出结果：&lt;/p&gt;\n&lt;p&gt;a =  [1, 2, 3, 4, [\'a\', \'b\', \'c\'], 5]&lt;/p&gt;\n&lt;p&gt;b =  [1, 2, 3, 4, [\'a\', \'b\', \'c\'], 5]&lt;/p&gt;\n&lt;p&gt;c =  [1, 2, 3, 4, [\'a\', \'b\', \'c\']]&lt;/p&gt;\n&lt;p&gt;d =  [1, 2, 3, 4, [\'a\', \'b\']]&lt;/p&gt;\n&lt;p&gt;另外一段话或许更好理解&lt;/p&gt;\n<blockquote>\n&lt;p&gt;以列表为例，如果浅拷贝，那么系统就新建一个列表，它的每个元素都指向原来列表的每个元素（就像C语言里的指针数组），输出的时候就把它各元素指向的母体元素内容显示出来，所以列表a追加了数字\"5\"以后列表c并没有显示，因为列表c中并没有指向这个新元素的元素。但是追加了字母\"c\"以后显示出来了，因为字母\"c\"属于列表a的第五个元素的一部分，在列表c有对应的指向，所以就显示出来了。而对于深拷贝来说没有任何改变，因为深拷贝是新建一个列表，把原列表的内容原封不动拷过来，拷过来以后它和原列表一模一样，至于原列表后来做了什么改变根本不关它的事。形象理解就是浅拷贝是活的，深拷贝是死的。&lt;/p&gt;\n</blockquote>','前一篇文章讲了Python的参数传递机制，由于和浅拷贝有几分相似，然而对于浅拷贝和深拷贝这个知识点我一直都是一知半解，今天静下来看看它的相关知识。发现了一篇很简短但是让人很明白的文章。\n\n文章出处：[CoderZh](http://www.cnblogs.com/coderzh/archive/2008/05/17/1201506.html)\n\nPython中的对象之间赋值时是按引用传递的，如果需要拷贝对象，需要使用标准库中的copy模块。\n\n1. copy.copy 浅拷贝 只拷贝父对象，不会拷贝对象的内部的子对象。\n2. copy.deepcopy 深拷贝 拷贝对象及其子对象\n\n一个很好的例子：\n<pre>\nimport copy\na = [1, 2, 3, 4, [\'a\', \'b\']]  #原始对象\n\nb = a  #赋值，传对象的引用\nc = copy.copy(a)  #对象拷贝，浅拷贝\nd = copy.deepcopy(a)  #对象拷贝，深拷贝\n\na.append(5)  #修改对象a\na[4].append(\'c\')  #修改对象a中的[\'a\', \'b\']数组对象\n\nprint(\'a = \', a)\nprint(\'b = \', b)\nprint(\'c = \', c)\nprint(\'d = \', d)\n</pre>\n\n输出结果：\n\na =  [1, 2, 3, 4, [\'a\', \'b\', \'c\'], 5]\n\nb =  [1, 2, 3, 4, [\'a\', \'b\', \'c\'], 5]\n\nc =  [1, 2, 3, 4, [\'a\', \'b\', \'c\']]\n\nd =  [1, 2, 3, 4, [\'a\', \'b\']]\n\n另外一段话或许更好理解\n> 以列表为例，如果浅拷贝，那么系统就新建一个列表，它的每个元素都指向原来列表的每个元素（就像C语言里的指针数组），输出的时候就把它各元素指向的母体元素内容显示出来，所以列表a追加了数字\"5\"以后列表c并没有显示，因为列表c中并没有指向这个新元素的元素。但是追加了字母\"c\"以后显示出来了，因为字母\"c\"属于列表a的第五个元素的一部分，在列表c有对应的指向，所以就显示出来了。而对于深拷贝来说没有任何改变，因为深拷贝是新建一个列表，把原列表的内容原封不动拷过来，拷过来以后它和原列表一模一样，至于原列表后来做了什么改变根本不关它的事。形象理解就是浅拷贝是活的，深拷贝是死的。',1,'python',1475991808,0,28,0,1,1),(107,'Python中的Super关键字(转)','&lt;p&gt;同样是在思考python的面试题时想到的，关于super()的用法，既然接触了，为什么不把它弄清楚呢？&lt;/p&gt;\n&lt;p&gt;有一篇文章对此讲解得很清楚了，我把它转载过来，并适当做些补充和修改：<a href=\"https://laike9m.com/blog/li-jie-python-super,70/\">原文</a>&lt;/p&gt;\n&lt;p&gt;重要的事情说三遍&lt;/p&gt;\n&lt;p&gt;<strong>不要一说到 super 就想到父类！super 指的是 MRO 中的下一个类!</strong>&lt;/p&gt;\n&lt;p&gt;<strong>不要一说到 super 就想到父类！super 指的是 MRO 中的下一个类!</strong>&lt;/p&gt;\n&lt;p&gt;<strong>不要一说到 super 就想到父类！super 指的是 MRO 中的下一个类!</strong>&lt;/p&gt;\n&lt;p&gt;一说到 super 就想到父类这是初学者很容易犯的一个错误，也是我当年犯的错误(因为这和别的语言中super的用法有区别)。 忘记了这件事之后，再去看这篇文章：<a href=\"https://rhettinger.wordpress.com/2011/05/26/super-considered-super/\">Python’s super() considered super</a>! 这是 Raymond Hettinger 写的一篇文章，也是全世界公认的对 super 讲解最透彻的一篇文章，凡是讨论 super 都一定会提到它（当然还有一篇 Python\'s Super Considered Harmful）。&lt;/p&gt;\n&lt;p&gt;如果不想看长篇大论就去看<a href=\"http://stackoverflow.com/questions/15896265/python-super-inheritance-and-needed-arguments/15896594#15896594\">这个答案</a>，super 其实干的是这件事：\n&lt;pre&gt;\ndef super(cls, inst):\n    mro = inst.__class__.mro() # Always the most derived class\n    return mro[mro.index(cls) + 1]\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;两个参数 cls 和 inst 分别做了两件事：&lt;/p&gt;\n<ol>\n<li>inst 负责生成 MRO 的 list</li>\n<li>通过 cls 定位当前 MRO 中的 index, 并返回 mro[index + 1]</li>\n</ol>\n&lt;p&gt;这两件事才是 super 的实质，一定要记住！\nMRO 全称 Method Resolution Order，它代表了类继承的顺序。后面详细说。&lt;/p&gt;\n&lt;p&gt;举个例子\n&lt;pre&gt;\nclass Root(object):\n    def __init__(self):\n        print(\"this is Root\")&lt;/p&gt;\n&lt;p&gt;class B(Root):\n    def __init__(self):\n        print(\"enter B\")\n        # print(self)  # this will print &lt;<strong>main</strong>.D object at 0x...&gt;\n        super(B, self).__init__()\n        print(\"leave B\")&lt;/p&gt;\n&lt;p&gt;class C(Root):\n    def __init__(self):\n        print(\"enter C\")\n        super(C, self).__init__()\n        print(\"leave C\")&lt;/p&gt;\n&lt;p&gt;class D(B, C):\n    pass&lt;/p&gt;\n&lt;p&gt;d = D()\nprint(d.__class__.__mro__)&lt;/p&gt;\n&lt;/pre&gt;\n\n&lt;p&gt;输出\n&lt;pre&gt;\nenter B\nenter C\nthis is Root\nleave C\nleave B\n(&lt;class \'__main__.d\'=\"\"&gt;, &lt;class \'__main__.b\'=\"\"&gt;, &lt;class \'__main__.c\'=\"\"&gt;, &lt;class \'__main__.root\'=\"\"&gt;, &lt;type \'object\'=\"\"&gt;)\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;知道了 super 和父类其实没有实质关联之后，我们就不难理解为什么 enter B 下一句是 enter C 而不是 this is Root（如果认为 super 代表“调用父类的方法”，会想当然的认为下一句应该是this is Root）。流程如下，在 B 的 __init__ 函数中：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;super(B, self).__init__()&lt;/p&gt;\n</blockquote>\n&lt;p&gt;首先，我们获取 self.__class__.__mr__，注意这里的 self 是 D 的 instance 而不是 B 的&lt;/p&gt;\n<blockquote>\n&lt;p&gt;\'<strong>main</strong>.D\'-&gt;\'<strong>main</strong>.B\'-&gt;\'<strong>main</strong>.C\'-&gt;\'<strong>main</strong>.Root\'-&gt;\'object\'&lt;/p&gt;\n</blockquote>\n&lt;p&gt;然后，通过 B 来定位 MRO 中的 index，并找到下一个。显然 B 的下一个是 C。于是，我们调用 C 的 __init__，打出 enter C。&lt;/p&gt;\n&lt;p&gt;顺便说一句为什么 B 的 __init__ 会被调用：因为 D 没有定义 __init__，所以会在 MRO 中找下一个类，去查看它有没有定义 __init__，也就是去调用 B 的 __init__。&lt;/p&gt;\n&lt;p&gt;其实这一切逻辑还是很清晰的，关键是理解 super 到底做了什么。&lt;/p&gt;\n&lt;p&gt;于是，MRO 中类的顺序到底是怎么排的呢？<strong>Python’s super() considered super</strong>!中已经有很好的解释，我翻译一下：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;在 MRO 中，基类永远出现在派生类后面，如果有多个基类，基类的相对顺序保持不变。&lt;/p&gt;\n</blockquote>\n&lt;hr/&gt;\n&lt;p&gt;以上就是原文，仔细读完基本都了解了&lt;/p&gt;\n&lt;p&gt;我个人以为之所以Python的super和Java等语言的super不同，很大一个原因是Python是<strong>多继承</strong>语言，而java是<strong>单继承</strong>语言，如果super是调用父类的方法的话，那么多个父类，怎么确定一个调用标准？到底调用哪个父类，所以就有了<strong>MRO</strong>查找规则。在PythonCookBook中有这么一段话描述MRO的C3算法：\n- 先检查子类再检查父类\n- 有多个父类时，按照MRO列表的顺序(同一个层级从左到右，如果有公共父类，那么公共父类将会在最右边的子类查找时排序)依次查找\n- 如果下一个待选的类出现了两个合法的选择，那么就从第一个父类中选取&lt;/p&gt;\n&lt;p&gt;考虑下面一段代码\n&lt;pre&gt;\nclass D(object):\n    pass&lt;/p&gt;\n&lt;p&gt;class E(object):\n    pass&lt;/p&gt;\n&lt;p&gt;class F(object):\n    pass&lt;/p&gt;\n&lt;p&gt;class C(D, F):\n    pass&lt;/p&gt;\n&lt;p&gt;class B(E, D):\n    pass&lt;/p&gt;\n&lt;p&gt;class A(B, C):\n    pass&lt;/p&gt;\n&lt;p&gt;if __name__ == \'__main__\':\n    print(A.__mro__)\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;继承关系如下图：\n&lt;div&gt;\n&lt;img src=\"http://o948iqcf0.bkt.clouddn.com/mro.jpg\" width=\"380px;\"&gt;\n&lt;/div&gt;&lt;/p&gt;\n&lt;p&gt;根据上面说的规则，它会先找到A,然后在B、C中继续查找，B在C的左边，所以B先会被查找到，然后B继承于E,D,E和C没有关系，所以E会被查找到，而D是B、C的公共父类，需要在C被搜索到过后再排序，而D位于F左边，所以会先被查找到，所以顺序应该是&lt;/p&gt;\n<blockquote>\n&lt;p&gt;A-&gt;B-&gt;E-&gt;C-&gt;D-&gt;F-&gt;object&lt;/p&gt;\n</blockquote>\n&lt;p&gt;我们运行代码，结果如下：&lt;/p&gt;\n&lt;p&gt;\'__main__.A\' -&gt; \'__main__.B\' -&gt;\'__main__.E\'-&gt; \'__main__.C\' -&gt; \'<em>_main</em>_.D\' -&gt; \'<em>_main</em>_.F\'-&gt;\'object\'&lt;/p&gt;\n&lt;p&gt;结果和我们预想的一样，如果修改一下，C只继承于F呢，那么MRO顺序如何？&lt;/p&gt;\n&lt;p&gt;运行结果如下&lt;/p&gt;\n&lt;p&gt;\'__main__.A\' -&gt; \'__main__.B\' -&gt;\'__main__.E\'-&gt; \'__main__.D\' -&gt; \'<em>_main</em>_.C\' -&gt; \'<em>_main</em>_.F\'-&gt;\'object\'&lt;/p&gt;','同样是在思考python的面试题时想到的，关于super()的用法，既然接触了，为什么不把它弄清楚呢？\n\n有一篇文章对此讲解得很清楚了，我把它转载过来，并适当做些补充和修改：[原文](https://laike9m.com/blog/li-jie-python-super,70/)\n\n重要的事情说三遍\n\n**不要一说到 super 就想到父类！super 指的是 MRO 中的下一个类!**\n\n**不要一说到 super 就想到父类！super 指的是 MRO 中的下一个类!**\n\n**不要一说到 super 就想到父类！super 指的是 MRO 中的下一个类!**\n\n一说到 super 就想到父类这是初学者很容易犯的一个错误，也是我当年犯的错误(因为这和别的语言中super的用法有区别)。 忘记了这件事之后，再去看这篇文章：[Python’s super() considered super](https://rhettinger.wordpress.com/2011/05/26/super-considered-super/)! 这是 Raymond Hettinger 写的一篇文章，也是全世界公认的对 super 讲解最透彻的一篇文章，凡是讨论 super 都一定会提到它（当然还有一篇 Python\'s Super Considered Harmful）。\n\n如果不想看长篇大论就去看[这个答案](http://stackoverflow.com/questions/15896265/python-super-inheritance-and-needed-arguments/15896594#15896594)，super 其实干的是这件事：\n<pre>\ndef super(cls, inst):\n    mro = inst.\\_\\_class\\_\\_.mro() # Always the most derived class\n    return mro[mro.index(cls) + 1]\n</pre>\n\n两个参数 cls 和 inst 分别做了两件事：\n\n1. inst 负责生成 MRO 的 list\n2. 通过 cls 定位当前 MRO 中的 index, 并返回 mro[index + 1]\n\n这两件事才是 super 的实质，一定要记住！\nMRO 全称 Method Resolution Order，它代表了类继承的顺序。后面详细说。\n\n举个例子\n<pre>\nclass Root(object):\n    def \\_\\_init\\_\\_(self):\n        print(\"this is Root\")\n\nclass B(Root):\n    def \\_\\_init\\_\\_(self):\n        print(\"enter B\")\n        # print(self)  \\# this will print <__main__.D object at 0x...>\n        super(B, self).\\_\\_init\\_\\_()\n        print(\"leave B\")\n\nclass C(Root):\n    def \\_\\_init\\_\\_(self):\n        print(\"enter C\")\n        super(C, self).\\_\\_init\\_\\_()\n        print(\"leave C\")\n\nclass D(B, C):\n    pass\n\nd = D()\nprint(d.\\_\\_class\\_\\_.\\_\\_mro\\_\\_)\n\n</pre>\n\n输出\n<pre>\nenter B\nenter C\nthis is Root\nleave C\nleave B\n(<class \'__main__.D\'>, <class \'__main__.B\'>, <class \'__main__.C\'>, <class \'__main__.Root\'>, <type \'object\'>)\n</pre>\n\n知道了 super 和父类其实没有实质关联之后，我们就不难理解为什么 enter B 下一句是 enter C 而不是 this is Root（如果认为 super 代表“调用父类的方法”，会想当然的认为下一句应该是this is Root）。流程如下，在 B 的 \\_\\_init\\_\\_ 函数中：\n> super(B, self).\\_\\_init\\_\\_()\n\n首先，我们获取 self.\\_\\_class\\_\\_.\\_\\_mr\\_\\_，注意这里的 self 是 D 的 instance 而不是 B 的\n\n> \'__main__.D\'->\'__main__.B\'->\'__main__.C\'->\'__main__.Root\'->\'object\'\n\n然后，通过 B 来定位 MRO 中的 index，并找到下一个。显然 B 的下一个是 C。于是，我们调用 C 的 \\_\\_init\\_\\_，打出 enter C。\n\n顺便说一句为什么 B 的 \\_\\_init\\_\\_ 会被调用：因为 D 没有定义 \\_\\_init\\_\\_，所以会在 MRO 中找下一个类，去查看它有没有定义 \\_\\_init\\_\\_，也就是去调用 B 的 \\_\\_init\\_\\_。\n\n其实这一切逻辑还是很清晰的，关键是理解 super 到底做了什么。\n\n于是，MRO 中类的顺序到底是怎么排的呢？**Python’s super() considered super**!中已经有很好的解释，我翻译一下：\n> 在 MRO 中，基类永远出现在派生类后面，如果有多个基类，基类的相对顺序保持不变。\n\n---\n以上就是原文，仔细读完基本都了解了\n\n我个人以为之所以Python的super和Java等语言的super不同，很大一个原因是Python是**多继承**语言，而java是**单继承**语言，如果super是调用父类的方法的话，那么多个父类，怎么确定一个调用标准？到底调用哪个父类，所以就有了**MRO**查找规则。在PythonCookBook中有这么一段话描述MRO的C3算法：\n- 先检查子类再检查父类\n- 有多个父类时，按照MRO列表的顺序(同一个层级从左到右，如果有公共父类，那么公共父类将会在最右边的子类查找时排序)依次查找\n- 如果下一个待选的类出现了两个合法的选择，那么就从第一个父类中选取\n\n考虑下面一段代码\n<pre>\nclass D(object):\n    pass\n\nclass E(object):\n    pass\n\nclass F(object):\n    pass\n\nclass C(D, F):\n    pass\n\nclass B(E, D):\n    pass\n\nclass A(B, C):\n    pass\n\nif \\_\\_name\\_\\_ == \'\\_\\_main\\_\\_\':\n    print(A.\\_\\_mro\\_\\_)\n</pre>\n\n继承关系如下图：\n<div>\n<img src=\'http://o948iqcf0.bkt.clouddn.com/mro.jpg\' width=\'380px;\'>\n</div>\n\n根据上面说的规则，它会先找到A,然后在B、C中继续查找，B在C的左边，所以B先会被查找到，然后B继承于E,D,E和C没有关系，所以E会被查找到，而D是B、C的公共父类，需要在C被搜索到过后再排序，而D位于F左边，所以会先被查找到，所以顺序应该是\n> A->B->E->C->D->F->object\n\n我们运行代码，结果如下：\n\n\'\\_\\_main\\_\\_.A\' -> \'\\_\\_main\\_\\_.B\' ->\'\\_\\_main\\_\\_.E\'-> \'\\_\\_main\\_\\_.C\' -> \'_\\_main_\\_.D\' -> \'_\\_main_\\_.F\'->\'object\'\n\n结果和我们预想的一样，如果修改一下，C只继承于F呢，那么MRO顺序如何？\n\n运行结果如下\n\n\'\\_\\_main\\_\\_.A\' -> \'\\_\\_main\\_\\_.B\' ->\'\\_\\_main\\_\\_.E\'-> \'\\_\\_main\\_\\_.D\' -> \'_\\_main_\\_.C\' -> \'_\\_main_\\_.F\'->\'object\'\n',1,'python',1475999191,0,31,0,1,1),(108,'编译型和解释型语言、静态和动态语言、强类型和若类型语言区别','<p>最近，在重新学习Java,适应Python过后看Java又是另一番风景。在思考为什么静态语言需要声明变量类型，比如</p>\n<blockquote>\n<p>String ts = \"test\"</p>\n</blockquote>\n<p>而对于Python等动态语言，却又是这样声明</p>\n<blockquote>\n<p>ts = \"test\"</p>\n</blockquote>\n<p>我想到一个问题：既然<em>ts</em>(变量名)表示一个地址，指向该变量的值，那么为什么还需要在使用它之前，还加一个类型进行声明呢？后来我又查阅了关于变量和内存的相关知识，又查了关于动态类型和静态类型语言的相关知识，看到有一篇文章写得不过，很全面又很简短，转载过来：</p>\n<p>以下内容转自：http://www.cnblogs.com/zy1987/p/3784753.html</p>\n<hr />\n<h3>编译型语言和解释型语言</h3>\n<h4>1、编译型语言</h4>\n<p>需通过编译器（compiler）将源代码编译成机器码，之后才能执行的语言。一般需经过编译（compile）、链接（linker）这两个步骤。编译是把源代码编译成机器码，链接是把各个模块的机器码和依赖库串连起来生成可执行文件。</p>\n<p>优点：编译器一般会有预编译的过程对代码进行优化。因为编译只做一次，运行时不需要编译，所以编译型语言的程序执行效率高。可以脱离语言环境独立运行。</p>\n<p>缺点：编译之后如果需要修改就需要整个模块重新编译。编译的时候根据对应的运行环境生成机器码，不同的操作系统之间移植就会有问题，需要根据运行的操作系统环境编译不同的可执行文件。</p>\n<p>代表语言：C、C++、Pascal、Object-C以及最近很火的苹果新语言swift</p>\n<h4>2、解释型语言</h4>\n<p>解释性语言的程序不需要编译，相比编译型语言省了道工序，解释性语言在运行程序的时候才逐行翻译。</p>\n<p>优点：有良好的平台兼容性，在任何环境中都可以运行，前提是安装了解释器（虚拟机）。灵活，修改代码的时候直接修改就可以，可以快速部署，不用停机维护。</p>\n<p>缺点：每次运行的时候都要解释一遍，性能上不如编译型语言。</p>\n<p>代表语言：JavaScript、Python、Erlang、PHP、Perl、Ruby</p>\n<h4>3、混合型语言</h4>\n<p>既然编译型和解释型各有缺点就会有人想到把两种类型整合起来，取其精华去其糟粕。就出现了半编译型语言。比如C#,C#在编译的时候不是直接编译成机器码而是中间码，.NET平台提供了中间语言运行库运行中间码，中间语言运行库类似于Java虚拟机。.net在编译成IL代码后，保存在dll中，首次运行时由JIT在编译成机器码缓存在内存中，下次直接执行（博友回复指出）。我个人认为抛开一切的偏见C#是这个星球上最好的编程语言。可惜微软的政策限制了C#的推广。</p>\n<p>Java先生成字节码再在Java虚拟机中解释执行。</p>\n<p>严格来说混合型语言属于解释型语言。C#更接近编译型语言。</p>\n<h3>动态语言和静态语言</h3>\n<h4>1、动态语言</h4>\n<p>是一类在运行时可以改变其结构的语言：例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化。通俗点说就是在运行时代码可以根据某些条件改变自身结构。</p>\n<p>主要动态语言：Object-C、C#、JavaScript、PHP、Python、Erlang。</p>\n<h4>2、静态语言</h4>\n<p>与动态语言相对应的，运行时结构不可变的语言就是静态语言。如Java、C、C++。</p>\n<h4>3、注意：</h4>\n<p>很多人认为解释型语言都是动态语言，这个观点是错的！Java是解释型语言但是不是动态语言，Java不能在运行的时候改变自己结构。反之成立吗？动态语言都是解释型语言。也是错的！Object-C是编译型语言，但是他是动态语言。得益于特有的run time机制（准确说run time不是语法特性是运行时环境，这里不展开）OC代码是可以在运行的时候插入、替换方法的。</p>\n<p>C#也是动态语言，通过C#的反射机制可以动态的插入一段代码执行。所以我说C#是这个星球最好的编程语言。</p>\n<h3>动态类型语言和静态类型语言</h3>\n<h4>1、动态类型语言</h4>\n<p>很多网上资料把动态类型语言和动态语言混为一谈，简直是误人子弟。动态类型语言和动态语言是完全不同的两个概念。动态类型语言是指在运行期间才去做数据类型检查的语言，说的是数据类型，动态语言说的是运行是改变结构，说的是代码结构。</p>\n<p>动态类型语言的数据类型不是在编译阶段决定的，而是把类型绑定延后到了运行阶段。</p>\n<p>主要语言：Python、Ruby、Erlang、JavaScript、swift、PHP、Perl。</p>\n<h4>2、静态类型语言</h4>\n<p>静态语言的数据类型是在编译其间确定的或者说运行之前确定的，编写代码的时候要明确确定变量的数据类型。</p>\n<p>主要语言：C、C++、C#、Java、Object-C。</p>\n<h4>3、注意：</h4>\n<p>相当一部分程序员，也包括曾经的我，认为解释型语言都是动态类型语言，编译型语言都是静态类型语言。这个也是错的。swift是编译型语言但是它也是动态类型语言。C#和Java是解释型语言也是静态类型语言。</p>\n<h3>强类型语言和弱类型语言</h3>\n<h4>1、强类型语言：</h4>\n<p>强类型语言，一旦一个变量被指定了某个数据类型，如果不经过强制类型转换，那么它就永远是这个数据类型。你不能把一个整形变量当成一个字符串来处理。</p>\n<p>主要语言：Java、C#、Python、Object-C、Ruby</p>\n<h4>2、弱类型语言：</h4>\n<p>数据类型可以被忽略，一个变量可以赋不同数据类型的值。一旦给一个整型变量a赋一个字符串值，那么a就变成字符类型。</p>\n<p>主要语言：JavaScript、PHP、C、C++（C和C++有争议，但是确实可以给一个字符变量赋整形值，可能初衷是强类型，形态上接近弱类型）</p>\n<h4>3、注意：</h4>\n<p>一个语言是不是强类型语言和是不是动态类型语言也没有必然联系。Python是动态类型语言，是强类型语言。JavaScript是动态类型语言，是弱类型语言。Java是静态类型语言，是强类型语言。</p>\n<hr />\n<p>下面再回答刚才提出的问题</p>\n<p>对于静态类型语言，所有的变量都需要在声明时指出它的数据类型，这样做的原因是：变量在程序中负责保存数据，程序中的每个变量都会在内存中占据一定的空间。静态类型语言<strong>所有的数据都有自己的数据类型，每种数据类型在内存中占据空间的大小又不一样，因此一个变量不可能保存任意类型的数据</strong>，所以在声明变量时必须指明这个变量的数据类型。</p>\n<p>其实又牵引出了另外一个问题，到底什么是变量？它的存储机制如何？</p>\n<p>引用知乎上一个很中肯的回答</p>\n<blockquote>\n<p>作者：Jason Ji</p>\n<p>链接：https://www.zhihu.com/question/34266997/answer/58226555</p>\n<p>来源：知乎</p>\n<p>变量：用来标识(identify)一块内存区域，这块区域的值一般是可以更改的，这就是它“变”的由来，但是我们可以通过使用如const等一些修饰符号来限定这一内存区域的操作特性(characteristic)，即变量的操作特性。用const修饰的使变量不能更改的就和常量一样的变量叫做常变量。</p>\n<p>变量名：是一个标识符(identifier)，用来指代一块内存区域，即变量，使用变量使我们操作内存以区域(area)，以块(block)为单位，提高了方便性。 </p>\n<p>你的机器代码中，是不会出现变量名的；变量名是给我们程序员操作内存来使用的。 </p>\n<p>想想在汇编年代，没有变量名，我们操作内存，都是用地址来直接操作的，还要控制区域大小；当然汇编语言已经有了简单的变量。 </p>\n<p>对于编译器，它会搜集我们的变量名，比如我们定义了一个全局的int a;那么编译器都为我们做了什么呢？ \n它会为程序预留4个字节的空间（假设在32位平台），并把我们的变量名“a”保存进符号表，并用这个符号表的索引对应实际的空间。 </p>\n<p>如果下面出现b = a;那么它就会根据符号表找到变量的真正的物理位置，取得它的值，赋给b。 </p>\n<p>这是写编译器需要做的，我们需要建立符号表。 但是实际在汇编层次上，操作的都是地址而已，不存在任何名称了。</p>\n</blockquote>\n<p>另外，再补充一下，上面的回答针对的是编译型语言，对于可以执行<strong>eval</strong>的解释型语言来说，变量名是存储的，比如JS的每个Environment Record就存了所有的局部变量，以及访问链</p>\n<p>还有就是变量在内存中的类型</p>\n<blockquote>\n<p>对于C/C++来说，不同指令对同一块内存会解释成不同的类型，也就是说类型是用指令解释的，计算机并不知道它的类型，而对于其它语言，一般存在额外的元数据区</p>\n</blockquote>','最近，在重新学习Java,适应Python过后看Java又是另一番风景。在思考为什么静态语言需要声明变量类型，比如\n> String ts = \"test\"\n\n而对于Python等动态语言，却又是这样声明\n> ts = \"test\"\n\n我想到一个问题：既然*ts*(变量名)表示一个地址，指向该变量的值，那么为什么还需要在使用它之前，还加一个类型进行声明呢？后来我又查阅了关于变量和内存的相关知识，又查了关于动态类型和静态类型语言的相关知识，看到有一篇文章写得不过，很全面又很简短，转载过来：\n\n以下内容转自：http://www.cnblogs.com/zy1987/p/3784753.html\n\n---\n\n### 编译型语言和解释型语言\n#### 1、编译型语言\n\n需通过编译器（compiler）将源代码编译成机器码，之后才能执行的语言。一般需经过编译（compile）、链接（linker）这两个步骤。编译是把源代码编译成机器码，链接是把各个模块的机器码和依赖库串连起来生成可执行文件。\n\n优点：编译器一般会有预编译的过程对代码进行优化。因为编译只做一次，运行时不需要编译，所以编译型语言的程序执行效率高。可以脱离语言环境独立运行。\n\n缺点：编译之后如果需要修改就需要整个模块重新编译。编译的时候根据对应的运行环境生成机器码，不同的操作系统之间移植就会有问题，需要根据运行的操作系统环境编译不同的可执行文件。\n\n代表语言：C、C++、Pascal、Object-C以及最近很火的苹果新语言swift\n\n#### 2、解释型语言\n\n解释性语言的程序不需要编译，相比编译型语言省了道工序，解释性语言在运行程序的时候才逐行翻译。\n\n优点：有良好的平台兼容性，在任何环境中都可以运行，前提是安装了解释器（虚拟机）。灵活，修改代码的时候直接修改就可以，可以快速部署，不用停机维护。\n\n缺点：每次运行的时候都要解释一遍，性能上不如编译型语言。\n\n代表语言：JavaScript、Python、Erlang、PHP、Perl、Ruby\n\n#### 3、混合型语言\n\n既然编译型和解释型各有缺点就会有人想到把两种类型整合起来，取其精华去其糟粕。就出现了半编译型语言。比如C#,C#在编译的时候不是直接编译成机器码而是中间码，.NET平台提供了中间语言运行库运行中间码，中间语言运行库类似于Java虚拟机。.net在编译成IL代码后，保存在dll中，首次运行时由JIT在编译成机器码缓存在内存中，下次直接执行（博友回复指出）。我个人认为抛开一切的偏见C#是这个星球上最好的编程语言。可惜微软的政策限制了C#的推广。\n\nJava先生成字节码再在Java虚拟机中解释执行。\n\n严格来说混合型语言属于解释型语言。C#更接近编译型语言。\n\n \n\n### 动态语言和静态语言\n#### 1、动态语言\n\n是一类在运行时可以改变其结构的语言：例如新的函数、对象、甚至代码可以被引进，已有的函数可以被删除或是其他结构上的变化。通俗点说就是在运行时代码可以根据某些条件改变自身结构。\n\n主要动态语言：Object-C、C#、JavaScript、PHP、Python、Erlang。\n\n#### 2、静态语言\n\n与动态语言相对应的，运行时结构不可变的语言就是静态语言。如Java、C、C++。\n\n \n\n#### 3、注意：\n\n很多人认为解释型语言都是动态语言，这个观点是错的！Java是解释型语言但是不是动态语言，Java不能在运行的时候改变自己结构。反之成立吗？动态语言都是解释型语言。也是错的！Object-C是编译型语言，但是他是动态语言。得益于特有的run time机制（准确说run time不是语法特性是运行时环境，这里不展开）OC代码是可以在运行的时候插入、替换方法的。\n\nC#也是动态语言，通过C#的反射机制可以动态的插入一段代码执行。所以我说C#是这个星球最好的编程语言。\n\n \n\n### 动态类型语言和静态类型语言\n#### 1、动态类型语言\n\n很多网上资料把动态类型语言和动态语言混为一谈，简直是误人子弟。动态类型语言和动态语言是完全不同的两个概念。动态类型语言是指在运行期间才去做数据类型检查的语言，说的是数据类型，动态语言说的是运行是改变结构，说的是代码结构。\n\n动态类型语言的数据类型不是在编译阶段决定的，而是把类型绑定延后到了运行阶段。\n\n主要语言：Python、Ruby、Erlang、JavaScript、swift、PHP、Perl。\n\n#### 2、静态类型语言\n\n静态语言的数据类型是在编译其间确定的或者说运行之前确定的，编写代码的时候要明确确定变量的数据类型。\n\n主要语言：C、C++、C#、Java、Object-C。\n\n#### 3、注意：\n\n相当一部分程序员，也包括曾经的我，认为解释型语言都是动态类型语言，编译型语言都是静态类型语言。这个也是错的。swift是编译型语言但是它也是动态类型语言。C#和Java是解释型语言也是静态类型语言。\n\n### 强类型语言和弱类型语言\n#### 1、强类型语言：\n\n强类型语言，一旦一个变量被指定了某个数据类型，如果不经过强制类型转换，那么它就永远是这个数据类型。你不能把一个整形变量当成一个字符串来处理。\n\n主要语言：Java、C#、Python、Object-C、Ruby\n\n#### 2、弱类型语言：\n\n数据类型可以被忽略，一个变量可以赋不同数据类型的值。一旦给一个整型变量a赋一个字符串值，那么a就变成字符类型。\n\n主要语言：JavaScript、PHP、C、C++（C和C++有争议，但是确实可以给一个字符变量赋整形值，可能初衷是强类型，形态上接近弱类型）\n\n#### 3、注意：\n\n一个语言是不是强类型语言和是不是动态类型语言也没有必然联系。Python是动态类型语言，是强类型语言。JavaScript是动态类型语言，是弱类型语言。Java是静态类型语言，是强类型语言。\n\n---\n\n下面再回答刚才提出的问题\n\n对于静态类型语言，所有的变量都需要在声明时指出它的数据类型，这样做的原因是：变量在程序中负责保存数据，程序中的每个变量都会在内存中占据一定的空间。静态类型语言**所有的数据都有自己的数据类型，每种数据类型在内存中占据空间的大小又不一样，因此一个变量不可能保存任意类型的数据**，所以在声明变量时必须指明这个变量的数据类型。\n\n其实又牵引出了另外一个问题，到底什么是变量？它的存储机制如何？\n\n引用知乎上一个很中肯的回答\n>作者：Jason Ji\n\n>链接：https://www.zhihu.com/question/34266997/answer/58226555\n\n>来源：知乎\n\n>变量：用来标识(identify)一块内存区域，这块区域的值一般是可以更改的，这就是它“变”的由来，但是我们可以通过使用如const等一些修饰符号来限定这一内存区域的操作特性(characteristic)，即变量的操作特性。用const修饰的使变量不能更改的就和常量一样的变量叫做常变量。\n\n>变量名：是一个标识符(identifier)，用来指代一块内存区域，即变量，使用变量使我们操作内存以区域(area)，以块(block)为单位，提高了方便性。 \n\n>你的机器代码中，是不会出现变量名的；变量名是给我们程序员操作内存来使用的。 \n\n>想想在汇编年代，没有变量名，我们操作内存，都是用地址来直接操作的，还要控制区域大小；当然汇编语言已经有了简单的变量。 \n\n>对于编译器，它会搜集我们的变量名，比如我们定义了一个全局的int a;那么编译器都为我们做了什么呢？ \n它会为程序预留4个字节的空间（假设在32位平台），并把我们的变量名“a”保存进符号表，并用这个符号表的索引对应实际的空间。 \n\n>如果下面出现b = a;那么它就会根据符号表找到变量的真正的物理位置，取得它的值，赋给b。 \n\n>这是写编译器需要做的，我们需要建立符号表。 但是实际在汇编层次上，操作的都是地址而已，不存在任何名称了。\n\n另外，再补充一下，上面的回答针对的是编译型语言，对于可以执行**eval**的解释型语言来说，变量名是存储的，比如JS的每个Environment Record就存了所有的局部变量，以及访问链\n\n还有就是变量在内存中的类型\n> 对于C/C++来说，不同指令对同一块内存会解释成不同的类型，也就是说类型是用指令解释的，计算机并不知道它的类型，而对于其它语言，一般存在额外的元数据区\n',1,'底层',1476066838,0,38,0,1,1),(109,'聊聊Python中的访问权限','&lt;p&gt;请看如下代码&lt;/p&gt;\n&lt;pre&gt;\nclass Student(object):\n    def __init__(self, name):\n        self.name = name\n\nif __name__ == \'__main__\':\n    bart = Student(\'resolvewang\')\n    print(bart.name)\n&lt;/pre&gt;\n\n&lt;p&gt;结果&lt;/p&gt;\n<blockquote>\n&lt;p&gt;resolvewang&lt;/p&gt;\n</blockquote>\n&lt;p&gt;那么，我们怎么设置private属性呢？在Python中，可以通过两个<em>_</em>设置private属性，通过访问器方法访问。将上述代码稍加修改，修改如下\n&lt;pre&gt;\nclass Student(object):\n    def __init__(self, name):\n        self.__name = name&lt;/p&gt;\n&lt;p&gt;if __name__ == \'__main__\':\n    bart = Student(\'resolvewang\')\n    print(bart.__name)\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;然后运行程序，结果如下&lt;/p&gt;\n<blockquote>\n&lt;p&gt;AttributeError: \'Student\' object has no attribute \'__name\'&lt;/p&gt;\n</blockquote>\n&lt;p&gt;说明确实设置为了private属性了，我们通过访问器方法访问试试\n&lt;pre&gt;\ndef get_name(self):\n    return self.__name\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;在程序中调用get_name()方法，代码如下\n&lt;pre&gt;\nclass Student(object):\n    def __init__(self, name):\n        self.__name = name\n    def get_name(self):\n        return self.__name&lt;/p&gt;\n&lt;p&gt;if __name__ == \'__main__\':\n    bart = Student(\'resolvewang\')\n    print(bart.get_name())\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;运行结果&lt;/p&gt;\n<blockquote>\n&lt;p&gt;resolvewang&lt;/p&gt;\n</blockquote>\n&lt;p&gt;证实了可以通过方法访问到私有属性&lt;/p&gt;\n&lt;p&gt;其实，还有一种不提倡的方法，可以直接访问到私有变量，我们先用&lt;/p&gt;\n<blockquote>\n&lt;p&gt;print(dir(bart))&lt;/p&gt;\n</blockquote>\n&lt;p&gt;打印出bart的所有属性，如下&lt;/p&gt;\n<blockquote>\n&lt;p&gt;_Student__name, __class__, __delattr__, __dict__ ...&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这里我想说的是<strong>_Student__name</strong>这个属性，注意前面是一个下划线，我们打印出来看看&lt;/p&gt;\n<blockquote>\n&lt;p&gt;resolvewang&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这就是我们的私有变量！是否能修改呢？&lt;/p&gt;\n<blockquote>\n&lt;p&gt;bart._Student__name = \'wpm\'&lt;/p&gt;\n</blockquote>\n&lt;p&gt;再调用get_name()看看结果&lt;/p&gt;\n<blockquote>\n&lt;p&gt;wpm&lt;/p&gt;\n</blockquote>\n&lt;p&gt;所以可以通过这种方法访问私有变量并且修改，为啥Python会提供这个自由呢？Python有一个设计哲学：<strong>我们大家都是成年人，不必像约束小孩子那样</strong>。这种方法通常不推荐使用。&lt;/p&gt;','请看如下代码\n\n<pre>\nclass Student(object):\n    def __init__(self, name):\n        self.name = name\n\nif __name__ == \'__main__\':\n    bart = Student(\'resolvewang\')\n    print(bart.name)\n</pre>\n\n结果\n> resolvewang\n\n那么，我们怎么设置private属性呢？在Python中，可以通过两个*_*设置private属性，通过访问器方法访问。将上述代码稍加修改，修改如下\n<pre>\nclass Student(object):\n    def \\_\\_init\\_\\_(self, name):\n        self.__name = name\n\nif \\_\\_name\\_\\_ == \'\\_\\_main\\_\\_\':\n    bart = Student(\'resolvewang\')\n    print(bart.__name)\n</pre>\n\n然后运行程序，结果如下\n> AttributeError: \'Student\' object has no attribute \'__name\'\n\n说明确实设置为了private属性了，我们通过访问器方法访问试试\n<pre>\ndef get_name(self):\n	return self.\\_\\_name\n</pre>\n\n在程序中调用get_name()方法，代码如下\n<pre>\nclass Student(object):\n    def \\_\\_init\\_\\_(self, name):\n        self.\\_\\_name = name\n    def get_name(self):\n        return self.\\_\\_name\n\nif \\_\\_name\\_\\_ == \'\\_\\_main\\_\\_\':\n    bart = Student(\'resolvewang\')\n    print(bart.get_name())\n</pre>\n\n运行结果\n> resolvewang\n\n证实了可以通过方法访问到私有属性\n\n其实，还有一种不提倡的方法，可以直接访问到私有变量，我们先用\n> print(dir(bart))\n\n打印出bart的所有属性，如下\n> \\_Student\\_\\_name, \\_\\_class\\_\\_, \\_\\_delattr\\_\\_, \\_\\_dict\\_\\_ ...\n\n这里我想说的是**\\_Student\\_\\_name**这个属性，注意前面是一个下划线，我们打印出来看看\n> resolvewang\n\n这就是我们的私有变量！是否能修改呢？\n> bart.\\_Student\\_\\_name = \'wpm\'\n\n再调用get_name()看看结果\n> wpm\n\n所以可以通过这种方法访问私有变量并且修改，为啥Python会提供这个自由呢？Python有一个设计哲学：**我们大家都是成年人，不必像约束小孩子那样**。这种方法通常不推荐使用。',1,'python',1476104947,0,28,0,1,1),(110,'一天两道Python面试题：语言特性(二)','&lt;p&gt;问题一&lt;/p&gt;\n<blockquote>\n&lt;p&gt;@staticmethod 和 @classmethod&lt;/p&gt;\n</blockquote>\n&lt;p&gt;python中存在三种方法，静态方法、类方法和实例方法，代码如下：\n&lt;pre&gt;\nclass A(object):\n    def foo(self,x):\n        print \"executing foo(%s,%s)\"%(self,x)\n    @classmethod\n    def class_foo(cls,x):\n        print \"executing class_foo(%s,%s)\"%(cls,x)\n    @staticmethod\n    def static_foo(x):\n        print \"executing static_foo(%s)\"%x&lt;/p&gt;\n&lt;p&gt;a=A()\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;先看看foo()中的self和class_foo的cls参数，它们实际上是对实例或者类的绑定。以实例方法为例，我们知道在类中每次定义方法的时候都需要绑定这个实例，就是foo(self, x),为什么这么做呢？因为<strong>实例方法的调用离不开实例</strong>，所以需要把实例传递给函数，对于a.foo(x),其实可看做是foo(a, x).对于类方法，也一样，它传递的是类而不是实例作为参数。self和cls只是约定俗成的参数名，可以改，但建议别改。另外，实例可以访问实例属性和类属性；类方法只能访问类属性，不能访问实例属性；为什么要有类属性，一句话<strong>命令空间</strong>。&lt;/p&gt;\n&lt;p&gt;再谈谈静态方法，静态方法不依靠<strong>隐式的传递实例或者类作为参数</strong>，它在被调用时对类或者实例一无所知。静态方法能做的事情类外的普通方法基本都能做，那么为什么还需要静态方法呢？原因是有的方法和某个类在逻辑上存在依赖关系，如果不用类的命名空间约束它，那么模块中会有各种可能只用于某个特殊用途的方法。&lt;/p&gt;\n&lt;hr/&gt;\n&lt;p&gt;今天搬了办公场所，时间所限，就写一道题，明天继续，加油！&lt;/p&gt;','问题一\n> @staticmethod 和 @classmethod\n\npython中存在三种方法，静态方法、类方法和实例方法，代码如下：\n<pre>\nclass A(object):\n    def foo(self,x):\n        print \"executing foo(%s,%s)\"%(self,x)\n    @classmethod\n    def class_foo(cls,x):\n        print \"executing class_foo(%s,%s)\"%(cls,x)\n    @staticmethod\n    def static_foo(x):\n        print \"executing static_foo(%s)\"%x\n\na=A()\n</pre>\n\n先看看foo()中的self和class_foo的cls参数，它们实际上是对实例或者类的绑定。以实例方法为例，我们知道在类中每次定义方法的时候都需要绑定这个实例，就是foo(self, x),为什么这么做呢？因为**实例方法的调用离不开实例**，所以需要把实例传递给函数，对于a.foo(x),其实可看做是foo(a, x).对于类方法，也一样，它传递的是类而不是实例作为参数。self和cls只是约定俗成的参数名，可以改，但建议别改。另外，实例可以访问实例属性和类属性；类方法只能访问类属性，不能访问实例属性；为什么要有类属性，一句话**命令空间**。\n\n再谈谈静态方法，静态方法不依靠**隐式的传递实例或者类作为参数**，它在被调用时对类或者实例一无所知。静态方法能做的事情类外的普通方法基本都能做，那么为什么还需要静态方法呢？原因是有的方法和某个类在逻辑上存在依赖关系，如果不用类的命名空间约束它，那么模块中会有各种可能只用于某个特殊用途的方法。\n\n---\n\n今天搬了办公场所，时间所限，就写一道题，明天继续，加油！',1,'python,面试题',1476108736,0,33,0,1,1),(111,'一天两道Python面试题:语言特性(三)','<h3>1. 类变量和实例变量</h3>\n<h4>类变量是提供给类使用的变量，实例变量是提供给实例使用的。</h4>\n<p>查看下面这段代码\n<pre>\nclass Person:\n    name = \'aaa\'</p>\n<p>p1=Person()\np2=Person()\np1.name = \'bbb\'\nprint(p1.name, p2.name, Person.name)\n</pre></p>\n<p>结果</p>\n<blockquote>\n<p>bbb aaa aaa</p>\n</blockquote>\n<p>这里p1.name = \'bbb\'是实例调用了类变量，其实和函数传参的问题一样，一开始指向的“aaa”,但是在实例作用域中把类变量的引用改变了，其实就变成了一个实例变量,即self.name</p>\n<p>举一反三，如果</p>\n<blockquote>\n<p>name = []</p>\n</blockquote>\n<p>然后修改</p>\n<blockquote>\n<p>p1.name.append[\'resolvewang\']</p>\n</blockquote>\n<p>结果</p>\n<blockquote>\n<p>[\'resolvewang\'] [\'resolvewang\'] [\'resolvewang\']</p>\n</blockquote>\n<p>这是因为name在这里是可变对象，当我们使用<em>p1.name.append[\'resolvewang\']</em>的时候，p1.name仍然指向的是Person.name指向的内存，而前者由于是不可变对象，p1.name的值又产生了一个新的值，所以p1.name只能指向的是一个新的内存</p>\n<h3>2. 问题二</h3>\n<h4>怎么理解Python的metaclass</h4>\n<p>metaclass属于比较深度的魔法了。在我的理解中，metaclass<strong>既是类的属性，也是类的类</strong></p>\n<p>下面我来解释我的观点</p>\n<p>知识铺垫\n- 对象</p>\n<p>python中，一切皆对象，我们常谈的对象是<strong>实例对象</strong>，除此之外，还包括<strong>类对象</strong>、<strong>函数对象</strong>等。实例对象就不用解释了吧，类对象就是一个一个的类，它们是type类的实例，就拿object类来看</p>\n<blockquote>\n<p>type(object)</p>\n</blockquote>\n<p>结果</p>\n<blockquote>\n<p>class \'type\'</p>\n</blockquote>\n<p>也可以用object.__class__来查看实例所属的类。除了类对象，还有函数对象，通过<em>print.__class__</em>来查看</p>\n<blockquote>\n<p>class \'builtin_function_or_method\'</p>\n</blockquote>\n<p>这里我们重点讨论的是实例对象和类对象</p>\n<p>了解了对象的概念，我们再来谈谈对象的创建。静态的创建这里就不列举了，这里说说两种动态创建类的方法：1.普通方法创建 2.通过type创建</p>\n<p>普通方法创建示例代码如下\n<pre>\ndef create_obj(arg):\n    class A(object):\n        name = \'resolvewang\'\n    return A\n</pre></p>\n<p>使用type(类名，父类元组，属性字典)的方式创建如下</p>\n<blockquote>\n<p>B = type(\'B\', (object,), {\'name\': \'test\'})</p>\n<p>b_instance = B()</p>\n<p>print(b_instance.name)</p>\n</blockquote>\n<p>结果</p>\n<blockquote>\n<p>test</p>\n</blockquote>\n<p>两种方式创建的效果一样，第二种更加动态，而我们需要重点理解的也是使用type方法进行创建，因为通过metaclass创建类也需要它</p>\n<p>再说说通过metaclass创建类的经过</p>\n<p>前面说了metaclass是类对象的属性。如果一个类对象中含有metaclass,那么在创建该类对象的时候，会调用指定metaclass的__new__方法来进行创建(该方法内部需要调用type.__init__来创建)，比如下面代码，我想使用元类来创建一个类，即有List的特性，又新加了add方法\n<pre>\nclass ListMetaclass(type):\n    def __new__(cls, name, bases, attrs):\n        attrs[\'add\'] = lambda self, value: self.append(value)\n        # 也可以直接用type()方法创建\n        return type.__new__(cls, name, bases, attrs)\nclass MyList(list, metaclass=ListMetaclass):\n    pass\n</pre></p>\n<p>测试</p>\n<blockquote>\n<p>my_list = MyList()</p>\n<p>my_list.add(1)</p>\n<p>print(my_list)</p>\n</blockquote>\n<p>结果</p>\n<blockquote>\n<p>[1]</p>\n</blockquote>\n<p>如果是python2.x，那么写法就类似这样\n<pre>\nclass MyList(list):\n    __metaclass__ = ListMetaclass\n    pass\n</pre></p>\n<p>基于这种写法，我把metaclass也理解为是类的一个属性(可能这个理解从严格意义上来说不正确，但是理解起来更容易了)。这个属性会在创建MyList类的开始，就调用自身的__new__()方法，并且传入的参数依次是拥有metaclass属性的类(MyList)对象、它的名字、父类元组和类的属性</p>\n<p>所以说，元类的作用如下\n- 拦截类的创建\n- 修改并且返回拥有元类这个属性的类</p>\n<p>至于啥时候用它，引用Python专家Tim Peters的一句话</p>\n<blockquote>\n<p>元类就是深度的魔法，99%的用户应该根本不必为此操心。如果你想搞清楚究竟是否需要用到元类，那么你就不需要它。那些实际用到元类的人都非常清楚地知道他们需要做什么，而且根本不需要解释为什么要用元类</p>\n</blockquote>\n<p>我们接触过的关于元类的用法是编写ORM框架，比如sqlalchemy就使用了这个技术。以后自己也动手写一个ORM框架</p>','###1. 类变量和实例变量\n\n####类变量是提供给类使用的变量，实例变量是提供给实例使用的。\n\n查看下面这段代码\n<pre>\nclass Person:\n    name = \'aaa\'\n\np1=Person()\np2=Person()\np1.name = \'bbb\'\nprint(p1.name, p2.name, Person.name)\n</pre>\n\n结果\n> bbb aaa aaa\n\n这里p1.name = \'bbb\'是实例调用了类变量，其实和函数传参的问题一样，一开始指向的“aaa”,但是在实例作用域中把类变量的引用改变了，其实就变成了一个实例变量,即self.name\n\n举一反三，如果\n> name = []\n\n然后修改\n> p1.name.append[\'resolvewang\']\n\n结果\n> [\'resolvewang\'] [\'resolvewang\'] [\'resolvewang\']\n\n这是因为name在这里是可变对象，当我们使用*p1.name.append[\'resolvewang\']*的时候，p1.name仍然指向的是Person.name指向的内存，而前者由于是不可变对象，p1.name的值又产生了一个新的值，所以p1.name只能指向的是一个新的内存\n\n###2. 问题二\n####怎么理解Python的metaclass\n\nmetaclass属于比较深度的魔法了。在我的理解中，metaclass**既是类的属性，也是类的类**\n\n下面我来解释我的观点\n\n知识铺垫\n- 对象\n\npython中，一切皆对象，我们常谈的对象是**实例对象**，除此之外，还包括**类对象**、**函数对象**等。实例对象就不用解释了吧，类对象就是一个一个的类，它们是type类的实例，就拿object类来看\n> type(object)\n\n结果\n> class \'type\'\n\n也可以用object.\\_\\_class\\_\\_来查看实例所属的类。除了类对象，还有函数对象，通过*print.\\_\\_class\\_\\_*来查看\n> class \'builtin_function_or_method\'\n\n这里我们重点讨论的是实例对象和类对象\n\n了解了对象的概念，我们再来谈谈对象的创建。静态的创建这里就不列举了，这里说说两种动态创建类的方法：1.普通方法创建 2.通过type创建\n\n普通方法创建示例代码如下\n<pre>\ndef create_obj(arg):\n    class A(object):\n        name = \'resolvewang\'\n    return A\n</pre>\n\n使用type(类名，父类元组，属性字典)的方式创建如下\n>B = type(\'B\', (object,), {\'name\': \'test\'})\n\n>b_instance = B()\n\n> print(b_instance.name)\n\n结果\n> test\n\n两种方式创建的效果一样，第二种更加动态，而我们需要重点理解的也是使用type方法进行创建，因为通过metaclass创建类也需要它\n\n再说说通过metaclass创建类的经过\n\n前面说了metaclass是类对象的属性。如果一个类对象中含有metaclass,那么在创建该类对象的时候，会调用指定metaclass的\\_\\_new\\_\\_方法来进行创建(该方法内部需要调用type.\\_\\_init\\_\\_来创建)，比如下面代码，我想使用元类来创建一个类，即有List的特性，又新加了add方法\n<pre>\nclass ListMetaclass(type):\n    def \\_\\_new\\_\\_(cls, name, bases, attrs):\n        attrs[\'add\'] = lambda self, value: self.append(value)\n        \\# 也可以直接用type()方法创建\n        return type.\\_\\_new\\_\\_(cls, name, bases, attrs)\nclass MyList(list, metaclass=ListMetaclass):\n    pass\n</pre>\n\n测试\n> my_list = MyList()\n\n> my_list.add(1)\n\n> print(my_list)\n\n结果\n> [1]\n\n如果是python2.x，那么写法就类似这样\n<pre>\nclass MyList(list):\n	\\_\\_metaclass\\_\\_ = ListMetaclass\n	pass\n</pre>\n\n基于这种写法，我把metaclass也理解为是类的一个属性(可能这个理解从严格意义上来说不正确，但是理解起来更容易了)。这个属性会在创建MyList类的开始，就调用自身的\\_\\_new\\_\\_()方法，并且传入的参数依次是拥有metaclass属性的类(MyList)对象、它的名字、父类元组和类的属性\n\n所以说，元类的作用如下\n- 拦截类的创建\n- 修改并且返回拥有元类这个属性的类\n\n至于啥时候用它，引用Python专家Tim Peters的一句话\n>元类就是深度的魔法，99%的用户应该根本不必为此操心。如果你想搞清楚究竟是否需要用到元类，那么你就不需要它。那些实际用到元类的人都非常清楚地知道他们需要做什么，而且根本不需要解释为什么要用元类\n\n我们接触过的关于元类的用法是编写ORM框架，比如sqlalchemy就使用了这个技术。以后自己也动手写一个ORM框架',1,'Python,面试题',1476187823,0,31,0,1,1),(112,'一天两道Python面试题:语言特性(四)','&lt;h3&gt;问题一：聊聊Python的自省&lt;/h3&gt;\n<blockquote>\n&lt;p&gt;自省就是运行时能够获取对象的类型，类似Java的反射&lt;/p&gt;\n</blockquote>\n&lt;p&gt;常用的自省函数：type、dir、getattr、hasattr、isinstance、callable&lt;/p&gt;\n&lt;hr/&gt;\n&lt;h3&gt;问题二: 字典推导式&lt;/h3&gt;\n<blockquote>\n&lt;p&gt;d = {key: value for (key, value) in iterable}&lt;/p&gt;\n</blockquote>\n&lt;p&gt;可以用任何方式的迭代器(元组,列表,生成器..),只要<strong>可迭代对象</strong>的元素中有两个值。进阶代码：&lt;/p&gt;\n&lt;pre&gt;\ndef key_value_gen(k):\n   yield chr(k+65)\n   yield chr((k+13)%26+65)\nd = dict(map(key_value_gen, range(26)))\n&lt;/pre&gt;\n\n&lt;p&gt;上面是一段关于生成器和列表推导式的代码，在我的理解中，<em>key_value_gen</em>是一个函数，但是当它传递了一个具体的参数后，就成了一个生成器，其中有几个yield那么就可以看做返回几个值(调用的时候用next()顺序调用)。上述代码等价于&lt;/p&gt;\n&lt;pre&gt;\ndef key_value_gen(k):\n   return chr(k+65),chr((k+13)%26+65)\nd = dict(map(key_value_gen, range(26)))\n&lt;/pre&gt;\n\n&lt;p&gt;这两段代码也印证了上面说的<strong>只要可迭代对象的元素中有两个值</strong>&lt;/p&gt;','### 问题一：聊聊Python的自省\n\n> 自省就是运行时能够获取对象的类型，类似Java的反射\n\n常用的自省函数：type、dir、getattr、hasattr、isinstance、callable\n\n---\n\n### 问题二: 字典推导式\n\n> d = {key: value for (key, value) in iterable}\n\n可以用任何方式的迭代器(元组,列表,生成器..),只要**可迭代对象**的元素中有两个值。进阶代码：\n\n<pre>\ndef key_value_gen(k):\n   yield chr(k+65)\n   yield chr((k+13)%26+65)\nd = dict(map(key_value_gen, range(26)))\n</pre>\n\n上面是一段关于生成器和列表推导式的代码，在我的理解中，*key_value_gen*是一个函数，但是当它传递了一个具体的参数后，就成了一个生成器，其中有几个yield那么就可以看做返回几个值(调用的时候用next()顺序调用)。上述代码等价于\n\n<pre>\ndef key_value_gen(k):\n   return chr(k+65),chr((k+13)%26+65)\nd = dict(map(key_value_gen, range(26)))\n</pre>\n\n这两段代码也印证了上面说的**只要可迭代对象的元素中有两个值**',1,'python,面试题',1476365983,0,34,0,1,1),(113,'SqlAlchemy的object转化为dict','&lt;p&gt;这几天由于项目需要给客户提供restful接口，想到使用sqlalchemy,但是在将sqlalchemy的查询结果显示出来的时候遇到了一个问题，如何将其转化为dict，因为sqlalchemy查询出来的对象中多了一些属性，比如<strong>_sa_instance_state</strong>，后来看到了这么个用法：__table__.c,它对应的是表的各个属性，这样就可以将obj转化为dict了，代码如下&lt;/p&gt;\n&lt;pre&gt;\ndef to_dict(ins):\n    table_columns = ins.__table__.c\n    l = [column.key for column in table_columns]\n    d = {}\n    for k, v in ins.__dict__.items():\n        if k in l:\n            d[k] = str(v) if v is not None else \'\'\n    return d\n&lt;/pre&gt;','这几天由于项目需要给客户提供restful接口，想到使用sqlalchemy,但是在将sqlalchemy的查询结果显示出来的时候遇到了一个问题，如何将其转化为dict，因为sqlalchemy查询出来的对象中多了一些属性，比如**_sa_instance_state**，后来看到了这么个用法：\\_\\_table\\_\\_.c,它对应的是表的各个属性，这样就可以将obj转化为dict了，代码如下\n\n<pre>\ndef to_dict(ins):\n    table_columns = ins.__table__.c\n    l = [column.key for column in table_columns]\n    d = {}\n    for k, v in ins.__dict__.items():\n        if k in l:\n            d[k] = str(v) if v is not None else \'\'\n    return d\n</pre>',1,'python',1476669069,0,25,0,1,1),(114,'聊聊Python中的mixin','&lt;p&gt;Mixin读作\'mix-in\',意为混入。以前一直不理解这是什么黑魔法，今天看了一些文章，把自己的理解记录下来。&lt;/p&gt;\n&lt;p&gt;说简单一点，mixin就是<strong>多重继承</strong>，只不过对多重继承有了一定的要求，要求如下：&lt;/p&gt;\n<ul>\n<li>\n&lt;p&gt;Mixin类必须是单一职责&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;Mixin类没有__init__()方法&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;Mixin类没有实例属性&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;Mixin类只能混入别的类&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;Mixin类的方法和主类方法不重名&lt;/p&gt;\n</li>\n</ul>\n&lt;p&gt;如果做到了这几点，那么就可以看做是一个mixin类了，而且也不会因为super()而发生调用混乱问题。其实从上面描述中可以看出，mixin对主体的信息一无所知，它只具有单一的职责。使用mixin的好处是不需要像Java等单继承语言那样需要严格的继承体系和庞大的继承链。比如，动物包括会飞和不会飞的动物，然后会飞的动物中又包含哺乳和非哺乳动物，不会飞的动物也包含哺乳动物和非哺乳动物，如果再往下细分，则类的层次更加复杂。刚才所说的例子中会飞的动物和不会飞的动物都包含哺乳动物，这样划分就会出现某些方面重复的了。那么我们可以根据动物的各种属性来进行定义吗？鸭子类型就是这个意思：&lt;/p&gt;\n<blockquote>\n&lt;p&gt;当一只动物走路像鸭子，游泳像鸭子，我们就可以把它看做是鸭子&lt;/p&gt;\n</blockquote>\n&lt;p&gt;意思就是我们只关心它的功能，它的功能决定了它的类别。Mixin就是这样的类，因为每个mixin类只提供单一方法。由于没有接口限制，所以对开发者要求更高了&lt;/p&gt;\n<blockquote>\n&lt;p&gt;代码中无接口而脑海中有清晰的接口&lt;/p&gt;\n</blockquote>','Mixin读作\'mix-in\',意为混入。以前一直不理解这是什么黑魔法，今天看了一些文章，把自己的理解记录下来。\n\n说简单一点，mixin就是**多重继承**，只不过对多重继承有了一定的要求，要求如下：\n\n- Mixin类必须是单一职责\n\n- Mixin类没有\\_\\_init\\_\\_()方法\n\n- Mixin类没有实例属性\n\n- Mixin类只能混入别的类\n\n- Mixin类的方法和主类方法不重名\n\n如果做到了这几点，那么就可以看做是一个mixin类了，而且也不会因为super()而发生调用混乱问题。其实从上面描述中可以看出，mixin对主体的信息一无所知，它只具有单一的职责。使用mixin的好处是不需要像Java等单继承语言那样需要严格的继承体系和庞大的继承链。比如，动物包括会飞和不会飞的动物，然后会飞的动物中又包含哺乳和非哺乳动物，不会飞的动物也包含哺乳动物和非哺乳动物，如果再往下细分，则类的层次更加复杂。刚才所说的例子中会飞的动物和不会飞的动物都包含哺乳动物，这样划分就会出现某些方面重复的了。那么我们可以根据动物的各种属性来进行定义吗？鸭子类型就是这个意思：\n> 当一只动物走路像鸭子，游泳像鸭子，我们就可以把它看做是鸭子\n\n意思就是我们只关心它的功能，它的功能决定了它的类别。Mixin就是这样的类，因为每个mixin类只提供单一方法。由于没有接口限制，所以对开发者要求更高了\n> 代码中无接口而脑海中有清晰的接口',1,'python',1476867313,0,27,0,1,1),(115,'一天两道Python面试题:语言特性(五)','&lt;h3&gt;问题一:Python中单下划线和双下划线&lt;/h3&gt;\n<blockquote>\n&lt;p&gt;_foo:一种约定，程序员用来指定私有变量的方式。&lt;/p&gt;\n&lt;p&gt;__foo: 设置私有变量，不能直接通过obj.__foo来访问，但是可以通过obj.__cls__.__foo来访问 &lt;/p&gt;\n&lt;p&gt;__foo__: 一种约定，Python内部的名字，用来区别于其它用户自定义的命名，防止冲突&lt;/p&gt;\n</blockquote>\n&lt;hr/&gt;\n&lt;h3&gt;问题二：*args和**args的区别&lt;/h3&gt;\n<blockquote>\n&lt;p&gt;*args:可变参数，允许传递任意数量的参数&lt;/p&gt;\n&lt;p&gt;**kwargs: 关键字参数，允许使用没有事先定义的参数名&lt;/p&gt;\n</blockquote>\n&lt;p&gt;关键字参数在最近读的requests源码中经常看到，使用它可以避免经常修改函数的必选参数，一个比较pythonic的用法如下&lt;/p&gt;\n<blockquote>\n&lt;p&gt;timeout = kwargs.pop(\'timeout\', None)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;除此之外，还有一个命名关键字参数，形式如下&lt;/p&gt;\n<blockquote>\n&lt;p&gt;func(a,b,*,c)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;这个是Python3才有的，它的作用是约束关键字，只有指定名的关键字才可以出现，比如上面只能出现func(1,2,c=3)这种形式而不能出现func(1,2,c=3,d=4)或者func(1,2,d=4)这种形式&lt;/p&gt;\n&lt;p&gt;还有一个就是函数参数的位置&lt;/p&gt;\n<blockquote>\n&lt;p&gt;必选-&gt;默认-&gt;可变-&gt;命令关键字-&gt;关键字&lt;/p&gt;\n</blockquote>\n&lt;p&gt;当一个函数在调用而不是在定义的时候出现*,其实是对函数参数进行解包，而不是传递引用。看例子：\n&lt;pre&gt;\nmy_list = [1, 2, 3]\ndef print_list(a, b, c):\n    print(a+b+c)&lt;/p&gt;\n&lt;p&gt;print_list(*my_list)&lt;/p&gt;\n&lt;p&gt;结果\n&gt;&gt;&gt; 6&lt;/p&gt;\n&lt;p&gt;print_list(my_list)&lt;/p&gt;\n&lt;p&gt;结果\n&gt;&gt;&gt;TypeError：print_list()missing 2 required positional arguments:\'b\' and \'c\'\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;所以\"*\"是对参数进行解包，无论是在定义还是在调用函数的时候，解出来的包是单个的数。\"**\"也是一样的,它解出来的包是单个的键值对。这两种情况能正常工作的前提是函数的参数个数必须和解包后的数据个数一致。&lt;/p&gt;','### 问题一:Python中单下划线和双下划线\n\n> _foo:一种约定，程序员用来指定私有变量的方式。\n\n> \\_\\_foo: 设置私有变量，不能直接通过obj.\\_\\_foo来访问，但是可以通过obj.\\_\\_cls\\_\\_.\\_\\_foo来访问 \n\n> \\_\\_foo\\_\\_: 一种约定，Python内部的名字，用来区别于其它用户自定义的命名，防止冲突\n\n---\n\n### 问题二：\\*args和\\*\\*args的区别\n\n> *args:可变参数，允许传递任意数量的参数\n\n> \\*\\*kwargs: 关键字参数，允许使用没有事先定义的参数名\n\n关键字参数在最近读的requests源码中经常看到，使用它可以避免经常修改函数的必选参数，一个比较pythonic的用法如下\n> timeout = kwargs.pop(\'timeout\', None)\n\n除此之外，还有一个命名关键字参数，形式如下\n> func(a,b,*,c)\n\n这个是Python3才有的，它的作用是约束关键字，只有指定名的关键字才可以出现，比如上面只能出现func(1,2,c=3)这种形式而不能出现func(1,2,c=3,d=4)或者func(1,2,d=4)这种形式\n\n还有一个就是函数参数的位置\n> 必选->默认->可变->命令关键字->关键字\n\n\n当一个函数在调用而不是在定义的时候出现*,其实是对函数参数进行解包，而不是传递引用。看例子：\n<pre>\nmy_list = [1, 2, 3]\ndef print_list(a, b, c):\n	print(a+b+c)\n\nprint_list(*my_list)\n\n结果\n\\>\\>\\> 6\n\nprint_list(my_list)\n\n结果\n\\>\\>\\>TypeError：print_list()missing 2 required positional arguments:\'b\' and \'c\'\n</pre>\n\n所以\"\\*\"是对参数进行解包，无论是在定义还是在调用函数的时候，解出来的包是单个的数。\"\\*\\*\"也是一样的,它解出来的包是单个的键值对。这两种情况能正常工作的前提是函数的参数个数必须和解包后的数据个数一致。\n\n',1,'python,面试题',1476877339,0,29,0,1,1),(116,'Python单例模式','&lt;p&gt;直到今天，我才真正懂了单例模式，以前只是单纯会写它，没明白为何返回一个类中的属性，就是实例了，不明白为何实例自己还包含自己本身。在读requests的源码时，有一段关于管理权限的代码是这样的&lt;/p&gt;\n&lt;pre&gt;\n    class AuthManager(object):\n        def __new__(cls):\n            singleton = cls.__dict__.get(\'__singleton__\')\n            if singleton is not None:\n                return singleton\n\n            cls.__singleton__ = singleton = object.__new__(cls)\n            return singleton\n&lt;/pre&gt;\n\n&lt;p&gt;如果new一个实例&lt;/p&gt;\n<blockquote>\n&lt;p&gt;auth = AuthManager()&lt;/p&gt;\n</blockquote>\n&lt;p&gt;有一点我不明白的就是，为何auth对象中包含自身(__singleton__属性)，对象怎么包含自己了？后来在网上查阅了很多资料，基本都是讲怎么写单例模式，但是没讲它为何是这样的，可能是我比较笨吧。后来我查了它的定义相关的描述才懂。这是让我彻底明白的描述&lt;/p&gt;\n<blockquote>\n&lt;p&gt;实现单例模式的思路是：一个类能返回对象一个<strong>引用</strong>(永远是同一个)和一个获得该实例的方法（必须是<strong>静态方法</strong>，通常使用getInstance这个名称）；当我们调用这个方法时，如果类持有的<strong>引用不为空</strong>就返回这个引用，如果类保持的引用为空就创建该类的实例并将实例的引用赋予该类保持的引用；同时我们还将该类的构造函数定义为私有方法，这样其他处的代码就无法通过调用该类的构造函数来实例化该类的对象，只有通过该类提供的静态方法来得到该类的唯一实例&lt;/p&gt;\n</blockquote>\n&lt;p&gt;原来，singleton属性只是一个引用，可以简单的看做是一个地址，并且这个属性是<strong>类属性</strong>而非实例属性，只是可以通过实例访问到罢了。之所以用__new__是因为它返回的就是一个类的实例，恰恰符合返回类的需求。&lt;/p&gt;\n&lt;p&gt;关于单例模式的理解大概就是如此了。这里我并没有讲它的定义，因为定义很简单，即<strong>一个类只能拥有一个实例</strong>&lt;/p&gt;','直到今天，我才真正懂了单例模式，以前只是单纯会写它，没明白为何返回一个类中的属性，就是实例了，不明白为何实例自己还包含自己本身。在读requests的源码时，有一段关于管理权限的代码是这样的\n\n<pre>\n	class AuthManager(object):\n		def __new__(cls):\n			singleton = cls.__dict__.get(\'__singleton__\')\n			if singleton is not None:\n				return singleton\n			\n			cls.__singleton__ = singleton = object.__new__(cls)\n			return singleton\n</pre>\n如果new一个实例\n> auth = AuthManager()\n\n有一点我不明白的就是，为何auth对象中包含自身(\\_\\_singleton\\_\\_属性)，对象怎么包含自己了？后来在网上查阅了很多资料，基本都是讲怎么写单例模式，但是没讲它为何是这样的，可能是我比较笨吧。后来我查了它的定义相关的描述才懂。这是让我彻底明白的描述\n>实现单例模式的思路是：一个类能返回对象一个**引用**(永远是同一个)和一个获得该实例的方法（必须是**静态方法**，通常使用getInstance这个名称）；当我们调用这个方法时，如果类持有的**引用不为空**就返回这个引用，如果类保持的引用为空就创建该类的实例并将实例的引用赋予该类保持的引用；同时我们还将该类的构造函数定义为私有方法，这样其他处的代码就无法通过调用该类的构造函数来实例化该类的对象，只有通过该类提供的静态方法来得到该类的唯一实例\n\n原来，singleton属性只是一个引用，可以简单的看做是一个地址，并且这个属性是**类属性**而非实例属性，只是可以通过实例访问到罢了。之所以用\\_\\_new\\_\\_是因为它返回的就是一个类的实例，恰恰符合返回类的需求。\n\n关于单例模式的理解大概就是如此了。这里我并没有讲它的定义，因为定义很简单，即**一个类只能拥有一个实例**\n\n\n',1,'python,设计模式',1477016065,0,22,0,1,1),(117,'一天两道Python面试题:语言特性(六)','<h3>问题一:谈谈对面向切面编程(AOP)的理解</h3>\n<p>下面是<strong>AOP</strong>的定义</p>\n<blockquote>\n<p>在运行时，动态地将代码切入到类的指定方法、指定位置上的编程思想就是面向切面的编程</p>\n</blockquote>\n<p>装饰器就是面向切面编程的一个典型例子。装饰器模式是设计模式的一种，它的定义</p>\n<blockquote>\n<p>装饰器就是把其他函数作为参数的函数</p>\n</blockquote>\n<p>理解Python的装饰器前，需要知道关于它的基本知识</p>\n<ol>\n<li>在Python中，一切都是对象，所以函数也是对象</li>\n<li>对象可以赋值给另一个变量，并且可以在别的函数中定义</li>\n<li>函数可以当做变量return,并且可以直接作为参数传递</li>\n</ol>\n<p>这就意味着一个函数可以返回另一个函数，比如\n<pre>\ndef test_dec(func):\n    def wraps():\n        return \'start \' + func() + \' end\'\n    return wraps</p>\n<p>def foo():\n    return \'hello decrecotr\'</p>\n<p>if __name__ == \'__main__\':\n    new_foo = test_dec(foo)\n    print(new_foo)\n    print(new_foo())\n</pre></p>\n<p>结果</p>\n<blockquote>\n<p><function test_dec.<locals>.wraps at 0x000001C73E2B9A60&gt;</p>\n<p>start hello decrecotr end</p>\n</blockquote>\n<p>那么上面的代码和装饰器有什么关系呢？我们在定义<strong>foo()</strong>的时候使用<em>@test_dec</em>来试试，代码如下\n<pre>\ndef test_dec(func):\n    def wraps():\n        return \'start \' + func() + \' end\'\n    return wraps</p>\n<p>@test_dec\ndef foo():\n    return \'hello decrecotr\'</p>\n<p>if __name__ == \'__main__\':\n    r = foo()\n    print(r)\n</pre></p>\n<p>结果</p>\n<blockquote>\n<p>start hello decrecotr end</p>\n</blockquote>\n<p>和上面的<strong>new_foo()</strong>运算结果一致。其实，test_dec()就是一个装饰器函数。而使用<em>@func_dec</em>就相当于</p>\n<blockquote>\n<p>foo = test_dec(foo)</p>\n</blockquote>\n<p>如果是两个或者多个装饰器函数呢，运行顺序如何？代码如下\n<pre>\ndef test_dec_begin(func):\n    def wraps():\n        print(\'Begin:I am begin_func\')\n        func()\n        print(\'End:I am begin_func\')\n    return wraps</p>\n<p>def test_dec_after(func):\n    def wraps():\n        print(\'Begin:I am after_func\')\n        func()\n        print(\'End:I am after_func\')\n    return wraps</p>\n<p>@test_dec_begin\n@test_dec_after\ndef foo():\n     print(\'hello decrecotr\')</p>\n<p>foo()\n</pre>\n结果\n<pre>\nBegin:I am begin_func\nBegin:I am after_func\nhello decrecotr\nEnd:I am after_func\nEnd:I am begin_func\n</pre></p>\n<p>其实，它就相当于</p>\n<blockquote>\n<p>foo = test_dec_begin(test_dec_after(foo))</p>\n<p>foo()</p>\n</blockquote>\n<p>关于装饰器的知识，还有一些，比如让装饰器传递参数、装饰器类等，这些就不在这里做说明了</p>\n<h3>问题二：Python中重载</h3>\n<p>函数重载主要是为了解决两个问题\n- 可变参数类型\n- 可变参数个数</p>\n<p>一个设计的基本原则是，仅仅当两个函数除了参数类型和参数个数不同以外，其功能是完全相同的，此时才使用函数重载，如果函数功能不同，那么不应该使用重载，而是使用一个名字不同的函数</p>\n<p>对于参数类型不同的情况，Python根本不需要处理，如果函数功能相同，那么不同参数类型在Python中很可能是相同的代码，没必要做成两个不同函数。</p>\n<p>如果参数个数不同呢？Python中使用缺省参数即可解决问题</p>\n<p>鉴于情况1和情况2，Python自然不需要函数重载了。</p>','### 问题一:谈谈对面向切面编程(AOP)的理解\n\n下面是**AOP**的定义\n> 在运行时，动态地将代码切入到类的指定方法、指定位置上的编程思想就是面向切面的编程\n\n装饰器就是面向切面编程的一个典型例子。装饰器模式是设计模式的一种，它的定义\n> 装饰器就是把其他函数作为参数的函数\n\n理解Python的装饰器前，需要知道关于它的基本知识\n\n1. 在Python中，一切都是对象，所以函数也是对象\n2. 对象可以赋值给另一个变量，并且可以在别的函数中定义\n3. 函数可以当做变量return,并且可以直接作为参数传递\n\n这就意味着一个函数可以返回另一个函数，比如\n<pre>\ndef test_dec(func):\n    def wraps():\n        return \'start \' + func() + \' end\'\n    return wraps\n\n\ndef foo():\n    return \'hello decrecotr\'\n\nif \\_\\_name\\_\\_ == \'\\_\\_main\\_\\_\':\n    new_foo = test_dec(foo)\n    print(new_foo)\n	print(new_foo())\n</pre>\n\n结果\n> <function test_dec.<locals>.wraps at 0x000001C73E2B9A60>\n\n> start hello decrecotr end\n\n那么上面的代码和装饰器有什么关系呢？我们在定义**foo()**的时候使用*@test_dec*来试试，代码如下\n<pre>\ndef test_dec(func):\n    def wraps():\n        return \'start \' + func() + \' end\'\n    return wraps\n\n\n@test_dec\ndef foo():\n    return \'hello decrecotr\'\n\nif \\_\\_name\\_\\_ == \'\\_\\_main\\_\\_\':\n    r = foo()\n    print(r)\n</pre>\n\n结果\n> start hello decrecotr end\n\n和上面的**new_foo()**运算结果一致。其实，test_dec()就是一个装饰器函数。而使用*@func_dec*就相当于\n> foo = test_dec(foo)\n\n如果是两个或者多个装饰器函数呢，运行顺序如何？代码如下\n<pre>\ndef test_dec_begin(func):\n    def wraps():\n        print(\'Begin:I am begin_func\')\n        func()\n        print(\'End:I am begin_func\')\n    return wraps\n\n\ndef test_dec_after(func):\n    def wraps():\n        print(\'Begin:I am after_func\')\n        func()\n        print(\'End:I am after_func\')\n    return wraps\n\n\n@test_dec_begin\n@test_dec_after\ndef foo():\n     print(\'hello decrecotr\')\n\n\nfoo()\n</pre>\n结果\n<pre>\nBegin:I am begin_func\nBegin:I am after_func\nhello decrecotr\nEnd:I am after_func\nEnd:I am begin_func\n</pre>\n\n其实，它就相当于\n> foo = test_dec_begin(test_dec_after(foo))\n\n> foo()\n\n关于装饰器的知识，还有一些，比如让装饰器传递参数、装饰器类等，这些就不在这里做说明了\n\n### 问题二：Python中重载\n\n函数重载主要是为了解决两个问题\n- 可变参数类型\n- 可变参数个数\n\n一个设计的基本原则是，仅仅当两个函数除了参数类型和参数个数不同以外，其功能是完全相同的，此时才使用函数重载，如果函数功能不同，那么不应该使用重载，而是使用一个名字不同的函数\n\n对于参数类型不同的情况，Python根本不需要处理，如果函数功能相同，那么不同参数类型在Python中很可能是相同的代码，没必要做成两个不同函数。\n\n如果参数个数不同呢？Python中使用缺省参数即可解决问题\n\n鉴于情况1和情况2，Python自然不需要函数重载了。\n\n',1,'python,面试题',1477223827,0,27,0,1,1),(118,'一天两道Python面试题:语言特性(七)','&lt;h3&gt;问题一：新式类和旧式类&lt;/h3&gt;\n&lt;p&gt;从Python2.2开始，如果类从object或者内置类型继承，那么就是新式类；如果没有继承任何类，那么就是旧式类。在Python3.x中，类全部是新式类，不管类是从object或者内置基本类型继承，还是采用旧式类的写法。&lt;/p&gt;\n&lt;p&gt;我们先看看旧式类和新式类在Python2.x中的属性\n&lt;pre&gt;\nclass OldClass:\n    pass&lt;/p&gt;\n&lt;p&gt;class NewClass(object):\n    pass&lt;/p&gt;\n&lt;p&gt;dir(OldClass)\n&gt;&gt;&gt;[\'__doc__\', \'__module__\']&lt;/p&gt;\n&lt;p&gt;dir(NewClass)\n&gt;&gt;&gt;[\'__class__\', \'__delattr__\', \'__dict__\', \'__doc__\', \'__format__\', \'__getattribute__\', \'__hash__\', \'__init__\', \'__module__\', \'__new__\', \'__reduce__\', \'__reduce_ex__\', \'__repr__\', \'__setattr__\', \'__sizeof__\', \'__str__\', \'__subclasshook__\', \'__weakref__\']\n&lt;/pre&gt;&lt;/p&gt;\n&lt;p&gt;可以看到新式类比旧式类新增了很多属性，比较重要的特性有&lt;/p&gt;\n<ul>\n<li>\n&lt;p&gt;super方法的改变&lt;/p&gt;\n<blockquote>\n&lt;p&gt;super(class, self)-&gt;super()&lt;/p&gt;\n</blockquote>\n</li>\n<li>\n&lt;p&gt;MRO改变了,拥有__mro__属性&lt;/p&gt;\n<blockquote>\n&lt;p&gt;深度优先(MRO)-&gt;广度优先(C3 MRO)&lt;/p&gt;\n</blockquote>\n</li>\n<li>\n&lt;p&gt;增加了__slots__&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;新式类不能被手动抛出，除非是继承于<strong>Exception</strong>类&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;增加了descriptor功能&lt;/p&gt;\n</li>\n</ul>\n&lt;h3&gt;问题二：__new__和__init__的区别&lt;/h3&gt;\n<ol>\n<li>\n&lt;p&gt;__new__是一个静态方法，而__init__是一个实例方法&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;__new__会返回创建的实例，而__init__什么都不会返回&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;只有在调用__new__创建了一个cls的实例后__init__才能被调用&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;我们可以使用__metaclass__来创建类，使用__new__创建实例，使用__init__将创建的实例初始化&lt;/p&gt;\n</li>\n</ol>','### 问题一：新式类和旧式类\n\n从Python2.2开始，如果类从object或者内置类型继承，那么就是新式类；如果没有继承任何类，那么就是旧式类。在Python3.x中，类全部是新式类，不管类是从object或者内置基本类型继承，还是采用旧式类的写法。\n\n我们先看看旧式类和新式类在Python2.x中的属性\n<pre>\nclass OldClass:\n	pass\n\n\nclass NewClass(object):\n	pass\n\ndir(OldClass)\n\\>\\>\\>[\'\\_\\_doc\\_\\_\', \'\\_\\_module\\_\\_\']\n\ndir(NewClass)\n\\>\\>\\>[\'\\_\\_class\\_\\_\', \'\\_\\_delattr\\_\\_\', \'\\_\\_dict\\_\\_\', \'\\_\\_doc\\_\\_\', \'\\_\\_format\\_\\_\', \'\\_\\_getattribute\\_\\_\', \'\\_\\_hash\\_\\_\', \'\\_\\_init\\_\\_\', \'\\_\\_module\\_\\_\', \'\\_\\_new\\_\\_\', \'\\_\\_reduce\\_\\_\', \'\\_\\_reduce\\_ex\\_\\_\', \'\\_\\_repr\\_\\_\', \'\\_\\_setattr\\_\\_\', \'\\_\\_sizeof\\_\\_\', \'\\_\\_str\\_\\_\', \'\\_\\_subclasshook\\_\\_\', \'\\_\\_weakref\\_\\_\']\n</pre>\n\n可以看到新式类比旧式类新增了很多属性，比较重要的特性有\n\n- super方法的改变\n>super(class, self)->super()\n\n- MRO改变了,拥有\\_\\_mro\\_\\_属性\n> 深度优先(MRO)->广度优先(C3 MRO)\n\n- 增加了\\_\\_slots\\_\\_\n\n- 新式类不能被手动抛出，除非是继承于**Exception**类\n\n- 增加了descriptor功能\n\n### 问题二：\\_\\_new\\_\\_和\\_\\_init\\_\\_的区别\n\n1. \\_\\_new\\_\\_是一个静态方法，而\\_\\_init\\_\\_是一个实例方法\n\n2. \\_\\_new\\_\\_会返回创建的实例，而\\_\\_init\\_\\_什么都不会返回\n\n3. 只有在调用\\_\\_new\\_\\_创建了一个cls的实例后\\_\\_init\\_\\_才能被调用\n\n4. 我们可以使用\\_\\_metaclass\\_\\_来创建类，使用\\_\\_new\\_\\_创建实例，使用\\_\\_init\\_\\_将创建的实例初始化',1,'python,面试题',1477397488,0,18,0,1,1),(119,'一天两道Python面试题：语言特性(八)','<h3>问题一：Python中的作用域</h3>\n<p>Python中，一个变量的作用域总是由在代码中被赋值的地方所决定的。</p>\n<p>当 Python 遇到一个变量的话他会按照这样的顺序进行搜索：</p>\n<p>本地作用域（Local）→当前作用域被嵌入的本地作用域（Enclosing locals）→全局/模块作用域（Global）→内置作用域（Built-in），即<strong>LEGB规则</strong></p>\n<h3>问题二：全局解释锁GIL</h3>\n<p>线程全局锁(Global Interpreter Lock),即Python为了保证线程安全而采取的独立线程运行的限制,说白了就是一个核只能在同一时间运行一个线程.</p>\n<p>解决办法就是多进程和下面的协程(协程也只是单CPU,但是能减小切换代价提升性能).</p>','### 问题一：Python中的作用域\n\nPython中，一个变量的作用域总是由在代码中被赋值的地方所决定的。\n\n当 Python 遇到一个变量的话他会按照这样的顺序进行搜索：\n\n本地作用域（Local）→当前作用域被嵌入的本地作用域（Enclosing locals）→全局/模块作用域（Global）→内置作用域（Built-in），即**LEGB规则**\n\n### 问题二：全局解释锁GIL\n\n线程全局锁(Global Interpreter Lock),即Python为了保证线程安全而采取的独立线程运行的限制,说白了就是一个核只能在同一时间运行一个线程.\n\n解决办法就是多进程和下面的协程(协程也只是单CPU,但是能减小切换代价提升性能).',1,'python,面试题',1477471558,0,17,0,1,1),(120,'一天两道Python面试题：语言特性(九)','<h3>问题一：协程</h3>\n<p>协程是进程和线程的升级版，与多线程和多进程相比，优势如下：</p>\n<ul>\n<li>\n<p>进程和线程都面临着状态切换，而协程中子程序(又称函数)的切换是由程序自身控制，因此没有线程切换的开销</p>\n</li>\n<li>\n<p>协程是单线程，不用像多线程那样需要加锁，也没有共享变量冲突</p>\n</li>\n</ul>\n<p>为了充分利用多核优势，可以使用协程+多线程的方式</p>\n<p>Python对协程的支持是通过生成器的方式实现的。生成器有两种生成方式</p>\n<ul>\n<li>\n<p>生成器表达式，比如</p>\n<blockquote>\n<p>g = (x for x in range(100))  如果把（）换为[]就是列表生成式了</p>\n</blockquote>\n</li>\n<li>\n<p>使用<strong>yield</strong>关键字,比如\n<pre>\n    def gen():\n        for i in range(100):\n            yield i\n            print(i)\n</pre></p>\n</li>\n</ul>\n<p>对生成器的调用可以采用<strong>next()</strong>，也可以使用for...in...的方式，如果是第二种方式，每次调用返回的是yield后的变量。之所以可以用next()和for...in...，是因为生成器本身也实现了<strong>迭代器协议</strong></p>\n<p><strong>yield</strong>是一个神奇的关键字，我在这里详细讲讲</p>\n<p>和yield有关的一共有三个词，<strong>yield</strong>,<strong>yield from</strong>, <strong>send()</strong>,下面是对它们的具体理解。</p>\n<p>先说说<strong>yield</strong>吧，以上面的代码为例</p>\n<blockquote>\n<p>g = gen() </p>\n</blockquote>\n<p>此时 g就是一个生成器，由于它实现了迭代器协议，我们可以用next(g)调用它</p>\n<blockquote>\n<p>a = next(g)</p>\n<p>print(a)</p>\n<p>>>> 0</p>\n<p>b = next(g)</p>\n<p>>>> 0</p>\n<p>print(b)</p>\n<p>>>> 1</p>\n</blockquote>\n<p>从上面我们可以看出，我们第一次调用生成器的时候，它在yield处返回了0，程序<strong>中端了</strong>执行，并且<strong>保存了当前的上下文环境</strong>,再次调用<em>next(g)</em>，程序打印出了 0,说明它是从<strong>yield之后继续执行</strong>,再次执行到yield处返回了1，以此往复...</p>\n<p>到现在，大家应该都明白包含yield的生成器的执行过程了吧.</p>\n<p>现在再来看看send()方法吧，比如</p>\n<blockquote>\n<p>val = yield i</p>\n</blockquote>\n<p>通过上面的讲解，我们已经明白了程序运行到yield表达式就会<strong>\'暂停\'</strong>,并把值返回，返回的值可以通过next()得到，那么在yield表达式前面用等式是什么意思？这时候就必须说到send()方法了，send()方法用于<strong>启动或者继续一个中断的生成器</strong>，它必须带参数，对于一个<strong>刚启动的生成器</strong>,使用send(None),send传递的参数就是 = 左边的变量，比如g.send(5), 那么val就为5.下面是生产者消费者的示例代码：</p>\n<pre>\ndef consumer():\n    r = \'\'\n    while True:\n        n = yield r\n        if not n:\n            return\n        print(\'[CONSUMER] Consuming %s...\' % n)\n        r = \'200 OK\'\n\ndef produce(c):\n    c.send(None)\n    n = 0\n    while n < 5:\n        n = n + 1\n        print(\'[PRODUCER] Producing %s...\' % n)\n        r = c.send(n)\n        print(\'[PRODUCER] Consumer return: %s\' % r)\n    c.close()\n\nc = consumer()\nproduce(c)\n</pre>\n\n<p>解释一下代码过程，首先是生成一个生成器。然后</p>\n<blockquote>\n<p>c.send(None)</p>\n</blockquote>\n<p>启动一个生成器，也就是会运行生成器中的代码，和<strong>next(c)作用相同</strong>。当进入<em>while True</em>语句块，由于<em>yield r</em>，所以生成器会‘暂停’，直接运行‘主函数’，主函数进入while语句快后</p>\n<blockquote>\n<p>r = c.send(n)</p>\n</blockquote>\n<p>send()方法会恢复暂停的生成器，使其继续执行，由于send()发送了值进入生成器，所以可以通过\"n=\"来获取，这时候生成器中的循环运行到下一次yield,生成器又中断执行，并且将yield返回的值传递给r.然后重复这个过程...最后关闭生成器</p>\n<p>上面的生产者消费者例子就是一个协程，可以看出，子程序的切换完全由程序自身控制，并且一直是单线程，也不存在共享变量(这里是n)冲突的情况。可见协程的好处。大家需要通过这段程序弄清楚yield和send()在各个子程序中对于中断与恢复执行的作用</p>\n<p>下面再说说yield from 吧。</p>\n<blockquote>\n<p>yield from会把内嵌的generator输出作为当前generator输出的一部分</p>\n</blockquote>\n<p>比如\n<pre>\ndef g(x):\n     yield from range(x, 0, -1)\n     yield from range(x)\n</pre></p>\n<p>list(g(5))\n结果</p>\n<blockquote>\n<p>>>> [5, 4, 3, 2, 1, 0, 1, 2, 3, 4]</p>\n</blockquote>\n<p>下面两个生成器是相同的\n<pre>\ndef g1(x):\n    for i in range(x):\n        yield i</p>\n<p>def g2(x):\n    yield from range(x)\n</pre></p>\n<p>从上面可以看出，yield 后面跟的是单个变量，而yield from 后面跟的确实一个可迭代对象，并且把内部的生成器作为外部生成器的一部分</p>\n<p>yield from 配合可协程方法使用。通俗理解：</p>\n<blockquote>\n<p>yield from 是一个标记, 告诉程序, 这个事情估计还得好一会才能搞完. 你先去做别的, 这边完事了再继续.就好比我在玩纸牌接龙, 同时又要下载一部电影. 下电影要两个小时. 下电影这个事就可以yield from 一下. 不至于下载的时候啥也不干就盯着迅雷发呆, yield from之后, 就可以把下载最小化, 继续玩纸牌接龙. 等电影下载好了, 再回来看电影.</p>\n</blockquote>\n<p>其实这个就是异步IO的运用了</p>\n<p>此外，关于python的异步IO,python3.5支持async/await，大家有兴趣可以看看</p>','### 问题一：协程\n\n协程是进程和线程的升级版，与多线程和多进程相比，优势如下：\n\n- 进程和线程都面临着状态切换，而协程中子程序(又称函数)的切换是由程序自身控制，因此没有线程切换的开销\n\n- 协程是单线程，不用像多线程那样需要加锁，也没有共享变量冲突\n\n为了充分利用多核优势，可以使用协程+多线程的方式\n\nPython对协程的支持是通过生成器的方式实现的。生成器有两种生成方式\n\n- 生成器表达式，比如\n> g = (x for x in range(100))  如果把（）换为[]就是列表生成式了\n\n- 使用**yield**关键字,比如\n<pre>\n	def gen():\n		for i in range(100):\n			yield i\n			print(i)\n</pre>\n\n对生成器的调用可以采用**next()**，也可以使用for...in...的方式，如果是第二种方式，每次调用返回的是yield后的变量。之所以可以用next()和for...in...，是因为生成器本身也实现了**迭代器协议**\n\n**yield**是一个神奇的关键字，我在这里详细讲讲\n\n和yield有关的一共有三个词，**yield**,**yield from**, **send()**,下面是对它们的具体理解。\n\n先说说**yield**吧，以上面的代码为例\n> g = gen() \n\n此时 g就是一个生成器，由于它实现了迭代器协议，我们可以用next(g)调用它\n> a = next(g)\n\n> print(a)\n\n> \\>\\>\\> 0\n\n> b = next(g)\n\n> \\>\\>\\> 0\n\n> print(b)\n\n> \\>\\>\\> 1\n\n从上面我们可以看出，我们第一次调用生成器的时候，它在yield处返回了0，程序**中端了**执行，并且**保存了当前的上下文环境**,再次调用*next(g)*，程序打印出了 0,说明它是从**yield之后继续执行**,再次执行到yield处返回了1，以此往复...\n\n到现在，大家应该都明白包含yield的生成器的执行过程了吧.\n\n现在再来看看send()方法吧，比如\n> val = yield i\n\n通过上面的讲解，我们已经明白了程序运行到yield表达式就会**\'暂停\'**,并把值返回，返回的值可以通过next()得到，那么在yield表达式前面用等式是什么意思？这时候就必须说到send()方法了，send()方法用于**启动或者继续一个中断的生成器**，它必须带参数，对于一个**刚启动的生成器**,使用send(None),send传递的参数就是 = 左边的变量，比如g.send(5), 那么val就为5.下面是生产者消费者的示例代码：\n\n<pre>\ndef consumer():\n    r = \'\'\n    while True:\n        n = yield r\n        if not n:\n            return\n        print(\'[CONSUMER] Consuming %s...\' % n)\n        r = \'200 OK\'\n\ndef produce(c):\n    c.send(None)\n    n = 0\n    while n < 5:\n        n = n + 1\n        print(\'[PRODUCER] Producing %s...\' % n)\n        r = c.send(n)\n        print(\'[PRODUCER] Consumer return: %s\' % r)\n    c.close()\n\nc = consumer()\nproduce(c)\n</pre>\n\n解释一下代码过程，首先是生成一个生成器。然后\n> c.send(None)\n\n启动一个生成器，也就是会运行生成器中的代码，和**next(c)作用相同**。当进入*while True*语句块，由于*yield r*，所以生成器会‘暂停’，直接运行‘主函数’，主函数进入while语句快后\n> r = c.send(n)\n\nsend()方法会恢复暂停的生成器，使其继续执行，由于send()发送了值进入生成器，所以可以通过\"n=\"来获取，这时候生成器中的循环运行到下一次yield,生成器又中断执行，并且将yield返回的值传递给r.然后重复这个过程...最后关闭生成器\n\n上面的生产者消费者例子就是一个协程，可以看出，子程序的切换完全由程序自身控制，并且一直是单线程，也不存在共享变量(这里是n)冲突的情况。可见协程的好处。大家需要通过这段程序弄清楚yield和send()在各个子程序中对于中断与恢复执行的作用\n\n下面再说说yield from 吧。\n> yield from会把内嵌的generator输出作为当前generator输出的一部分\n\n比如\n<pre>\ndef g(x):\n     yield from range(x, 0, -1)\n     yield from range(x)\n</pre>\n\nlist(g(5))\n结果\n> \\>\\>\\> [5, 4, 3, 2, 1, 0, 1, 2, 3, 4]\n\n下面两个生成器是相同的\n<pre>\ndef g1(x):\n    for i in range(x):\n        yield i\n\ndef g2(x):\n    yield from range(x)\n</pre>\n\n从上面可以看出，yield 后面跟的是单个变量，而yield from 后面跟的确实一个可迭代对象，并且把内部的生成器作为外部生成器的一部分\n\nyield from 配合可协程方法使用。通俗理解：\n>yield from 是一个标记, 告诉程序, 这个事情估计还得好一会才能搞完. 你先去做别的, 这边完事了再继续.就好比我在玩纸牌接龙, 同时又要下载一部电影. 下电影要两个小时. 下电影这个事就可以yield from 一下. 不至于下载的时候啥也不干就盯着迅雷发呆, yield from之后, 就可以把下载最小化, 继续玩纸牌接龙. 等电影下载好了, 再回来看电影.\n\n其实这个就是异步IO的运用了\n\n此外，关于python的异步IO,python3.5支持async/await，大家有兴趣可以看看\n\n',1,'python,面试题',1477560275,0,12,0,1,1),(121,'一天两道Python面试题:语言特性(10)','<h3>问题一：闭包</h3>\n<blockquote>\n<p>闭包是函数式编程的重要语法结构。同样是一种组织代码的结构，提高了代码的可重复使用性。当一个内嵌函数引用外部作用域的变量，我们就会得到一个闭包</p>\n</blockquote>\n<p>创建一个闭包的条件</p>\n<ul>\n<li>\n<p>必须有一个内嵌函数</p>\n</li>\n<li>\n<p>内嵌函数必须引用外部函数中的变量</p>\n</li>\n<li>\n<p>外部函数的返回值必须是内嵌函数</p>\n</li>\n</ul>\n<p>对于闭包的理解，我们要理解先前讲过的<strong>LEGB</strong>规则， 其实闭包和装饰器有些类似，都有内嵌函数，并且都会返回函数，其实装饰器可以看做是闭包的一种，只不过引用的变量的类型是函数对象</p>\n<h3>问题二： 匿名函数</h3>\n<blockquote>\n<p>通常是在需要一个函数，又不想费神去命名一个函数的场合下使用，即匿名函数。在Python中，匿名函数是通过<strong>lambda</strong>关键字实现的</p>\n</blockquote>\n<p>比如</p>\n<blockquote>\n<p>f = lambda x: x*x</p>\n</blockquote>\n<p>这里的lambda 表达式将返回一个函数对象，并且可以使用一个变量指向该函数，比如我们调用f(2)，结果</p>\n<blockquote>\n<p>>>> 4</p>\n</blockquote>\n<p>现在大家都明白了吧，\":\"左边的是参数，而右边的表达式是返回值。并且可以使用多个参数，比如</p>\n<blockquote>\n<p>f = lambda x,y: x*y</p>\n</blockquote>\n<p>这个函数将接受两个参数，并返回它们的积</p>\n<p>匿名函数有啥好处呢？</p>\n<ol>\n<li>\n<p>不会定义污染环境的函数。比如我们需要一个返回平方的函数，但是这个函数只会使用一次，那么我们就可以在这种场景下使用匿名函数</p>\n</li>\n<li>\n<p>代码更加简短易读。比如</p>\n<blockquote>\n<p>map(lambda x:x*x, [y for y in range(10)])</p>\n</blockquote>\n</li>\n</ol>\n<p>这段代码返回一个10以内所有数的平方组成的列表，是不是很简洁明了呢？其实，关于这一点，不同的人有不同的看法，有的就不喜欢这么用，因为感觉它更抽象晦涩。所以怎么用，还是取决于自身</p>','### 问题一：闭包\n\n>闭包是函数式编程的重要语法结构。同样是一种组织代码的结构，提高了代码的可重复使用性。当一个内嵌函数引用外部作用域的变量，我们就会得到一个闭包\n\n创建一个闭包的条件\n\n- 必须有一个内嵌函数\n\n- 内嵌函数必须引用外部函数中的变量\n\n- 外部函数的返回值必须是内嵌函数\n\n对于闭包的理解，我们要理解先前讲过的**LEGB**规则， 其实闭包和装饰器有些类似，都有内嵌函数，并且都会返回函数，其实装饰器可以看做是闭包的一种，只不过引用的变量的类型是函数对象\n\n### 问题二： 匿名函数\n\n> 通常是在需要一个函数，又不想费神去命名一个函数的场合下使用，即匿名函数。在Python中，匿名函数是通过**lambda**关键字实现的\n\n比如\n> f = lambda x: x*x\n\n这里的lambda 表达式将返回一个函数对象，并且可以使用一个变量指向该函数，比如我们调用f(2)，结果\n> \\>\\>\\> 4\n\n现在大家都明白了吧，\":\"左边的是参数，而右边的表达式是返回值。并且可以使用多个参数，比如\n> f = lambda x,y: x*y\n\n这个函数将接受两个参数，并返回它们的积\n\n匿名函数有啥好处呢？\n\n1. 不会定义污染环境的函数。比如我们需要一个返回平方的函数，但是这个函数只会使用一次，那么我们就可以在这种场景下使用匿名函数\n\n2. 代码更加简短易读。比如\n> map(lambda x:x*x, [y for y in range(10)])\n\n这段代码返回一个10以内所有数的平方组成的列表，是不是很简洁明了呢？其实，关于这一点，不同的人有不同的看法，有的就不喜欢这么用，因为感觉它更抽象晦涩。所以怎么用，还是取决于自身',1,'python,面试题',1477659002,0,14,0,1,1),(122,'一天两道Python面试题:语言特性(11)','&lt;h3&gt;问题一：Python函数式编程&lt;/h3&gt;\n&lt;p&gt;函数式编程的三个特性&lt;/p&gt;\n<ul>\n<li>\n&lt;p&gt;immutable data 不可变数据：默认变量是不可变的，如果需要改变变量，就需要把变量copy出去修改&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;first class functions: 函数可以当变量来使用，也就是说，函数可以像变量一样被创建，修改，并且当成变量一样传递，返回或者是在函数中嵌套函数&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;尾递归优化：每次递归时都会重用stack,这样能够提升性能，这个需要编译器或者语言支持，Python就不支持&lt;/p&gt;\n</li>\n</ul>\n&lt;p&gt;函数式编程的几个技术&lt;/p&gt;\n<ul>\n<li>\n&lt;p&gt;map&amp;reduce 这个在python中也有体现，就不说了&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;pipeline 把函数实例当成一个一个的action,把一组action放到一个数组或者列表中，然后把数据传给这个action list,数据就像pipeline一样顺序的被各个函数操作，得到我们想要的结果&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;递归 递归的精髓是描述问题，这个也正是函数式编程的精髓&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;currying 把一个函数的多个参数分解成多个函数，然后把函数多层封装起来，每层函数都返回一个函数去接收下一个参数&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;高阶函数 把函数当参数，把传入的函数做成一个封装，然后返回这个封装函数，现象就是函数传入传出，像面向对象的对象满天飞一样&lt;/p&gt;\n</li>\n</ul>\n&lt;p&gt;python对函数式编程支持力度比较小，常用的有lambda、map&amp;reduce、filter()等函数&lt;/p&gt;\n&lt;h3&gt;问题二：Python中的垃圾回收&lt;/h3&gt;\n&lt;p&gt;Python中主要采用引用计数来跟踪和回收垃圾，以标记清除来解决循环引用问题，通过分代回收以空间换时间来提高垃圾回收效率&lt;/p&gt;\n&lt;p&gt;1.引用计数&lt;/p&gt;\n<blockquote>\n&lt;p&gt;当对象有一个新引用时，它的引用计数就加1，当引用被删除或指向了别的对象时，它的引用计数就减一，直到引用计数为0时，该对象的生命就结束了&lt;/p&gt;\n</blockquote>\n&lt;p&gt;以前我有一点不能理解，当创建一个对象的时候，它的引用为1，如果我们不操作它，从某个层面上说它就是垃圾了，Python应该回收它，但是它的引用却有1，如果我们不手动调用del操作，怎么回收呢？后来我才知道引用有一个<strong>生命周期</strong>，过了它的生命周期它的引用也会减1&lt;/p&gt;\n&lt;p&gt;引用计数的优点&lt;/p&gt;\n<ul>\n<li>简单</li>\n</ul>\n&lt;p&gt;缺点：&lt;/p&gt;\n<ul>\n<li>循环引用对象无法回收</li>\n</ul>\n&lt;p&gt;容易产生循环引用的包括<strong>list,dict,class</strong>等对象&lt;/p&gt;\n&lt;p&gt;在Python中，我们可以通过&lt;/p&gt;\n<blockquote>\n&lt;p&gt;sys.getrefcount(obj)&lt;/p&gt;\n</blockquote>\n&lt;p&gt;获取一个对象的引用计数，它比实际的引用计数多加了1，因为我们调用obj这个引用其实也是多了一个引用计数，所以会比我们认为的要多1&lt;/p&gt;\n&lt;p&gt;2.标记清除&lt;/p&gt;\n<blockquote>\n&lt;p&gt;标记清除法主要用于解决循环引用问题。它的主要过程如下\n- 寻找gc root: gc root为全局引用或者函数栈上的引用\n- 标记阶段：从gc root出发，通过每一个引用能到达的对象，就是 reachable对象\n- 清除阶段：再次遍历，如果发现某个对象没有标记为reachable,则删除&lt;/p&gt;\n</blockquote>\n&lt;p&gt;在垃圾回收的时候，会暂停整个应用程序，等标记清除结束后才恢复整个应用程序的运行&lt;/p&gt;\n&lt;p&gt;3.分代回收&lt;/p&gt;\n<blockquote>\n&lt;p&gt;Python中共有三个代，当各个代中的对象数量达到了阈值的时候就会触发Python的垃圾回收，各个代的数量可以通过 <em>gc.get_threshold()查看</em>&lt;/p&gt;\n</blockquote>\n&lt;p&gt;分代收集的思想就是活的越久的对象，就越不是垃圾，回收的频率就应该越低。所以当Python发现经过几次垃圾回收该对象都是reachable时，就将该对象移入二代中，以此类推。那么Python中是如何检查各个代是否达到阈值呢？Python中每次会从二代(年老代)开始检查，如果二代中的对象大于阈值将同时回收2,1,0代的对象，如果一代满足条件，那么将回收1,0代的对象&lt;/p&gt;\n&lt;p&gt;ps: 以前如果类重写了__del__()方法的话，垃圾收集器可能不能成功的回收掉循环引用的对象，因为根据Python的定义，在释放该对象的占用的资源前需要调用该函数，如果a,b两个对象循环引用，并且都含有__del__()方法，那么在删除b之后，a.__del__()仍然会调用b对象，这样会造成异常，所以Python采取了较为保守的策略，对于自定义的类，如果存在__del__方法，Python会直接放到一个garbage列表中，这个列表在运行期间不能释放，所以会发生内存泄露。可以通过gc.garbage查看该garbage列表中不能释放的对象。但是通过测试，目前版本的Python并不存在此问题。也可以通过使用<strong>弱引用</strong>来解决该问题，好像Python3.x就是这样做的&lt;/p&gt;','### 问题一：Python函数式编程\n\n函数式编程的三个特性\n\n- immutable data 不可变数据：默认变量是不可变的，如果需要改变变量，就需要把变量copy出去修改\n\n- first class functions: 函数可以当变量来使用，也就是说，函数可以像变量一样被创建，修改，并且当成变量一样传递，返回或者是在函数中嵌套函数\n\n- 尾递归优化：每次递归时都会重用stack,这样能够提升性能，这个需要编译器或者语言支持，Python就不支持\n\n函数式编程的几个技术\n\n- map&reduce 这个在python中也有体现，就不说了\n\n- pipeline 把函数实例当成一个一个的action,把一组action放到一个数组或者列表中，然后把数据传给这个action list,数据就像pipeline一样顺序的被各个函数操作，得到我们想要的结果\n\n- 递归 递归的精髓是描述问题，这个也正是函数式编程的精髓\n\n- currying 把一个函数的多个参数分解成多个函数，然后把函数多层封装起来，每层函数都返回一个函数去接收下一个参数\n\n- 高阶函数 把函数当参数，把传入的函数做成一个封装，然后返回这个封装函数，现象就是函数传入传出，像面向对象的对象满天飞一样\n\npython对函数式编程支持力度比较小，常用的有lambda、map&reduce、filter()等函数\n\n### 问题二：Python中的垃圾回收\n\nPython中主要采用引用计数来跟踪和回收垃圾，以标记清除来解决循环引用问题，通过分代回收以空间换时间来提高垃圾回收效率\n\n1.引用计数\n> 当对象有一个新引用时，它的引用计数就加1，当引用被删除或指向了别的对象时，它的引用计数就减一，直到引用计数为0时，该对象的生命就结束了\n\n以前我有一点不能理解，当创建一个对象的时候，它的引用为1，如果我们不操作它，从某个层面上说它就是垃圾了，Python应该回收它，但是它的引用却有1，如果我们不手动调用del操作，怎么回收呢？后来我才知道引用有一个**生命周期**，过了它的生命周期它的引用也会减1\n\n引用计数的优点\n\n- 简单\n\n缺点：\n\n- 循环引用对象无法回收\n\n容易产生循环引用的包括**list,dict,class**等对象\n\n在Python中，我们可以通过\n> sys.getrefcount(obj)\n\n获取一个对象的引用计数，它比实际的引用计数多加了1，因为我们调用obj这个引用其实也是多了一个引用计数，所以会比我们认为的要多1\n\n2.标记清除\n> 标记清除法主要用于解决循环引用问题。它的主要过程如下\n- 寻找gc root: gc root为全局引用或者函数栈上的引用\n- 标记阶段：从gc root出发，通过每一个引用能到达的对象，就是 reachable对象\n- 清除阶段：再次遍历，如果发现某个对象没有标记为reachable,则删除\n\n在垃圾回收的时候，会暂停整个应用程序，等标记清除结束后才恢复整个应用程序的运行\n\n3.分代回收\n> Python中共有三个代，当各个代中的对象数量达到了阈值的时候就会触发Python的垃圾回收，各个代的数量可以通过 *gc.get_threshold()查看*\n\n分代收集的思想就是活的越久的对象，就越不是垃圾，回收的频率就应该越低。所以当Python发现经过几次垃圾回收该对象都是reachable时，就将该对象移入二代中，以此类推。那么Python中是如何检查各个代是否达到阈值呢？Python中每次会从二代(年老代)开始检查，如果二代中的对象大于阈值将同时回收2,1,0代的对象，如果一代满足条件，那么将回收1,0代的对象\n\n\nps: 以前如果类重写了\\_\\_del\\_\\_()方法的话，垃圾收集器可能不能成功的回收掉循环引用的对象，因为根据Python的定义，在释放该对象的占用的资源前需要调用该函数，如果a,b两个对象循环引用，并且都含有\\_\\_del\\_\\_()方法，那么在删除b之后，a.\\_\\_del\\_\\_()仍然会调用b对象，这样会造成异常，所以Python采取了较为保守的策略，对于自定义的类，如果存在\\_\\_del\\_\\_方法，Python会直接放到一个garbage列表中，这个列表在运行期间不能释放，所以会发生内存泄露。可以通过gc.garbage查看该garbage列表中不能释放的对象。但是通过测试，目前版本的Python并不存在此问题。也可以通过使用**弱引用**来解决该问题，好像Python3.x就是这样做的',1,'python,面试题',1477799390,0,13,0,1,1),(123,'一天两道Python面试题：语言特性(12)','<h3>问题一：Python的is和 == 的区别</h3>\n<blockquote>\n<p>is是对比地址，而 == 是对比值</p>\n</blockquote>\n<p>例子</p>\n<blockquote>\n<p>a = 10000</p>\n<p>b = 10000</p>\n<p>a is b</p>\n<p>>>&gt; False</p>\n<p>a == b</p>\n<p>>>> True</p>\n</blockquote>\n<p>更常用的是对None的判断，正确用法是 <strong>obj is None</strong> 而不是 <em>obj == None</em></p>\n<h3>问题二：Python的List</h3>\n<p>关于List常用的API</p>\n<blockquote>\n<p>append, insert, pop, remove, sort</p>\n</blockquote>\n<p>还有切片和迭代等特性</p>\n<p>如果想知道Cython中list的实现方式，请参考<a href=\"http://www.jianshu.com/p/J4U6rR\">这篇文章</a></p>','### 问题一：Python的is和 == 的区别\n\n> is是对比地址，而 == 是对比值\n\n例子\n> a = 10000\n\n> b = 10000\n\n> a is b\n\n> \\>\\>> False\n\n> a == b\n\n> \\>\\>\\> True\n\n更常用的是对None的判断，正确用法是 **obj is None** 而不是 *obj == None*\n\n### 问题二：Python的List\n\n关于List常用的API\n> append, insert, pop, remove, sort\n\n还有切片和迭代等特性\n\n如果想知道Cython中list的实现方式，请参考[这篇文章](http://www.jianshu.com/p/J4U6rR)',1,'python,面试题',1477918210,0,18,0,1,1),(124,'对于研究生生活方式的思考','<p>最近，项目组事情比较少，为了让自己不虚度光阴，所以自己新建了一个<a href=\"https://github.com/ResolveWang/SinaUserCrawler\">repository</a>，专门做微博用户抓取，打算用<strong>多线程和分布式</strong>的方式来提高自己的开发技能,然后给需要的人提供一个<strong>Restful</strong>接口，这样自己的技能栈可以得到扩展和提升。</p>\n<hr />\n<p>因为在上研究生的时候，就有一个比较清晰的目标，两年后一定要得到一份不错的工作，最好是成都腾讯。所以我就一直在学习和巩固自己的编程技能，主要是开发方面，目前使用<em>Python</em>比较多，但是在学习了一段时间<em>java</em>过后，我发现原来编译型语言也有它的美，而且更加底层，和<em>python</em>完全是两种美。以前也使用过<em>PHP</em>和<em>JS</em>，但是现在就打算学好<em>python</em> &amp; <em>java</em>,因为经历和时间都有限，这点我是比较清楚的。</p>\n<p>我一直在学习语言的使用，从API到底层机制，从框架使用到源码阅读，感觉自己也有一些成长。由于项目组是做舆情分析的，本来来实验室是想做云计算或者基础架构服务那块的，结果被导师安排到情报分析这块来了。从大四进实验室到研一上半学期过去了，爬虫那块自己还算是有一些自己的经验和心得了，但是感觉没有多少可以深入的地方了，也没有项目驱动学习和提升技能。只有自己看书，然后写代码。有时候感觉自己没进步，也很焦躁，因为看到同级人都这么努力，而且有的明显在成长，当然不是嫉妒，只是焦虑和羞愧自己没进步。</p>\n<p>这学期基本翘掉了所有的课来写代码。有一天我们的项目组长问我，在做啥，我如实回答了，说在基于自己的兴趣做一个微博用户爬虫。后来就被约谈了。大概意思就是实验室每个月给你发了钱，你要尽心尽力为实验室出力。说起发钱这件事，哎，同一个年级的，我300而别人就是500！能者多得我懂，但是差别不能这么大吧，安排给我做的事虽然不多，但是我帮项目组别的师兄师姐分担了任务的啊。他们解决不了的某些问题不都是我来帮忙搞定或者直接搞定吗？这些估计项目组长也不会知道。算了，不吐槽这个了。然后组长就表示担心我发论文会比较困难，希望我现在开始准备论文。他的好心我能理解，而且也很感激，我并不是一个不懂得感恩的人。但是我也有自己的考量，如果大把时间拿来读paper了，对于我以后求职有好处吗？这个问题我有些迷茫，因为我觉得读paper的时间我可以拿来看很多比较好的书籍，丰富自己的技术栈。哎，这一点比较迷茫。今天看了将近一天的paper,只有一篇，感觉自己没啥收获啊，担心满满的。问了一下组长读论文的方法，他直接给我百度的结果，晕了...我自己也会百度啊，我其实并不是伸手党，我只是想听听身边过来人的经验。看来以后这种比较傻的问题还是自己谷歌吧。</p>\n<hr />\n<p>这些都是今天有感而发，感觉思路还是很杂乱，心情很复杂，不知道到底该把重心往哪里放。上天唯一做到公平的就是给了所有人二十四个小时/天，或许我应该每天都充分利用我的时间，除了吃饭多陪陪自己的女朋友以外。也或许我该找到一个学习更加高效、科研更加高效的方法。</p>\n<p>写了这么多，我还是很迷茫。<strong>工程能力</strong>和<strong>科研能力</strong>我该如何选择？我该怎样读才能说毕业时真正上过研究生</p>','最近，项目组事情比较少，为了让自己不虚度光阴，所以自己新建了一个[repository](https://github.com/ResolveWang/SinaUserCrawler)，专门做微博用户抓取，打算用**多线程和分布式**的方式来提高自己的开发技能,然后给需要的人提供一个**Restful**接口，这样自己的技能栈可以得到扩展和提升。\n\n---\n\n因为在上研究生的时候，就有一个比较清晰的目标，两年后一定要得到一份不错的工作，最好是成都腾讯。所以我就一直在学习和巩固自己的编程技能，主要是开发方面，目前使用*Python*比较多，但是在学习了一段时间*java*过后，我发现原来编译型语言也有它的美，而且更加底层，和*python*完全是两种美。以前也使用过*PHP*和*JS*，但是现在就打算学好*python* & *java*,因为经历和时间都有限，这点我是比较清楚的。\n\n我一直在学习语言的使用，从API到底层机制，从框架使用到源码阅读，感觉自己也有一些成长。由于项目组是做舆情分析的，本来来实验室是想做云计算或者基础架构服务那块的，结果被导师安排到情报分析这块来了。从大四进实验室到研一上半学期过去了，爬虫那块自己还算是有一些自己的经验和心得了，但是感觉没有多少可以深入的地方了，也没有项目驱动学习和提升技能。只有自己看书，然后写代码。有时候感觉自己没进步，也很焦躁，因为看到同级人都这么努力，而且有的明显在成长，当然不是嫉妒，只是焦虑和羞愧自己没进步。\n\n这学期基本翘掉了所有的课来写代码。有一天我们的项目组长问我，在做啥，我如实回答了，说在基于自己的兴趣做一个微博用户爬虫。后来就被约谈了。大概意思就是实验室每个月给你发了钱，你要尽心尽力为实验室出力。说起发钱这件事，哎，同一个年级的，我300而别人就是500！能者多得我懂，但是差别不能这么大吧，安排给我做的事虽然不多，但是我帮项目组别的师兄师姐分担了任务的啊。他们解决不了的某些问题不都是我来帮忙搞定或者直接搞定吗？这些估计项目组长也不会知道。算了，不吐槽这个了。然后组长就表示担心我发论文会比较困难，希望我现在开始准备论文。他的好心我能理解，而且也很感激，我并不是一个不懂得感恩的人。但是我也有自己的考量，如果大把时间拿来读paper了，对于我以后求职有好处吗？这个问题我有些迷茫，因为我觉得读paper的时间我可以拿来看很多比较好的书籍，丰富自己的技术栈。哎，这一点比较迷茫。今天看了将近一天的paper,只有一篇，感觉自己没啥收获啊，担心满满的。问了一下组长读论文的方法，他直接给我百度的结果，晕了...我自己也会百度啊，我其实并不是伸手党，我只是想听听身边过来人的经验。看来以后这种比较傻的问题还是自己谷歌吧。\n\n---\n\n这些都是今天有感而发，感觉思路还是很杂乱，心情很复杂，不知道到底该把重心往哪里放。上天唯一做到公平的就是给了所有人二十四个小时/天，或许我应该每天都充分利用我的时间，除了吃饭多陪陪自己的女朋友以外。也或许我该找到一个学习更加高效、科研更加高效的方法。\n\n写了这么多，我还是很迷茫。**工程能力**和**科研能力**我该如何选择？我该怎样读才能说毕业时真正上过研究生',3,'感悟',1478008527,0,15,0,1,1),(125,'一天两道Python面试题:语言特性(13)','&lt;h3&gt;问题一：Python读文件的read，readline,readlines区别&lt;/h3&gt;\n<ul>\n<li>\n&lt;p&gt;read()：从当前指针处读到文件末尾&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;readline():读取下一行，使用生成器的方式，资源占有少，读取时间长。它的读取方式和直接用next(file_handler)遍历文件一样，对文件指针进行遍历可以直接按行得到读取结果&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;readlines(size): 从当前指针按行读取到文件末尾或者指定字节size处,并且返回按行读取的结果，结果是一个列表&lt;/p&gt;\n</li>\n</ul>\n&lt;p&gt;另外，关于文件和文件指针，还有两个比较有用的函数，<strong>seek()</strong>和<strong>tell()</strong>.seek()用于移动文件指针到指定位置(偏移量)，而tell()用于返回当前文件指针位置。Python3.x下，在调用next()的时候，<strong>标志位会被置为False</strong>，所以再调用tell()就会报错&lt;/p&gt;\n<blockquote>\n&lt;p&gt;OSError: telling position disabled by next() call&lt;/p&gt;\n</blockquote>\n&lt;p&gt;可以通过调用seek()将标志位重置为True&lt;/p&gt;\n&lt;h3&gt;问题二：Python2.7和Python3.x的区别&lt;/h3&gt;\n<ul>\n<li>\n&lt;p&gt;Python 3.x 介绍的 一些Python 2 不兼容的关键字和特性可以通过在 Python 2 的内置 __future__ 模块导入。如果你计划让你的代码支持 Python 3.x，建议你使用 __future__ 模块导入。例如，如果我想要 在Python 2 中表现 Python 3.x 中的整除，我们可以通过如下导入&lt;/p&gt;\n<blockquote>\n&lt;p&gt;from __future__ import division&lt;/p&gt;\n</blockquote>\n</li>\n<li>\n&lt;p&gt;print .python2中print是作为一个声明，而python3中print为函数，比如&lt;/p&gt;\n<blockquote>\n&lt;p&gt;print (\'a\', \'b\')&lt;/p&gt;\n</blockquote>\n</li>\n</ul>\n<blockquote>\n&lt;p&gt;在python2中的表现&lt;/p&gt;\n&lt;p&gt;&gt;&gt;&gt; （‘a’, \'b\'） # 这里被当成一个元组打印了&lt;/p&gt;\n&lt;p&gt;在python3中的表现\n&gt;&gt;&gt; a b  # 当做两个变量打印&lt;/p&gt;\n</blockquote>\n<ul>\n<li>\n&lt;p&gt;整除\n    在Python3中，除法运算的结果是小数，而Python2中不管是否除得尽都是向下取整。可以使用python2中的__future__模块来兼容python3&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;unicode&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;xrange 和 range&lt;/p&gt;\n</li>\n</ul>\n&lt;p&gt;...&lt;/p&gt;\n&lt;p&gt;细节比较多，需要了解请参考<a href=\"http://chenqx.github.io/2014/11/10/Key-differences-between-Python-2-7-x-and-Python-3-x/\">原文</a>&lt;/p&gt;','### 问题一：Python读文件的read，readline,readlines区别\n\n- read()：从当前指针处读到文件末尾\n\n- readline():读取下一行，使用生成器的方式，资源占有少，读取时间长。它的读取方式和直接用next(file_handler)遍历文件一样，对文件指针进行遍历可以直接按行得到读取结果\n\n- readlines(size): 从当前指针按行读取到文件末尾或者指定字节size处,并且返回按行读取的结果，结果是一个列表\n\n另外，关于文件和文件指针，还有两个比较有用的函数，**seek()**和**tell()**.seek()用于移动文件指针到指定位置(偏移量)，而tell()用于返回当前文件指针位置。Python3.x下，在调用next()的时候，**标志位会被置为False**，所以再调用tell()就会报错\n> OSError: telling position disabled by next() call\n\n可以通过调用seek()将标志位重置为True\n\n### 问题二：Python2.7和Python3.x的区别\n\n- Python 3.x 介绍的 一些Python 2 不兼容的关键字和特性可以通过在 Python 2 的内置 \\_\\_future\\_\\_ 模块导入。如果你计划让你的代码支持 Python 3.x，建议你使用 \\_\\_future\\_\\_ 模块导入。例如，如果我想要 在Python 2 中表现 Python 3.x 中的整除，我们可以通过如下导入\n > from \\_\\_future\\_\\_ import division\n\n- print .python2中print是作为一个声明，而python3中print为函数，比如\n > print (\'a\', \'b\')\n\n >在python2中的表现\n \n > \\>\\>\\> （‘a’, \'b\'） \\# 这里被当成一个元组打印了\n\n > 在python3中的表现\n> \\>\\>\\> a b  \\# 当做两个变量打印\n\n- 整除\n	在Python3中，除法运算的结果是小数，而Python2中不管是否除得尽都是向下取整。可以使用python2中的\\_\\_future\\_\\_模块来兼容python3\n\n- unicode\n\n- xrange 和 range\n\n...\n\n细节比较多，需要了解请参考[原文](http://chenqx.github.io/2014/11/10/Key-differences-between-Python-2-7-x-and-Python-3-x/)\n\n',1,'python,面试题',1478054300,0,20,0,1,1),(126,'oh-my-zsh修改欢迎界面','&lt;p&gt;前几天看到朋友的bash界面很炫酷，他的oh-my-zsh欢迎页面是自己的ID，几经折腾，终于找到修改方法了，由于网上这方面的内容比较少，所以我就记录下来，便于以后查看。&lt;/p&gt;\n&lt;p&gt;不管是linux还是mac os,都是修改一个叫<strong>motd</strong>的文件&lt;/p&gt;\n<blockquote>\n&lt;p&gt;vim /etc/motd&lt;/p&gt;\n</blockquote>\n&lt;p&gt;打开后发现它是空的，这个文件就用于存放欢迎界面内容，我在<a href=\"http://ascii.mastervb.net/text_to_ascii.php\">这个网站</a>上用指定文字生成的样式，我们把生成的字符拷贝到motd文件中即可，再次打开zsh就可以看到为你量身定制的欢迎界面了。&lt;/p&gt;\n&lt;p&gt;晒晒我的界面\n&lt;div&gt;<a href=\"http://o948iqcf0.bkt.clouddn.com/ohmz.png\" title=\"点击查看\">&lt;img src=\"http://o948iqcf0.bkt.clouddn.com/ohmz.png\" width=\"400px\"&gt;</a>&lt;/div&gt;&lt;/p&gt;','前几天看到朋友的bash界面很炫酷，他的oh-my-zsh欢迎页面是自己的ID，几经折腾，终于找到修改方法了，由于网上这方面的内容比较少，所以我就记录下来，便于以后查看。\n\n不管是linux还是mac os,都是修改一个叫**motd**的文件\n> vim /etc/motd\n\n打开后发现它是空的，这个文件就用于存放欢迎界面内容，我在[这个网站](http://ascii.mastervb.net/text_to_ascii.php)上用指定文字生成的样式，我们把生成的字符拷贝到motd文件中即可，再次打开zsh就可以看到为你量身定制的欢迎界面了。\n\n晒晒我的界面\n<div><a title=\'点击查看\' href=\'http://o948iqcf0.bkt.clouddn.com/ohmz.png\'><img src=\'http://o948iqcf0.bkt.clouddn.com/ohmz.png\' width=\'400px\'></a></div>\n\n\n',3,'linux',1478256737,0,19,0,1,1),(127,'CentOS升级Python后命令行Up、Left键、Right和Backspace键乱码问题','<p>关于<em>CentOS</em>上*Python版本的升级，请看<a href=\"http://www.rookiefly.cn/detail/86\">这篇</a></p>\n<p>升级过后却出现了另外一个问题，那就是在Python命令行中backspace等按键会失效，查阅资料才知道，没有启用<strong>readline</strong>,解决方法如下</p>\n<p>安装readline模块</p>\n<blockquote>\n<p>yum install readline-devel</p>\n</blockquote>\n<p>重新编译安装Python,过程就不说了，<a href=\"http://www.rookiefly.cn/detail/86\">此处</a>就是具体方法</p>','关于*CentOS*上*Python版本的升级，请看[这篇](http://www.rookiefly.cn/detail/86)\n\n升级过后却出现了另外一个问题，那就是在Python命令行中backspace等按键会失效，查阅资料才知道，没有启用**readline**,解决方法如下\n\n安装readline模块\n> yum install readline-devel\n\n重新编译安装Python,过程就不说了，[此处](http://www.rookiefly.cn/detail/86)就是具体方法',1,'python,linux',1478572693,0,13,0,1,1),(128,'使用heroku+shadowsocks-heroku进行科学上网','<p>Heroku是标准的<strong>Paas</strong>服务，我们的程序可以很简单的部署到Heroku上，开发者只需要使用Git将项目Push到Heroku的Git服务器上即可，git push会自动触发安装、配置和部署程序</p>\n<h3>预备工作</h3>\n<ul>\n<li>在<a href=\"https://www.heroku.com/\">heroku官网</a>注册heroku账号</li>\n<li>安装相应操作系统的Heroku客户端，这里是<a href=\"https://devcenter.heroku.com/articles/heroku-command-line\">地址</a></li>\n<li>安装后通过命令行登陆Heroku<blockquote>\n<p>heroku login</p>\n</blockquote>\n</li>\n</ul>\n<p>第一次使用上述命令的时候可能还需要安装，安装完毕之后可能会没有反映(正常的话应该会弹出email选项让你输入)，可以先不管它，重新打开一个命令行界面(我用windows就出现了这种情况)，输入\"heroku login\"即可</p>\n<ul>\n<li>通过命令行登陆后，可以通过命令行或者<a href=\"https://dashboard.heroku.com/new?org=personal-apps\">网页</a>创建app,通过网页的方式比较简单，输入app名字后直接点击<strong>Create App</strong>,使用命令的话如下<blockquote>\n<p>heroku create kxswforme <strong>kxswforme</strong>是你的app名字</p>\n</blockquote>\n</li>\n</ul>\n<p>关于heroku的配置，就到这里了</p>\n<hr />\n<h3>安装和配置shadowsocks-heroku</h3>\n<ul>\n<li>从github下载<a href=\"https://github.com/mrluanma/shadowsocks-heroku\">shadowsocks-heroku</a>的zip压缩包</li>\n<li>在本地某个目录指定一个文件夹(比如我使用的是<strong>G:\\kxswforme</strong>)，解压下载的<a href=\"https://github.com/mrluanma/shadowsocks-heroku/archive/master.zip\">zip文件</a>将全部文件拷贝到指定根目录（我这里是<strong>G:\\kxswforme</strong>）</li>\n<li>\n<p>修改<strong>config.json</strong>配置文件,修改server和remote_port如下</p>\n<blockquote>\n<p>\"server\": \"0.0.0.0\",\n\"remote_port\": 80,</p>\n</blockquote>\n</li>\n<li>\n<p>通过刚登陆的命令行界面，切换到放shadowsocks-heroku的目录(我的是<strong>G:\\kxswforme</strong>)，</p>\n</li>\n</ul>\n<p>初始化git仓库</p>\n<blockquote>\n<p>git init</p>\n</blockquote>\n<p>如果没有用过git，需要配置你的git账户</p>\n<blockquote>\n<p>git config --global user.email xx@xx.com(这里是你的git注册邮箱)</p>\n</blockquote>\n<p>关联远程仓库</p>\n<blockquote>\n<p>heroku git:remote -a kxswforme (kxswforme是我创建的app名字)</p>\n</blockquote>\n<p>再添加所有文件</p>\n<blockquote>\n<p>git add .</p>\n</blockquote>\n<p>添加注释</p>\n<blockquote>\n<p>git commit -m \'test\'</p>\n</blockquote>\n<p>推送到heroku的git服务器</p>\n<blockquote>\n<p>git push heroku master</p>\n</blockquote>\n<p>到这里可以使用简单的方法验证，在浏览器中输入 appname.herokuapp.com(这里的appname是你的app名字)，如果显示<strong>asdf.</strong>,那么就说明OK了</p>\n<ul>\n<li>\n<p>设置一些配置</p>\n<blockquote>\n<p>heroku config:set METHOD=rc4 KEY=foobar</p>\n</blockquote>\n</li>\n<li>\n<p>安装一些node的依赖</p>\n<blockquote>\n<p>npm install</p>\n</blockquote>\n</li>\n<li>\n<p>启动ss-heroku客户端</p>\n<blockquote>\n<p>node local.js -s kxswforme.herokuapp.com -l 1080 -m rc4 -k foobar -r 80 (这里的<strong>keswforme</strong>是我的app名字)</p>\n</blockquote>\n</li>\n</ul>\n<p>如果出现</p>\n<blockquote>\n<p>server listening at { address: \'127.0.0.1\', family: \'IPv4\', port: 1080 }</p>\n</blockquote>\n<p>那么就说明已经成功了</p>\n<hr />\n<p>由于这时候流量走的是socks通信，如果浏览器想要能访问被墙的网站，还需要为它设置代理，推荐使用<strong> SwitchySharp </strong>插件，设置方式我还是简单说说吧</p>\n<p><strong>SwitchySharp</strong>是chrome的插件，在安装过后，右击它的图标，选择<strong>选项</strong>,然后在<strong>情景模式</strong>的proxy中设置</p>\n<blockquote>\n<p>代理协议 -&gt; socks5</p>\n<p>代理服务器 -&gt; 127.0.0.1</p>\n<p>代理端口 -&gt; 1080</p>\n</blockquote>\n<p>点击<strong>应用选项</strong>保存更改，这时候就可以访问google了，这时候默认所有站点都走代理。当然你也可以设置某些站点不走代理，关于SwitchySharp的具体设置我就不详细说了，大家可以在网上很容易查阅到</p>\n<hr />\n<p>这里我有几个别的想法</p>\n<ul>\n<li>\n<p>可以把客户端脚本做成一个自启动的脚本，这样就不需要我们每次开机手动启动了</p>\n</li>\n<li>\n<p>我们可以使用<a href=\"https://github.com/kennethreitz/requests\"><strong>requests</strong></a>等网络库通过socks5代理来调用google搜索等服务,也可以让我们的<strong>网络爬虫</strong>走这层代理(说起网络爬虫，哎，就有点惭愧，自己很早就打算写这一系列教程，却一直搁置着，拖延症啊！)，而heroku提供免费50个app创建的权限，并且经过测试发现每个app的ip都不一样，所以那样子就避免了缺少<strong>代理IP</strong>的尴尬，我们从此就可以告别网上那些稳定性不够高的免费HTTP/HTTPS代理。</p>\n</li>\n<li>\n<p>从上面受到启发，我们可以找一些类似heroku的可免费提供Paas服务的应用和后端云,比如<strong>GAE</strong>,<strong>openshift</strong>等，由此来设置并获取一些可用的代理，或者直接把爬虫部署上去</p>\n</li>\n</ul>','Heroku是标准的**Paas**服务，我们的程序可以很简单的部署到Heroku上，开发者只需要使用Git将项目Push到Heroku的Git服务器上即可，git push会自动触发安装、配置和部署程序\n\n### 预备工作\n- 在[heroku官网](https://www.heroku.com/)注册heroku账号\n- 安装相应操作系统的Heroku客户端，这里是[地址](https://devcenter.heroku.com/articles/heroku-command-line)\n- 安装后通过命令行登陆Heroku\n> heroku login\n\n 第一次使用上述命令的时候可能还需要安装，安装完毕之后可能会没有反映(正常的话应该会弹出email选项让你输入)，可以先不管它，重新打开一个命令行界面(我用windows就出现了这种情况)，输入\"heroku login\"即可\n\n- 通过命令行登陆后，可以通过命令行或者[网页](https://dashboard.heroku.com/new?org=personal-apps)创建app,通过网页的方式比较简单，输入app名字后直接点击**Create App**,使用命令的话如下\n> heroku create kxswforme **kxswforme**是你的app名字\n\n关于heroku的配置，就到这里了\n\n---\n\n### 安装和配置shadowsocks-heroku\n\n- 从github下载[shadowsocks-heroku](https://github.com/mrluanma/shadowsocks-heroku)的zip压缩包\n- 在本地某个目录指定一个文件夹(比如我使用的是**G:\\kxswforme**)，解压下载的[zip文件](https://github.com/mrluanma/shadowsocks-heroku/archive/master.zip)将全部文件拷贝到指定根目录（我这里是**G:\\kxswforme**）\n- 修改**config.json**配置文件,修改server和remote_port如下\n> \"server\": \"0.0.0.0\",\n>\"remote_port\": 80,\n\n- 通过刚登陆的命令行界面，切换到放shadowsocks-heroku的目录(我的是**G:\\kxswforme**)，\n\n 初始化git仓库\n > git init\n\n 如果没有用过git，需要配置你的git账户\n > git config --global user.email xx@xx.com(这里是你的git注册邮箱)\n\n 关联远程仓库\n > heroku git:remote -a kxswforme (kxswforme是我创建的app名字)\n\n 再添加所有文件\n > git add .\n\n 添加注释\n > git commit -m \'test\'\n\n 推送到heroku的git服务器\n > git push heroku master\n\n 到这里可以使用简单的方法验证，在浏览器中输入 appname.herokuapp.com(这里的appname是你的app名字)，如果显示**asdf.**,那么就说明OK了\n\n- 设置一些配置\n> heroku config:set METHOD=rc4 KEY=foobar\n\n- 安装一些node的依赖\n> npm install\n\n- 启动ss-heroku客户端\n> node local.js -s kxswforme.herokuapp.com -l 1080 -m rc4 -k foobar -r 80 (这里的**keswforme**是我的app名字)\n\n 如果出现\n > server listening at { address: \'127.0.0.1\', family: \'IPv4\', port: 1080 }\n\n 那么就说明已经成功了\n\n---\n\n由于这时候流量走的是socks通信，如果浏览器想要能访问被墙的网站，还需要为它设置代理，推荐使用** SwitchySharp **插件，设置方式我还是简单说说吧\n\n**SwitchySharp**是chrome的插件，在安装过后，右击它的图标，选择**选项**,然后在**情景模式**的proxy中设置\n> 代理协议 -> socks5\n\n> 代理服务器 -> 127.0.0.1\n\n> 代理端口 -> 1080\n\n点击**应用选项**保存更改，这时候就可以访问google了，这时候默认所有站点都走代理。当然你也可以设置某些站点不走代理，关于SwitchySharp的具体设置我就不详细说了，大家可以在网上很容易查阅到\n\n---\n\n这里我有几个别的想法\n\n- 可以把客户端脚本做成一个自启动的脚本，这样就不需要我们每次开机手动启动了\n\n- 我们可以使用[**requests**](https://github.com/kennethreitz/requests)等网络库通过socks5代理来调用google搜索等服务,也可以让我们的**网络爬虫**走这层代理(说起网络爬虫，哎，就有点惭愧，自己很早就打算写这一系列教程，却一直搁置着，拖延症啊！)，而heroku提供免费50个app创建的权限，并且经过测试发现每个app的ip都不一样，所以那样子就避免了缺少**代理IP**的尴尬，我们从此就可以告别网上那些稳定性不够高的免费HTTP/HTTPS代理。\n\n- 从上面受到启发，我们可以找一些类似heroku的可免费提供Paas服务的应用和后端云,比如**GAE**,**openshift**等，由此来设置并获取一些可用的代理，或者直接把爬虫部署上去',3,'科学上网',1478674084,0,20,0,1,1),(129,'Win10设置.bat脚本开机自启','<ul>\n<li>Win+R 调出命令行</li>\n<li>\n<blockquote>\n<p>gpedit.msc</p>\n</blockquote>\n</li>\n<li>本地计算机 策略 -&gt; 计算机配置</li>\n<li>计算机配置 -&gt;Windows 设置</li>\n<li>Windows设置-&gt;脚本(启动/g关闭)</li>\n<li>点击<strong>启动</strong></li>\n<li>点击<strong>添加</strong></li>\n<li>然后添加自己的<strong>.bat</strong>脚本</li>\n<li>Ok</li>\n</ul>','- Win+R 调出命令行\n - > gpedit.msc\n- 本地计算机 策略 -> 计算机配置\n- 计算机配置 ->Windows 设置\n- Windows设置->脚本(启动/g关闭)\n- 点击**启动**\n- 点击**添加**\n- 然后添加自己的**.bat**脚本\n- Ok',1,'操作系统',1479037855,0,12,0,1,1),(132,'Python性能分析与优化','&lt;p&gt;早在写<a href=\"https://github.com/ResolveWang/myblog\">博客源码</a>的时候就加上了 『读书』 一栏，但是一直没有写关于书评的文章。一个原因是最近比较忙，另外一个原因是有的书看了过后感觉收获不是很大，只有特定一些章节感觉自己有所见识和收获，其它的就是看了就忘了。后面偶然接触到了<a href=\"http://www.xmind.net/\">Xmind</a>，感觉到它的强大和实用之处，我把它用来做读书笔记，感觉效果很不错。<strong>Xmind</strong>免费的功能对于我来说就已经够用了，如果大家有更多的需求，那么请购买Xmind Pro吧，这也是对原作者的一种支持，听说他还是一名中国人！&lt;/p&gt;\n&lt;hr/&gt;\n&lt;p&gt;『Python性能分析与优化』一书，听书名就很清晰，讲的就是关于Python语言的性能分析和优化。性能分析主要是借助可视化工具进行分析，辅以CProfile，书中讲的性能分析工具是<strong>pyprof2calltree+KCacheGrind</strong>，这个只能在Linux环境下运行。在Windows环境下有另外一款可视化性能分析工具<strong>Snakeviz</strong>,它会把函数的运行情况以Html的形式展示出来。&lt;/p&gt;\n&lt;p&gt;性能分析之后就是性能优化，这是一个永恒的话题，书中讲了一些常用的优化方法。下面我具体讲讲。&lt;/p&gt;\n&lt;p&gt;<strong>细节优化</strong>&lt;/p&gt;\n<ul>\n<li>使用函数返回值缓存结果，函数返回值一般为字典或者列表。这种写法在之前我阅读低版本Requests源码的视乎看到过，现在才明白为何要这么写。</li>\n<li>使用默认参数代替位置参数</li>\n<li>使用生成器创建长列表，使用列表生成式创建短列表</li>\n<li>使用ctypes</li>\n</ul>\n&lt;p&gt;<strong>常用优化方法</strong>&lt;/p&gt;\n<ul>\n<li>PyPy。不过这货只支持Python2.x进行优化，而且必须是纯Python代码</li>\n<li>Cython。使用Cython需要先将.pyx文件编译成.c文件，然后再将.c文件编译成.so文件</li>\n</ul>\n&lt;p&gt;<strong>多线程和多进程</strong>&lt;/p&gt;\n<ul>\n<li>IO密集型：可以使用多线程，GIL造成的影响忽略不计</li>\n<li>计算密集型： 使用多进程。多进程创建的开销比线程要大。另外，使用多进程需要考虑进程间通信，而使用多线程可能需要考虑线程的资源竞争和线程同步等问题</li>\n<li>书中还有一点没有讲到，就是使用异步来代替同步的方案，Python对异步的支持也很完善，异步IO是多线程的一个更合适的代替方案，因为它是单线程，所以不会有创建和销毁线程的开销，也不存在多线程的同步、竞态等问题</li>\n</ul>\n&lt;p&gt;<strong>数据处理</strong>&lt;/p&gt;\n<ul>\n<li>Numba：它支持直接把Python代码转化为机器码，甚至可以直接转化为CPU、GPU能够运行的代码，所以速度很快</li>\n<li>Pandas：它可以将大数据文件载入内存或者保存为其它形式，用它来处理大文件十分方便。它还可以与matplotlib轻松整合，做数据可视化工作。它是使用Cython编写的，所以速度也很快</li>\n<li>Parakeet：它可以轻松处理数值计算的问题，但是支持的数据类型有限，包括Python的数字、元组、列表和Numpy的数组。除此之外，它也不支持异常捕获和处理。</li>\n</ul>\n&lt;p&gt;大概内容就是这些，我在读的时候画了更详细的思维导图，有兴趣的可以看看：<a href=\"http://o948iqcf0.bkt.clouddn.com/pyopt.png\">查看</a>&lt;/p&gt;\n&lt;hr/&gt;\n&lt;p&gt;我在github上专门为此开了一个项目，欢迎大家<a href=\"https://github.com/ResolveWang/mybooklist\">围观</a>，觉得有帮助不防给个star&lt;/p&gt;','早在写[博客源码](https://github.com/ResolveWang/myblog)的时候就加上了 『读书』 一栏，但是一直没有写关于书评的文章。一个原因是最近比较忙，另外一个原因是有的书看了过后感觉收获不是很大，只有特定一些章节感觉自己有所见识和收获，其它的就是看了就忘了。后面偶然接触到了[Xmind](http://www.xmind.net/)，感觉到它的强大和实用之处，我把它用来做读书笔记，感觉效果很不错。**Xmind**免费的功能对于我来说就已经够用了，如果大家有更多的需求，那么请购买Xmind Pro吧，这也是对原作者的一种支持，听说他还是一名中国人！\n\n---\n\n『Python性能分析与优化』一书，听书名就很清晰，讲的就是关于Python语言的性能分析和优化。性能分析主要是借助可视化工具进行分析，辅以CProfile，书中讲的性能分析工具是**pyprof2calltree+KCacheGrind**，这个只能在Linux环境下运行。在Windows环境下有另外一款可视化性能分析工具**Snakeviz**,它会把函数的运行情况以Html的形式展示出来。\n\n性能分析之后就是性能优化，这是一个永恒的话题，书中讲了一些常用的优化方法。下面我具体讲讲。\n\n**细节优化**\n\n - 使用函数返回值缓存结果，函数返回值一般为字典或者列表。这种写法在之前我阅读低版本Requests源码的视乎看到过，现在才明白为何要这么写。\n - 使用默认参数代替位置参数\n - 使用生成器创建长列表，使用列表生成式创建短列表\n - 使用ctypes\n\n**常用优化方法**\n\n - PyPy。不过这货只支持Python2.x进行优化，而且必须是纯Python代码\n - Cython。使用Cython需要先将.pyx文件编译成.c文件，然后再将.c文件编译成.so文件\n\n**多线程和多进程**\n\n - IO密集型：可以使用多线程，GIL造成的影响忽略不计\n - 计算密集型： 使用多进程。多进程创建的开销比线程要大。另外，使用多进程需要考虑进程间通信，而使用多线程可能需要考虑线程的资源竞争和线程同步等问题\n - 书中还有一点没有讲到，就是使用异步来代替同步的方案，Python对异步的支持也很完善，异步IO是多线程的一个更合适的代替方案，因为它是单线程，所以不会有创建和销毁线程的开销，也不存在多线程的同步、竞态等问题\n\n**数据处理**\n\n - Numba：它支持直接把Python代码转化为机器码，甚至可以直接转化为CPU、GPU能够运行的代码，所以速度很快\n - Pandas：它可以将大数据文件载入内存或者保存为其它形式，用它来处理大文件十分方便。它还可以与matplotlib轻松整合，做数据可视化工作。它是使用Cython编写的，所以速度也很快\n - Parakeet：它可以轻松处理数值计算的问题，但是支持的数据类型有限，包括Python的数字、元组、列表和Numpy的数组。除此之外，它也不支持异常捕获和处理。\n \n 大概内容就是这些，我在读的时候画了更详细的思维导图，有兴趣的可以看看：[查看](http://o948iqcf0.bkt.clouddn.com/pyopt.png)\n\n---\n我在github上专门为此开了一个项目，欢迎大家[围观](https://github.com/ResolveWang/mybooklist)，觉得有帮助不防给个star\n',2,'python,性能优化',1479189021,0,16,0,1,1),(133,'Python爬虫系列(五):聊聊反爬虫措施','&lt;p&gt;前段时间写了关于<strong>『Python面试系列』</strong>的部分文章，语言层次的东西就写得差不多，有一些我写进那个系列的都零星的写在别的文章上了。更前一段时间写过<strong>『Python爬虫系列』</strong>的部分文章，但是真的感觉很多都想写，却在写的时候不知道如何下笔。这两天，在做关于被黑网站信息采集的时候，遇到了一个有趣的问题，是关于反爬虫的。所以这一篇我们一起聊聊反爬虫技术吧。&lt;/p&gt;\n&lt;hr/&gt;\n&lt;p&gt;现在依次列出来。&lt;/p&gt;\n&lt;p&gt;<strong>headers部分</strong>&lt;/p&gt;\n<ul>\n<li>根据是否带有合法的UA头来判断。举个例子吧，requests自带的UA头是<em>requests v</em>,连一点伪装都没有，爬虫被封杀了能怪谁呢？</li>\n<li>根据Refer来判断。有的链接只可能根据站内某个链接跳转过去，那个时候可能要带上Refer</li>\n<li>根据Cookie来判断。这个就比较有意思了。有的时候某些cookie字段可以通过服务器的响应头获得，一些页面的访问必须要带了这个响应头返回的cookie才能访问，印象中帮一位网友调bug的时候遇见过，他当时在做Apple开发者平台的相关数据采集的时候就遇到这个问题。除了响应头可能拿到某些cookie的键值对以外，有的站点会将cookie相关代码写入js中，然后当用户用浏览器访问网页的时候动态生成，我现在抓取的<a href=\"http://www.zone-h.com/archive/special=1/page=2\">这个网站</a>就是这样,如果我们直接用http库去请求它，会发现得到的是一个空白页，仔细观察会发现它的页面中有生成cookie的相关代码，我们需要通过渲染js来获取cookie值，Python中可通过<strong>PyExecjs</strong>这个库来执行js代码。 除了这点以外，这个网站还有一个比较有意思的点是，它会根据你的请求频率来判断你是不是爬虫（这点我们待会再讲），然后再决定是否对你的ip进行限制。如果这个时候你带上计算出来的cookie再去访问，只会得到一个有验证码的网页。那么怎么解决呢？照目前我知道的而言，只有使用<strong>代理IP</strong>了，但是我在网上找的代理IP很多一样会弹出验证码，这一点让我很费解，我以为我的代理ip没有生效，但是我用代理IP访问自己的站点或者一些IP查询站点的时候，返回的都是代理IP。这点我就很费解了。直到后面我在heroku上部署了一个ss的欧洲节点（有关在heroku上免费部署ss的方法请点击<a href=\"http://www.rookiefly.cn/detail/128\">此处</a>）,发现使用该代理并不会出现验证码，我才知道可能是某些ip，该站点本来就不信任。后来我在浏览器中用一个被限制了的ip访问该站点，一样弹出了验证码。在填了验证码后，可以正常访问了，但是<strong>只限于当前session</strong>,如果关掉浏览器再打开，又会出现验证码。通过抓包，我发现它在请求的时候，cookie中有一个<strong>PHPSessionID</strong>字段，这个就是session id.当我带上填写验证码过后的session id，再加上构造的cookie的时候，果然就可以正常爬取数据了。所以这一点也是一个思路，<strong>对于一些高频访问的IP，可以让它在某次验证之后，只是对于单个session放行，别的session仍然进行验证</strong>，目前除了把采集频率设置低一些外，我还没找到更好的方法突破它的限制</li>\n<li>post/get提交特定的参数。参数可以是加密后的用户名、密码（这样也是为了安全），同样会增加爬虫的编写难度，还可以是隐藏在页面中的一些特殊字段，比如csdn和知乎登陆的时候就会用到在登录页面中的一些隐藏字段的值。这个我们可以通过抓包来判断究竟客户端向服务器发送了哪些数据，从而确定我们用程序应该怎么提交</li>\n</ul>\n&lt;p&gt;<strong>页面部分</strong>&lt;/p&gt;\n<ul>\n<li>采用ajax异步加载的方式。这个方法可以阻止很多小爬虫了。但是这个方法可能阻止不了比较了解js和会抓包的人。即使不了解js，也可以用selelium+brower的方式进行傻瓜式的抓取</li>\n</ul>\n&lt;p&gt;<strong> 访问者行为部分</strong>&lt;/p&gt;\n<ul>\n<li>基于单个cookie固定频率的检测。检测某个时间段内某个cookie对于网站的访问是否超过阈值</li>\n<li>基于单个ip固定频率的检测。检测某个时间段内某个IPe对于网站的访问是否超过阈值</li>\n</ul>\n&lt;p&gt;以上两种方法都可以比较有效的缓解服务器的压力，并且减少恶意访问。基于它们，又提出了基于<strong>滑动时间窗口</strong>的检测方法。对于这几种通过控制访问频率来进行反爬的措施，目前我想到的应对方法只能是触碰它的边界获取它的近似阈值，然后以增加cookie或者ip的方式来提高采集速度了&lt;/p&gt;\n<ul>\n<li>\n&lt;p&gt;检测用户是否在页面有某些特定动作，比如拖拽光标悬停在某些页面元素上。这种方式解决方法可以通过selenium+browser来应对&lt;/p&gt;\n</li>\n<li>\n&lt;p&gt;针对selenium+brower的方式，现在已经有安全公司做了相关的反制措施了。比如提取webdriver的指纹，再判断是通过人还是代码驱动浏览器访问web页面的。这个我以前遇到过一次，除了硬着头皮读它的js代码进行逆向以外，基本无解啊。selenium那种方式只有看运气，某些webdriver的指纹没被提取，那么就用它驱动浏览器。还有个限制更严格的是，只要webdriver指纹不在它名单上的，他一律认为是非法的！这个我也遇到过一次，无解！&lt;/p&gt;\n</li>\n</ul>\n&lt;p&gt;补充一下，用selenium的话最好用phantomjs别用真实的浏览器，不然速度会很慢的...但是遇到window等phantomjs不支持的元素，那么只好用真实的浏览器了&lt;/p&gt;\n&lt;p&gt;<strong> 对于检测出来的爬虫的处理方法　</strong>&lt;/p&gt;\n<ul>\n<li>弹出验证码，进行人机验证</li>\n<li>禁止它的cookie或session</li>\n<li>禁止当前ip</li>\n<li>放行，但是参杂一些脏数据</li>\n</ul>\n&lt;hr/&gt;\n&lt;p&gt;写爬虫真实一个费力不讨好的活儿，一不小心别人就改了反爬虫策略，一不小心网站的页面结构就发生变化了...不过这个过程中也还是学到了很多东西，特别是对于http协议的一些理解，真的比以前要深得多了。&lt;/p&gt;\n&lt;p&gt;目前对于<a href=\"http://www.zone-h.com/archive/special=1/page=2\">这个网站</a>的采集就遇到了问题，它会限制访问频率，如果被检测出来了是爬虫，直接限制ip（表现方式是弹出验证码），如果严重它只会让验证过的session进行访问，同一个ip开另一个session还是会弹出验证码。所以希望有大神能够指点一二啊，还有一个比较有意思的问题是调用google搜索，同样会因为采集频率而受到限制，但是很奇怪的是同一个代理ip,被限制之后用浏览器同样可以访问，只是用程序访问会出错。这个问题应该是可以通过抓包等方式解决，但是我现在还是没眉目，也希望有童鞋可以交流、指点一下。&lt;/p&gt;','前段时间写了关于**『Python面试系列』**的部分文章，语言层次的东西就写得差不多，有一些我写进那个系列的都零星的写在别的文章上了。更前一段时间写过**『Python爬虫系列』**的部分文章，但是真的感觉很多都想写，却在写的时候不知道如何下笔。这两天，在做关于被黑网站信息采集的时候，遇到了一个有趣的问题，是关于反爬虫的。所以这一篇我们一起聊聊反爬虫技术吧。\n\n---\n\n现在依次列出来。\n\n**headers部分**\n\n- 根据是否带有合法的UA头来判断。举个例子吧，requests自带的UA头是*requests v*,连一点伪装都没有，爬虫被封杀了能怪谁呢？\n- 根据Refer来判断。有的链接只可能根据站内某个链接跳转过去，那个时候可能要带上Refer\n- 根据Cookie来判断。这个就比较有意思了。有的时候某些cookie字段可以通过服务器的响应头获得，一些页面的访问必须要带了这个响应头返回的cookie才能访问，印象中帮一位网友调bug的时候遇见过，他当时在做Apple开发者平台的相关数据采集的时候就遇到这个问题。除了响应头可能拿到某些cookie的键值对以外，有的站点会将cookie相关代码写入js中，然后当用户用浏览器访问网页的时候动态生成，我现在抓取的[这个网站](http://www.zone-h.com/archive/special=1/page=2)就是这样,如果我们直接用http库去请求它，会发现得到的是一个空白页，仔细观察会发现它的页面中有生成cookie的相关代码，我们需要通过渲染js来获取cookie值，Python中可通过**PyExecjs**这个库来执行js代码。 除了这点以外，这个网站还有一个比较有意思的点是，它会根据你的请求频率来判断你是不是爬虫（这点我们待会再讲），然后再决定是否对你的ip进行限制。如果这个时候你带上计算出来的cookie再去访问，只会得到一个有验证码的网页。那么怎么解决呢？照目前我知道的而言，只有使用**代理IP**了，但是我在网上找的代理IP很多一样会弹出验证码，这一点让我很费解，我以为我的代理ip没有生效，但是我用代理IP访问自己的站点或者一些IP查询站点的时候，返回的都是代理IP。这点我就很费解了。直到后面我在heroku上部署了一个ss的欧洲节点（有关在heroku上免费部署ss的方法请点击[此处](http://www.rookiefly.cn/detail/128)）,发现使用该代理并不会出现验证码，我才知道可能是某些ip，该站点本来就不信任。后来我在浏览器中用一个被限制了的ip访问该站点，一样弹出了验证码。在填了验证码后，可以正常访问了，但是**只限于当前session**,如果关掉浏览器再打开，又会出现验证码。通过抓包，我发现它在请求的时候，cookie中有一个**PHPSessionID**字段，这个就是session id.当我带上填写验证码过后的session id，再加上构造的cookie的时候，果然就可以正常爬取数据了。所以这一点也是一个思路，**对于一些高频访问的IP，可以让它在某次验证之后，只是对于单个session放行，别的session仍然进行验证**，目前除了把采集频率设置低一些外，我还没找到更好的方法突破它的限制\n- post/get提交特定的参数。参数可以是加密后的用户名、密码（这样也是为了安全），同样会增加爬虫的编写难度，还可以是隐藏在页面中的一些特殊字段，比如csdn和知乎登陆的时候就会用到在登录页面中的一些隐藏字段的值。这个我们可以通过抓包来判断究竟客户端向服务器发送了哪些数据，从而确定我们用程序应该怎么提交\n\n**页面部分**\n\n- 采用ajax异步加载的方式。这个方法可以阻止很多小爬虫了。但是这个方法可能阻止不了比较了解js和会抓包的人。即使不了解js，也可以用selelium+brower的方式进行傻瓜式的抓取\n\n** 访问者行为部分**\n\n- 基于单个cookie固定频率的检测。检测某个时间段内某个cookie对于网站的访问是否超过阈值\n- 基于单个ip固定频率的检测。检测某个时间段内某个IPe对于网站的访问是否超过阈值\n\n 以上两种方法都可以比较有效的缓解服务器的压力，并且减少恶意访问。基于它们，又提出了基于**滑动时间窗口**的检测方法。对于这几种通过控制访问频率来进行反爬的措施，目前我想到的应对方法只能是触碰它的边界获取它的近似阈值，然后以增加cookie或者ip的方式来提高采集速度了\n\n- 检测用户是否在页面有某些特定动作，比如拖拽光标悬停在某些页面元素上。这种方式解决方法可以通过selenium+browser来应对\n\n- 针对selenium+brower的方式，现在已经有安全公司做了相关的反制措施了。比如提取webdriver的指纹，再判断是通过人还是代码驱动浏览器访问web页面的。这个我以前遇到过一次，除了硬着头皮读它的js代码进行逆向以外，基本无解啊。selenium那种方式只有看运气，某些webdriver的指纹没被提取，那么就用它驱动浏览器。还有个限制更严格的是，只要webdriver指纹不在它名单上的，他一律认为是非法的！这个我也遇到过一次，无解！\n\n 补充一下，用selenium的话最好用phantomjs别用真实的浏览器，不然速度会很慢的...但是遇到window等phantomjs不支持的元素，那么只好用真实的浏览器了\n \n** 对于检测出来的爬虫的处理方法　**\n\n- 弹出验证码，进行人机验证\n- 禁止它的cookie或session\n- 禁止当前ip\n- 放行，但是参杂一些脏数据\n\n---\n\n写爬虫真实一个费力不讨好的活儿，一不小心别人就改了反爬虫策略，一不小心网站的页面结构就发生变化了...不过这个过程中也还是学到了很多东西，特别是对于http协议的一些理解，真的比以前要深得多了。\n\n目前对于[这个网站](http://www.zone-h.com/archive/special=1/page=2)的采集就遇到了问题，它会限制访问频率，如果被检测出来了是爬虫，直接限制ip（表现方式是弹出验证码），如果严重它只会让验证过的session进行访问，同一个ip开另一个session还是会弹出验证码。所以希望有大神能够指点一二啊，还有一个比较有意思的问题是调用google搜索，同样会因为采集频率而受到限制，但是很奇怪的是同一个代理ip,被限制之后用浏览器同样可以访问，只是用程序访问会出错。这个问题应该是可以通过抓包等方式解决，但是我现在还是没眉目，也希望有童鞋可以交流、指点一下。\n',1,'爬虫',1479383282,0,6,0,1,1),(134,'Python漫游指南：序言','<p>很早逛Github的时候就看到Kenneth Reitz大神的<a href=\"https://github.com/kennethreitz/python-guide\">python-guide</a>了，这是一本关于Python语言的开源电子书，目前已有超过10k的star了，并且已由O\'Reilly出版了，很遗憾的是没有中文译本。由于对Kenneth Reitz大神的崇拜和想为开源社区出一份力，所以我打算翻译这本『Hitchhiker\'s Guide to Python』,中文名就叫它<strong>Python漫游指南</strong>吧。</p>\n<p>下面是关于它的主要内容。</p>\n<p>本指南的目的是为Python新手和专家提供关于Python安装、配置和日常使用的最佳实践。</p>\n<p>本指南完全不同于Python官方文档。在这里你找不到任何关于Python的web框架使用方法，相反，你会看到一系列强烈推荐的实践建议。</p>\n<p>以下是本书的目录</p>\n<p><strong> 1.Python入门 </strong></p>\n<p>主要介绍选择Python版本和安装Python的方法</p>\n<p><strong> 2.编写优质的Python代码</strong></p>\n<p>这部分提供了关于Python编码的最佳实践</p>\n<p><strong> 3.Python应用场景</strong></p>\n<p>这部分介绍了在不同应用场景下的Python模块和工具</p>\n<p><strong> 4.Python代码移植</strong></p>\n<p>这部分主要讲解部署Python代码</p>\n<p><strong> 5.Python开发环境</strong></p>\n<p>这部分旨在讲解Python的开发环境，使用开发工具来编写我们的Python代码</p>\n<p><strong> 6.附录</strong></p>\n<p>这部分介绍Python的社区生态和背景信息等</p>','很早逛Github的时候就看到Kenneth Reitz大神的[python-guide](https://github.com/kennethreitz/python-guide)了，这是一本关于Python语言的开源电子书，目前已有超过10k的star了，并且已由O\'Reilly出版了，很遗憾的是没有中文译本。由于对Kenneth Reitz大神的崇拜和想为开源社区出一份力，所以我打算翻译这本『Hitchhiker\'s Guide to Python』,中文名就叫它**Python漫游指南**吧。\n\n下面是关于它的主要内容。\n\n本指南的目的是为Python新手和专家提供关于Python安装、配置和日常使用的最佳实践。\n\n本指南完全不同于Python官方文档。在这里你找不到任何关于Python的web框架使用方法，相反，你会看到一系列强烈推荐的实践建议。\n\n以下是本书的目录\n\n** 1.Python入门 **\n\n 主要介绍选择Python版本和安装Python的方法\n\n** 2.编写优质的Python代码**\n\n 这部分提供了关于Python编码的最佳实践\n\n** 3.Python应用场景**\n\n 这部分介绍了在不同应用场景下的Python模块和工具\n\n** 4.Python代码移植**\n\n 这部分主要讲解部署Python代码\n\n** 5.Python开发环境**\n\n 这部分旨在讲解Python的开发环境，使用开发工具来编写我们的Python代码\n\n** 6.附录**\n\n 这部分介绍Python的社区生态和背景信息等',1,'Python',1479448795,0,5,0,1,1),(135,'Python漫游指南：Python入门之选择Python解释器','<h2>选择Python版本：PYthon 2 vs Python 3</h2>\n<p>当选择Python解释器的时候，一个重要的问题就是“我应该选择Python 2还是Python 3”？然而，答案并不是那么的明显。</p>\n<p>请考虑到以下事实：\n1. Python 2.7已经作为标准使用很长时间了\n2. Python 3 引入了很多语言层面的变化，很多开发者对此并不满意\n3. Python 2.7将在2020年停止维护和更新\n4. Python 3 将被持续支持</p>\n<p>所以，对于版本的选择并不是一个容易的决定</p>\n<h3>建议</h3>\n<p>在以下情况使用Python 3:\n- 觉得无所谓\n- 钟情于Python 3\n- 对Python2 和 Python3的区别不关心\n- 不知道如何选择\n- 乐于改变</p>\n<p>在下面情况下使用Python 2：\n- 喜欢Python2,对Python3的未来没信心\n- 项目对于语言和运行时的稳定性要求很高\n- 软件依赖于Python 2</p>\n<h3>那么，选Python 3?</h3>\n<p>如果你正在选择一款Python解释器，并且没有倾向，那么推荐使用最新版本的Python 3.x,因为每个版本将会引进新的标准库或者改善现有标准库模块的安全性和稳定性。每次发布都是一次改进。</p>\n<p>如果是下面的情况，那么就使用Python 2：\n- 需要的扩展库在Python 3中没有合适的代替品\n- 仅仅是喜欢Python2,并且灵感也是来自Python 2</p>\n<p>试试<a href=\"https://caniusepython3.com/\">Can I Use Python 3</a>,以判断所依赖的库是否只是Python 2独有的。</p>\n<p>扩展阅读: <a href=\"https://wiki.python.org/moin/Python2orPython3\">Python 2 or Python 3</a></p>\n<h2>Python实现</h2>\n<p>当谈及Python的时候，不仅是只Python语言，其实还包含CPython这个具体实现。Python实际上是一个可以以多种方式实现的语言规范。</p>\n<h3>CPython</h3>\n<p><a href=\"https://www.python.org/\">CPython</a>是Python的标准实现，使用C语言编写。它将Python代码编译为中间字节码，然后由虚拟机解释执行。CPython提供了Python包和C扩展模块的最高层次的兼容性。</p>\n<p>如果你需要使用Python编写开源项目，并且希望有更多的受众，那么最好的选择是使用CPython。要使依赖于C扩展的包运行，CPython是唯一的Python实现选择。</p>\n<p>所有版本的Python都使用C语言实现，因为CPython是Python的参考实现。</p>\n<h3>PyPy</h3>\n<p><a href=\"http://pypy.org/\">PyPy</a>是使用RPython实现的Python解释器，RPython是Python的一个受限的静态类型子集。PyPy解释器具有即时编译器（JIT）并且支持多种后端，包括C,CLI，JVM等。</p>\n<p>PyPy旨在提高Python程序性能的同时提供与CPython最大的兼容性。</p>\n<p>如果你想提高Python代码的性能，何不尝试一下PyPy？一系列的基准测试表明它的速度比CPython快5倍。</p>\n<p>PyPy目前支持Python 2.7。PyPy 3 发布了beta版本，旨在支持Python 3。</p>\n<h3>Jython</h3>\n<p><a href=\"http://www.jython.org/\">Jython</a> 是另一种Python实现，它会将Python代码编译成Java字节码，然后被编译的Java字节码会被JVM(Java虚拟机)执行。另外，可以像引用Python模块的那样引用和使用任何Java类。</p>\n<p>如果需要调用Java的API或者在JVM上执行Python代码，Jython是最好的选择。</p>\n<p>目前Jython支持Python2.7。</p>\n<h3>IronPython</h3>\n<p><a href=\"http://ironpython.net/\">IronPython</a>使用.Net框架实现的Python解释器。它可以同时使用Python和.Net框架的相关库，并且我们可以编写Python API供其他在.Net框架中的语言调用。</p>\n<p><a href=\"http://ironpython.net/tools/\">Python Tools for Visual Studio</a>直接将IronPython集成到了Visual Studio的开发环境中，使之成为Windows开发者的一个理想选择。</p>\n<p>IronPython 目前支持Python 2.7。</p>\n<h3>PythonNet</h3>\n<p><a href=\"http://pythonnet.github.io/\">Python for .Net</a>是一个软件包，它使原生Python和.Net CLR无缝集成。这种方式和上文提到的IronPython的实现方式截然不同，这种方式更像是互补而不是竞争。</p>\n<p>可以借助Mono，将PythonNet安装在非Windows操作系统（比如OS X和Linux）中。</p>\n<p>目前PythonNet支持Python2.6到Python3.5。</p>\n<hr />\n<p>以上是书的内容。就内容我想说的是，从目前看，对于入门来说，选择Python3个人觉得更好，因为Python2在2020年就会停止更新，而且Python3引入了很多新特性，特别是对编码方式的处理，这个比Python2要人性化得多！</p>\n<p>对于Python解释器的实现来说，我们一般都是用CPython标准实现。Jython一直不温不火，已经又有很久没更新了。PyPy是一个改善性能的好选择，特别是对于需要长期运行的代码来说，如果需要改善性能，相关的还可以看看Cython，这个也是一个不错的选择。.Net相关的实现我不是很了解，所以就不妄加评论了。</p>','## 选择Python版本：PYthon 2 vs Python 3\n\n当选择Python解释器的时候，一个重要的问题就是“我应该选择Python 2还是Python 3”？然而，答案并不是那么的明显。\n\n请考虑到以下事实：\n1. Python 2.7已经作为标准使用很长时间了\n2. Python 3 引入了很多语言层面的变化，很多开发者对此并不满意\n3. Python 2.7将在2020年停止维护和更新\n4. Python 3 将被持续支持\n\n所以，对于版本的选择并不是一个容易的决定\n\n### 建议\n\n在以下情况使用Python 3:\n- 觉得无所谓\n- 钟情于Python 3\n- 对Python2 和 Python3的区别不关心\n- 不知道如何选择\n- 乐于改变\n\n在下面情况下使用Python 2：\n- 喜欢Python2,对Python3的未来没信心\n- 项目对于语言和运行时的稳定性要求很高\n- 软件依赖于Python 2\n\n### 那么，选Python 3?\n\n如果你正在选择一款Python解释器，并且没有倾向，那么推荐使用最新版本的Python 3.x,因为每个版本将会引进新的标准库或者改善现有标准库模块的安全性和稳定性。每次发布都是一次改进。\n\n如果是下面的情况，那么就使用Python 2：\n- 需要的扩展库在Python 3中没有合适的代替品\n- 仅仅是喜欢Python2,并且灵感也是来自Python 2\n\n试试[Can I Use Python 3](https://caniusepython3.com/),以判断所依赖的库是否只是Python 2独有的。\n\n扩展阅读: [Python 2 or Python 3](https://wiki.python.org/moin/Python2orPython3)\n\n\n## Python实现\n\n当谈及Python的时候，不仅是只Python语言，其实还包含CPython这个具体实现。Python实际上是一个可以以多种方式实现的语言规范。\n\n### CPython\n\n[CPython](https://www.python.org/)是Python的标准实现，使用C语言编写。它将Python代码编译为中间字节码，然后由虚拟机解释执行。CPython提供了Python包和C扩展模块的最高层次的兼容性。\n\n如果你需要使用Python编写开源项目，并且希望有更多的受众，那么最好的选择是使用CPython。要使依赖于C扩展的包运行，CPython是唯一的Python实现选择。\n\n所有版本的Python都使用C语言实现，因为CPython是Python的参考实现。\n\n### PyPy\n\n[PyPy](http://pypy.org/)是使用RPython实现的Python解释器，RPython是Python的一个受限的静态类型子集。PyPy解释器具有即时编译器（JIT）并且支持多种后端，包括C,CLI，JVM等。\n\nPyPy旨在提高Python程序性能的同时提供与CPython最大的兼容性。\n\n如果你想提高Python代码的性能，何不尝试一下PyPy？一系列的基准测试表明它的速度比CPython快5倍。\n\nPyPy目前支持Python 2.7。PyPy 3 发布了beta版本，旨在支持Python 3。\n\n### Jython\n\n[Jython](http://www.jython.org/) 是另一种Python实现，它会将Python代码编译成Java字节码，然后被编译的Java字节码会被JVM(Java虚拟机)执行。另外，可以像引用Python模块的那样引用和使用任何Java类。\n\n如果需要调用Java的API或者在JVM上执行Python代码，Jython是最好的选择。\n\n目前Jython支持Python2.7。\n\n### IronPython\n\n[IronPython](http://ironpython.net/)使用.Net框架实现的Python解释器。它可以同时使用Python和.Net框架的相关库，并且我们可以编写Python API供其他在.Net框架中的语言调用。\n\n[Python Tools for Visual Studio](http://ironpython.net/tools/)直接将IronPython集成到了Visual Studio的开发环境中，使之成为Windows开发者的一个理想选择。\n\nIronPython 目前支持Python 2.7。\n\n### PythonNet\n\n[Python for .Net](http://pythonnet.github.io/)是一个软件包，它使原生Python和.Net CLR无缝集成。这种方式和上文提到的IronPython的实现方式截然不同，这种方式更像是互补而不是竞争。\n\n可以借助Mono，将PythonNet安装在非Windows操作系统（比如OS X和Linux）中。\n\n目前PythonNet支持Python2.6到Python3.5。\n\n--- \n\n以上是书的内容。就内容我想说的是，从目前看，对于入门来说，选择Python3个人觉得更好，因为Python2在2020年就会停止更新，而且Python3引入了很多新特性，特别是对编码方式的处理，这个比Python2要人性化得多！\n\n对于Python解释器的实现来说，我们一般都是用CPython标准实现。Jython一直不温不火，已经又有很久没更新了。PyPy是一个改善性能的好选择，特别是对于需要长期运行的代码来说，如果需要改善性能，相关的还可以看看Cython，这个也是一个不错的选择。.Net相关的实现我不是很了解，所以就不妄加评论了。\n',1,'python',1479449185,0,5,0,1,1),(136,'Ubuntu下切换Python版本后的问题和解决方法','<p>很久以前，我写过一篇关于在<a href=\"http://www.rookiefly.cn/detail/48\">ubuntu下切换Python版本</a>的博客。但是在切换Python版本后，陆陆续续出现了比较多的问题。比如出现了<strong>No module name \'ConfigParser\'</strong>这个问题，好不容易解决了这个问题，又出现了别的问题，比如<strong>Sub-process /usr/bin/dpkg returned -1</strong>等，还有就是不能使用<strong>sudo apt-get -f install</strong>修复错误，不能使用<strong>sudo apt-get upgrade</strong>等。万般无奈，我想到了重装系统，后来突然想到可以使用切换版本的方法切换到系统默认的版本，看看能不能用<strong>sudo apt-get -f install</strong>。切换过后，果然又可以用了！</p>\n<p>但是这样切换了，怎么用Python3呢？下面是关键的命令</p>\n<blockquote>\n<p>python3 xx.py</p>\n</blockquote>\n<p>怎么使用pip呢？</p>\n<blockquote>\n<p>python3 -m pip install requests</p>\n</blockquote>\n<p>如果想用python2,那么也可以用上面的方式</p>','很久以前，我写过一篇关于在[ubuntu下切换Python版本](http://www.rookiefly.cn/detail/48)的博客。但是在切换Python版本后，陆陆续续出现了比较多的问题。比如出现了**No module name \'ConfigParser\'**这个问题，好不容易解决了这个问题，又出现了别的问题，比如**Sub-process /usr/bin/dpkg returned -1**等，还有就是不能使用**sudo apt-get -f install**修复错误，不能使用**sudo apt-get upgrade**等。万般无奈，我想到了重装系统，后来突然想到可以使用切换版本的方法切换到系统默认的版本，看看能不能用**sudo apt-get -f install**。切换过后，果然又可以用了！\n\n但是这样切换了，怎么用Python3呢？下面是关键的命令\n> python3 xx.py\n\n怎么使用pip呢？\n> python3 -m pip install requests\n\n\n如果想用python2,那么也可以用上面的方式\n\n',1,'python',1479652068,0,1,0,1,1);
/*!40000 ALTER TABLE `posts` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `tags`
--

DROP TABLE IF EXISTS `tags`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `tags` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) NOT NULL,
  `size` smallint(6) NOT NULL,
  `RGB` varchar(15) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=67 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `tags`
--

LOCK TABLES `tags` WRITE;
/*!40000 ALTER TABLE `tags` DISABLE KEYS */;
INSERT INTO `tags` VALUES (29,'数据库',13,'rgb(221,210,46)'),(30,'科学上网',15,'rgb(234,56,149)'),(31,'markdown',18,'rgb(109,88,174)'),(32,'flask',17,'rgb(215,5,67)'),(33,'sqlalchemy',15,'rgb(228,194,173'),(34,'oracle',19,'rgb(233,218,165'),(35,'nginx',18,'rgb(7,181,227)'),(36,'python',14,'rgb(158,221,169'),(37,'git',12,'rgb(68,243,233)'),(38,'github',19,'rgb(70,188,144)'),(39,'ubuntu',18,'rgb(162,151,253'),(40,'算法',15,'rgb(95,91,241)'),(41,'redis',16,'rgb(111,120,179'),(42,' redis',18,'rgb(102,47,226)'),(43,'sftp',12,'rgb(35,1,188)'),(44,'selnium',20,'rgb(74,150,234)'),(45,'爬虫',19,'rgb(146,81,192)'),(47,'requests',14,'rgb(153,40,124)'),(48,'模拟登陆',18,'rgb(170,34,195)'),(52,'测试',18,'rgb(50,111,0)'),(53,'navicat',19,'rgb(225,16,52)'),(54,'linux',16,'rgb(137,68,132)'),(55,'pyvenv',15,'rgb(161,19,246)'),(56,'ftp',18,'rgb(112,106,3)'),(57,'sublime',16,'rgb(12,208,159)'),(58,'环境配置',13,'rgb(204,6,41)'),(59,'java',13,'rgb(183,40,53)'),(60,'多进程',19,'rgb(16,152,0)'),(61,'面试题',20,'rgb(23,184,175)'),(62,'底层',15,'rgb(57,102,95)'),(63,'设计模式',13,'rgb(62,89,234)'),(64,'感悟',12,'rgb(102,38,164)'),(65,'操作系统',13,'rgb(98,1,116)'),(66,'性能优化',19,'rgb(160,165,65)');
/*!40000 ALTER TABLE `tags` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `users`
--

DROP TABLE IF EXISTS `users`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `users` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `name` varchar(255) NOT NULL,
  `password` varchar(255) NOT NULL,
  `level` smallint(2) NOT NULL DEFAULT '1' COMMENT '0表示管理员，1表示一般用户',
  `status` smallint(2) NOT NULL DEFAULT '1' COMMENT '0表示异常，1表示正常',
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `users`
--

LOCK TABLES `users` WRITE;
/*!40000 ALTER TABLE `users` DISABLE KEYS */;
INSERT INTO `users` VALUES (1,'resolvewang','wang1204',0,1);
/*!40000 ALTER TABLE `users` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `views`
--

DROP TABLE IF EXISTS `views`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!40101 SET character_set_client = utf8 */;
CREATE TABLE `views` (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `u_a` varchar(255) DEFAULT NULL,
  `ip` varchar(255) DEFAULT NULL,
  `post_id` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `views`
--

LOCK TABLES `views` WRITE;
/*!40000 ALTER TABLE `views` DISABLE KEYS */;
/*!40000 ALTER TABLE `views` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2016-11-20 22:29:49
